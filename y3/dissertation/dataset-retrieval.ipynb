{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itoETOcJSTMR"
      },
      "source": [
        "## Retrieve Data from SourceGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYN1PLjU1Tod",
        "outputId": "96388782-577d-48ae-e2d4-9c3bfd0f150f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (2.22.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JpbB-JDoS7q6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import datetime\n",
        "import requests\n",
        "import os\n",
        "from pathlib import Path\n",
        "import concurrent.futures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21wk-YgYBmGL"
      },
      "source": [
        "## Searching for test-source file pairs using SourceGraph GraphQL API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYRDG0ARDApz"
      },
      "source": [
        "### Collect All Relevant Test Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "30hitopTka-W"
      },
      "outputs": [],
      "source": [
        "sg_token = \"0ce61725c965870cc6a61b5d7caf6b48cf0ab8dc\"\n",
        "payload = {\n",
        "  \"query\": \"query ($query: String!) {\\n  search(query: $query, version: V2) {\\n    results {\\n      results {\\n        __typename\\n        ... on FileMatch {\\n          ...FileMatchFields\\n        }\\n      }\\n      matchCount\\n      elapsedMilliseconds\\n    }\\n  }\\n}\\n\\nfragment FileMatchFields on FileMatch {\\n  repository {\\n    name\\n    url\\n  }\\n  file {\\n    name\\n    url\\n  }\\n}\",\n",
        "  \"variables\": {\n",
        "    \"query\": \"file:.*_test.py file:has.content(import unittest) count:1000000 fork:no lang:python\"\n",
        "  }\n",
        "}\n",
        "\n",
        "destination = \"./Datasets/raw_datasets.json\"\n",
        "path = Path(destination)\n",
        "\n",
        "if not(path.exists()) :\n",
        "  r = requests.post('https://sourcegraph.com/.api/graphql', json=payload, headers={'Authorization': f\"token {sg_token}\"}, stream=True)\n",
        "  status = r.status_code\n",
        "\n",
        "  if status == 200 :\n",
        "      with open(destination, 'w+') as file:\n",
        "        data = r.json()[\"data\"][\"search\"][\"results\"]\n",
        "        json.dump(data, file, indent = 4)\n",
        "  else:\n",
        "    print(f\"Status Code: {status}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r58v9UjP2But"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\n",
            "filtered_datasets.json\n",
            "raw_datasets.json\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "ls \"./Datasets/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5lgMhLzDbMe"
      },
      "source": [
        "### Filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_yWGLRzR8mT"
      },
      "source": [
        "#### By existence of Source File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLLTKcybr8ly",
        "outputId": "90cc1c8e-cbdd-44de-b91a-0f92e0666830"
      },
      "outputs": [],
      "source": [
        "def search_source(query, schema):\n",
        "  payload = {\n",
        "    \"query\": schema,\n",
        "    \"variables\": {\n",
        "      \"query\": query\n",
        "    }\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    r = requests.post('https://sourcegraph.com/.api/graphql', json=payload, headers={'Authorization': f\"token {sg_token}\"}, stream=True)\n",
        "  except:\n",
        "    r = requests.post('https://sourcegraph.com/.api/graphql', json=payload, headers={'Authorization': f\"token {sg_token}\"}, verify=False)\n",
        "\n",
        "  status = r.status_code\n",
        "\n",
        "  if status == 200 :\n",
        "    data = r.json()['data']['search']\n",
        "\n",
        "    if data == None:\n",
        "      return\n",
        "\n",
        "    results = data[\"results\"][\"results\"]\n",
        "\n",
        "    search_count = data[\"results\"]['matchCount']\n",
        "\n",
        "    if search_count == 1:\n",
        "      result = results[0]\n",
        "      return result\n",
        "      \n",
        "  else:\n",
        "    print(f\"\\rStatus Code: {status}\", end=\"\")\n",
        "    print(f\"\\r{r.headers}\", end=\"\")\n",
        "    if(status == 500):\n",
        "      retry = int(r.headers[\"Retry-After\"])\n",
        "      time.sleep(retry)\n",
        "      \n",
        "source_files = dict()\n",
        "source_test_map = dict()\n",
        "\n",
        "def map_source_to_test(test_result):\n",
        "  source_file = test_result[\"file\"][\"name\"].replace(\"_test\", \"\")\n",
        "  source_test_mapping = dict()\n",
        "  # If a source file is found in the list of successfully retrieved source files add the pair to a source-test map\n",
        "  if source_file in source_files.keys():\n",
        "    source_test_mapping[\"source\"] = source_files[source_file][\"source_file\"]\n",
        "    source_test_mapping[\"test\"] = test_result.pop(\"file\")\n",
        "\n",
        "    source_test_map[source_file] = source_test_mapping\n",
        "\n",
        "schema = \"query ($query: String!) {\\n  search(query: $query, version: V2) {\\n    results {\\n      results {\\n        __typename\\n        ... on FileMatch {\\n          ...FileMatchFields\\n        }\\n      }\\n      matchCount\\n    }\\n  }\\n}\\n\\nfragment FileMatchFields on FileMatch {\\n  file {\\n    name\\n    url\\n  }\\n}\"\n",
        "\n",
        "def create_source_test_map():\n",
        "  with open(destination, 'r+') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "    fileCount = 0\n",
        "    \n",
        "    sg_queries = []\n",
        "\n",
        "    test_results = data[\"results\"]\n",
        "\n",
        "    # Create queries to find corresponding source files for each test file and prep a dictionary\n",
        "    for test_result in test_results:\n",
        "      repo = test_result[\"repository\"][\"name\"]\n",
        "      test_file = test_result[\"file\"][\"name\"]\n",
        "      source_file = test_file.replace(\"_test\", \"\")\n",
        "      del test_result[\"__typename\"]\n",
        "      del test_result[\"repository\"]\n",
        "\n",
        "      sg_query = f\"repo:{repo} (file:.*/{source_file}) fork:no lang:python\"\n",
        "\n",
        "      sg_queries.append(sg_query)\n",
        "\n",
        "  # This should occur prior to calling create_source_test_map (indentation issues)      \n",
        "  with concurrent.futures.ThreadPoolExecutor(max_workers=300) as executor:\n",
        "    fileCount = 0\n",
        "    duplicates = 0\n",
        "    # Check if a source file can be found on the server using our query\n",
        "    for query in sg_queries:\n",
        "      result = executor.submit(search_source, query, schema).result()\n",
        "      \n",
        "      if result:\n",
        "        file_name = result[\"file\"][\"name\"]\n",
        "        if file_name not in source_files.keys():\n",
        "          source_files[file_name] = {\"source_file\": {\"name\" : file_name, \"url\" : result[\"file\"][\"url\"]}}\n",
        "          fileCount += 1\n",
        "          print(\"\\r{0:.2f} % progess with source file search\".format(100 * fileCount/(len(sg_queries)-duplicates)), end=\"\")\n",
        "        else:\n",
        "          duplicates += 1\n",
        "\n",
        "  with open(destination.replace(\"raw\", \"filtered\"), 'w+') as file:    \n",
        "      fileCount = 0\n",
        "      \n",
        "      source_file_count = len(source_files.keys())\n",
        "      # For each test file perform the source to test mapping\n",
        "      with concurrent.futures.ThreadPoolExecutor(max_workers=300) as executor:\n",
        "        for test_result in test_results:\n",
        "          executor.submit(map_source_to_test, test_result)\n",
        "          fileCount += 1\n",
        "          \n",
        "          \n",
        "          print(\"\\r{0:.2f} % progess with source test mapping\".format(100 * fileCount/source_file_count), end=\"\")\n",
        "      \n",
        "      json.dump({\"results\": source_test_map}, file, indent = 4)\n",
        "          \n",
        "try:\n",
        "  with open(destination.replace(\"raw\", \"filtered\"), 'r+') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "except:\n",
        "  create_source_test_map()\n",
        "\n",
        "destination = destination.replace(\"raw\", \"filtered\")\n",
        "path = Path(destination)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brxmrVBkSJvI"
      },
      "source": [
        "#### By License and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVaSrRR4SzLI",
        "outputId": "2447acdc-ffab-4d85-ca0d-cbc1d070c395"
      },
      "outputs": [],
      "source": [
        "licenses = [\n",
        "    \"\\\"Licensed under the Apache License, Version 2.0\\\"\", # Apache License 2.0\n",
        "    \"\\\"Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\\\"\", # GNU AGPLv3, GNU GPLv3, GNU LGPLv3\n",
        "    \"\\\"Mozilla Public License Version 2.0\\\"\", # Mozilla Public License Version 2.0,\n",
        "    \"\\\"Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\\\"\", # BSD License\n",
        "    \"\\\"MIT License\\\"\" # MIT License\n",
        "]\n",
        "\n",
        "with open(destination, 'r+') as file:\n",
        "    data = json.load(file)\n",
        "    results = data[\"results\"]\n",
        "    files = results.keys()\n",
        "\n",
        "fileCount = 0\n",
        "\n",
        "src_folder = destination.replace(\"filtered_datasets.json\", \"data/src\")\n",
        "\n",
        "if(not(Path(src_folder).exists())):\n",
        "  os.makedirs(src_folder)\n",
        "  os.makedirs(src_folder.replace(\"src\", \"test\"))\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=300) as executor:\n",
        "  for file in files:\n",
        "    repo = '/'.join(results[file][\"source\"][\"url\"].split('/')[:3]).replace('/', '', 1)\n",
        "    query = f\"repo:{repo}(file:{file} content:{' OR '.join(licenses)})\"\n",
        "    schema = schema.replace(\"url\", \"content\")\n",
        "    \n",
        "    result = executor.submit(search_source, query, schema).result()\n",
        "\n",
        "    if result:\n",
        "      source_content = result[\"file\"][\"content\"]\n",
        "\n",
        "      source_path = os.path.join(src_folder, file)\n",
        "      \n",
        "\n",
        "      test_file = file.replace(\".py\", \"_test.py\")\n",
        "      \n",
        "      query = f\"repo:{repo}(file:{test_file})\"\n",
        "\n",
        "      result = executor.submit(search_source, query, schema).result()\n",
        "\n",
        "      if result:\n",
        "      # Ensure both source and test are valid first\n",
        "        if (not(Path(source_path).exists())):\n",
        "          with open(source_path, \"w\") as f:\n",
        "            f.write(source_content)\n",
        "\n",
        "        test_content = result[\"file\"][\"content\"]\n",
        "\n",
        "        test_path = os.path.join(src_folder.replace('src', 'test'), test_file)\n",
        "        \n",
        "        if (not(Path(test_path).exists())):\n",
        "          with open(test_path, \"w\") as f:\n",
        "            f.write(test_content)\n",
        "\n",
        "        fileCount += 1\n",
        "        print(f\"\\r{fileCount} file(s) out of {len(files)}\", end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKPzWFLwM1NN"
      },
      "source": [
        "### AST Miner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HTtB3q3dNr_"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/JetBrains-Research/astminer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ADSgD0-kewV"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "if [ ! -f /etc/profile.d/gradle.sh ]\n",
        "then\n",
        "  wget https://services.gradle.org/distributions/gradle-6.9.3-bin.zip -P /tmp\n",
        "  sudo unzip -d /opt/gradle /tmp/gradle-*.zip\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh1vYQnj_-sQ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GRADLE_HOME\"] = \"/opt/gradle/gradle-6.9.3\"\n",
        "os.environ[\"PATH\"] = f\"{os.environ['GRADLE_HOME']}/bin:{os.environ['PATH']}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2oi_WylltZ9"
      },
      "outputs": [],
      "source": [
        "! gradle -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsw4S5uUuFNl"
      },
      "source": [
        "### Use ASTMiner to convert Python Code to AST format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjWt4vU8AsG9"
      },
      "source": [
        "check out antlr_python_paths.yaml for setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8zM4gDWkLWi"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# gradle -p astminer shadowJar\n",
        "cd astminer\n",
        "./cli.sh /content/antlr_python_paths.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiZO4fbg_wdJ"
      },
      "outputs": [],
      "source": [
        "! python3 /content/src/test/resources/factorial.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
