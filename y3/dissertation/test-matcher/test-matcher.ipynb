{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TJSun009/University-Projects/blob/main/Test_Matcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bgjOkMrriB-Q"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiDQAGIjk1ee"
      },
      "outputs": [],
      "source": [
        "! pip install -Uqqq scipy networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUjrG3-fDDcX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from glob import iglob\n",
        "import importlib"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NGiAvVTs535v"
      },
      "source": [
        "### python-graphs dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r31L5nnSeL-"
      },
      "outputs": [],
      "source": [
        "# Graph Generator Approach\n",
        "# https://arxiv.org/pdf/2208.07461v1.pdf\n",
        "\n",
        "# install python-graphs on startup\n",
        "! apt-get -qq -y install graphviz graphviz-dev\n",
        "! pip install -Uqqq python-graphs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LJq3_r9jFem7"
      },
      "source": [
        "## CODE Dirs\n",
        "The Code Directory should be a path to a folder with subfolders /src and /test\n",
        "\n",
        "Your test and src files should have the naming convention *_test.py and *.py respectively\n",
        "- i.e. divide_test.py is the test for divide.py\n",
        "\n",
        "The data.zip is also available in the following GitHub [repo](https://github.com/TJSun009/University-Projects/blob/313cc021030769362faab8904c255b58d1327dd4/data.zip), which can be extracted and pointed to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJy8aIye_hMm"
      },
      "outputs": [],
      "source": [
        "CODE_DIR = \"PATH TO FILES\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h7jOhrQzPO-i"
      },
      "source": [
        "## Feed Data to Graph Network"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XYDzw1GVdjKe"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCUAunHgfRDc"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqqq torch-scatter torch-sparse torch-geometric -f https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DFjEdSGF-ma"
      },
      "outputs": [],
      "source": [
        "# each edge should be weighted differently based on its type, edge should contain types\n",
        "from python_graphs import program_graph_dataclasses\n",
        "\n",
        "# for ast class list\n",
        "import sys, inspect\n",
        "\n",
        "import torch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zb-RAp29RvT-"
      },
      "source": [
        "### Pytorch Code Data Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe_YGzOGR0Uh",
        "outputId": "51b9f5a9-be9f-4fab-dfe9-30f06986d01a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:31: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_scatter_cuda.so: undefined symbol: _ZN2at4_ops6narrow4callERKNS_6TensorElll\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_diag_cuda.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.data.dataset import to_list\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# This code data class represents a single graph generated in the code corpus as a pytorch data object\n",
        "class CodeData:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.x = []\n",
        "    self.edge_index = [[], []]\n",
        "    self.edge_attr = []\n",
        "    self.y = []\n",
        "    self.data = None\n",
        "    self.types = {\n",
        "        \"edge\" : program_graph_dataclasses.EdgeType._member_names_,\n",
        "        \"ast\" : [cls.__name__ for _, cls in inspect.getmembers(sys.modules[\"ast\"], inspect.isclass)]\n",
        "        }\n",
        "    self.vocab = set()\n",
        "    self.node_id_map = {}\n",
        "\n",
        "  def node_value_to_vect(self, k, v):\n",
        "    if k == \"node_type\":\n",
        "      return v.value\n",
        "    elif k == \"ast_type\":\n",
        "      ast_types = self.types[\"ast\"]\n",
        "      return ast_types.index(v) if v in ast_types else -1\n",
        "    elif k == \"ast_value\":\n",
        "      # transform vocab to list \n",
        "      return list(self.vocab).index(v)\n",
        "\n",
        "\n",
        "  def read(self, src_graph, test_graph):\n",
        "\n",
        "    # set identifier to file_name of graph if graph is a module\n",
        "    self.y = [int(src_graph.filename.replace(\"_test.py\", \"\") == test_graph.filename.replace(\"_test.py\", \".py\"))]\n",
        "\n",
        "    # offset to differentiate src and test nodes\n",
        "    offset = 0\n",
        "\n",
        "    for graph in [src_graph, test_graph]:\n",
        "\n",
        "      # add nodes to graph along with their attributes\n",
        "      # dict comprehension deduplicates node id\n",
        "      # we can exclude the ast_node as this info should be encoded in the graphs and edges\n",
        "      # exclude instruction temporarily due to complexity\n",
        "\n",
        "      nodes = graph.all_nodes()\n",
        "\n",
        "      # create dictionary of ast token values to context embeddings\n",
        "\n",
        "      # do one_hot_encoding instead for ease\n",
        "      self.vocab.update(set([node.ast_value for node in nodes]))\n",
        "\n",
        "      def update_node_id_map(idx, node, offset):\n",
        "        self.node_id_map[node.id] = idx + offset\n",
        "        return (idx + offset, node)\n",
        "\n",
        "      self.x.extend([update_node_id_map(idx, node, offset) for idx, node in enumerate(nodes)])\n",
        "\n",
        "      \n",
        "      # append edges to the graph along with their attributes\n",
        "      # dict comprehension deduplicates node ids for edge\n",
        "      \n",
        "      for edge in graph.edges:\n",
        "        self.edge_index[0].append(self.node_id_map[edge.id1])\n",
        "        self.edge_index[1].append(self.node_id_map[edge.id2])\n",
        "        self.edge_attr.append([edge.type.value])\n",
        "\n",
        "      offset = len(self.x)\n",
        "\n",
        "    # enumerate through self.x and add other features\n",
        "    for idx, (id, node) in enumerate(self.x):\n",
        "      self.x[idx] = [id] + [self.node_value_to_vect(k, v) for k, v in node.__dict__.items() if k not in [\"id\", \"ast_node\", \"instruction\", \"syntax\"]]\n",
        "\n",
        "  \n",
        "  def get_data(self):\n",
        "    if (len(self.y) > 0):\n",
        "      self.x = torch.tensor(self.x, dtype=torch.float32)\n",
        "      self.y = torch.tensor(self.y)\n",
        "      self.edge_index = torch.tensor(self.edge_index, dtype=torch.float32)\n",
        "      self.edge_attr = torch.tensor(self.edge_attr, dtype=torch.long)\n",
        "      \n",
        "      return Data(x=self.x, edge_index=self.edge_index, edge_attr=self.edge_attr, y=self.y)\n",
        "\n",
        "  def draw(self):\n",
        "    if len(self.x) > 0:\n",
        "\n",
        "      G = self.get_data().to_networkx()\n",
        "\n",
        "      # create normalizer for colours\n",
        "      norm = plt.Normalize()\n",
        "\n",
        "      # use vocab and edge_types to generate colours for plot\n",
        "      # edges are mapped to their position in types\n",
        "      token_colors = [self.vocab.index(val) for val in list(nx.get_node_attributes(self.G, \"ast_value\").values())]\n",
        "      edge_type_colors = [edge_type.value for edge_type in list(nx.get_edge_attributes(self.G, \"type\").values())]\n",
        "      \n",
        "      # normalize the colors between [0, 1]\n",
        "      node_color, edge_color = norm(token_colors), norm(edge_type_colors)\n",
        "\n",
        "      fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "\n",
        "      nx.draw_networkx(G, edge_color = edge_color, node_color = node_color, with_labels=True, ax = ax)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8fX44jExinI"
      },
      "source": [
        "## PyTorch Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51lrAu2lK9Z9"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Dataset\n",
        "import glob\n",
        "from torch_geometric.data.makedirs import makedirs\n",
        "from itertools import product\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_26M7_6GkZIw"
      },
      "outputs": [],
      "source": [
        "import gast\n",
        "from python_graphs import program_graph\n",
        "from contextlib import suppress\n",
        "\n",
        "def get_graph(fpath):\n",
        "  try:\n",
        "    with open(fpath, encoding=\"utf-8\") as f:\n",
        "      graph = program_graph.get_program_graph(gast.parse(f.read()))\n",
        "      graph.filename = os.path.basename(fpath)\n",
        "      return graph\n",
        "  except:\n",
        "    return None\n",
        "\n",
        "def save_pytorch_data(raw_paths, processed_dir, processed_file_names):\n",
        "  src_paths, test_paths = [], []\n",
        "\n",
        "  for path in raw_paths:\n",
        "    test_paths.append(path) if path.find(\"_test.py\") != -1 else src_paths.append(path)\n",
        "\n",
        "  source_test_pairs = list(product(src_paths, test_paths))\n",
        "\n",
        "  idx = 0\n",
        "\n",
        "  unparseable = []\n",
        "\n",
        "  for i, (src_path, test_path) in enumerate(pbar := tqdm(source_test_pairs)):\n",
        "    \n",
        "    if src_path in unparseable or test_path in unparseable:\n",
        "      continue\n",
        "\n",
        "    src_graph = get_graph(src_path)\n",
        "    \n",
        "    if src_graph == None:\n",
        "      unparseable.append(src_path)\n",
        "      pbar.set_description(f\"Could not parse {os.path.basename(src_path)}\")\n",
        "      continue\n",
        "    \n",
        "    \n",
        "    test_graph = get_graph(test_path)\n",
        "    \n",
        "    if test_graph == None:\n",
        "      unparseable.append(test_path)\n",
        "      pbar.set_description(f\"Could not parse {os.path.basename(test_path)}\")\n",
        "      continue\n",
        "    else:\n",
        "      if (os.path.exists(os.path.join(processed_dir, f\"data_{idx}.pt\"))):\n",
        "        idx += 1\n",
        "        continue\n",
        "    \n",
        "    pbar.set_description(f\"pairing [{os.path.basename(src_path)}, {os.path.basename(test_path)}]\")\n",
        "    \n",
        "    paired_data = CodeData()\n",
        "\n",
        "    paired_data.read(src_graph, test_graph)\n",
        "\n",
        "    data = paired_data.get_data()\n",
        "\n",
        "    data_file = f\"data_{idx}.pt\"\n",
        "\n",
        "    torch.save(data, os.path.join(processed_dir, data_file))\n",
        "\n",
        "    processed_file_names.append(data_file)\n",
        "\n",
        "    pbar.set_description(f\"saved {data_file}\")\n",
        "    \n",
        "    idx += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dhd2o1mLWKu"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "from glob import iglob\n",
        "class SourceTestDataset(Dataset):\n",
        "  def __init__(self, root, transform=None, pre_transform=None, pre_filter=None, gcs=False):\n",
        "      self.max_props = {\"nodes\": 0, \"edges\": 0}\n",
        "      self.cached_raw_files = []\n",
        "      self.cached_processed_files = []\n",
        "      self.vocab = set()\n",
        "      \n",
        "      self.types = {\n",
        "        \"edge\" : program_graph_dataclasses.EdgeType._member_names_,\n",
        "        \"ast\" : [cls.__name__ for _, cls in inspect.getmembers(sys.modules[\"ast\"], inspect.isclass)]\n",
        "      }\n",
        "\n",
        "      super().__init__(root, self.transform, pre_transform, pre_filter)\n",
        "      \n",
        "      # self.node_id_map = {}\n",
        "\n",
        "  def node_value_to_vect(self, k, v):\n",
        "    if k == \"node_type\":\n",
        "      return v.value\n",
        "    elif k == \"ast_type\":\n",
        "      ast_types = self.types[\"ast\"]\n",
        "      return ast_types.index(v) if v in ast_types else -1\n",
        "    elif k == \"ast_value\":\n",
        "      # transform vocab to list \n",
        "      return list(self.vocab).index(v)\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    if len(self.cached_raw_files) == 0:\n",
        "      source_files = os.listdir(os.path.join(CODE_DIR, \"raw\", \"src\", ''))\n",
        "      \n",
        "      for file in source_files:\n",
        "        self.cached_raw_files.append(os.path.join(CODE_DIR, \"raw\", \"src\", file))\n",
        "        self.cached_raw_files.append(os.path.join(CODE_DIR, \"raw\", \"test\", file.replace(\".py\", \"_test.py\")))\n",
        "    else:\n",
        "      self.cached_raw_files = [os.path.basename(file) for file in iglob(os.path.join(CODE_DIR, \"**\", \"*.py\"))]\n",
        "\n",
        "    return self.cached_raw_files\n",
        "  \n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    nodes = 0\n",
        "    \n",
        "    processed_files = []\n",
        "\n",
        "    for file in iglob(f\"{self.processed_dir}/[!pre_]*\"):\n",
        "      processed_files.append(os.path.basename(file))\n",
        "      if self.max_props[\"nodes\"] == 0:\n",
        "        data = torch.load(os.path.join(self.processed_dir, file))\n",
        "        nodes = max(nodes, data.x.size()[0])\n",
        "    else:\n",
        "      if(nodes > 0):\n",
        "        self.max_props[\"nodes\"] = nodes\n",
        "\n",
        "    if len(processed_files) > 0:\n",
        "      self.cached_processed_files = processed_files\n",
        "\n",
        "    return self.cached_processed_files\n",
        "\n",
        "  def download(self):\n",
        "    # Download to `self.raw_dir`.\n",
        "    raise NotImplementedError(f\"No data in {self.raw_dir} directory. Use the dataset retrieval notebook to retrieve files\")\n",
        "\n",
        "  def process(self):\n",
        "    # Read data into huge `Data` list.\n",
        "    save_pytorch_data(self.raw_file_names, self.processed_dir, self.cached_processed_files)\n",
        "\n",
        "  def len(self):\n",
        "    return len(self.processed_file_names)\n",
        "  \n",
        "  def transform(self, data):\n",
        "    from torch.nn import functional as F\n",
        "    node_pad = int(self.max_props[\"nodes\"] - data.x.size()[0])\n",
        "    edge_pad = int(self.max_props[\"edges\"] - data.edge_index.size()[1])\n",
        "    data.x = F.pad(data.x, (0, 0, 0, node_pad)).to(torch.float32)\n",
        "    data.edge_index = data.edge_index.to(torch.long)\n",
        "    return data\n",
        "\n",
        "  def get(self, idx):\n",
        "    data = torch.load(os.path.join(self.processed_dir, f\"data_{idx}.pt\"))\n",
        "    return data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j_qxqk5QuODa"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl92SSHT0hMt"
      },
      "outputs": [],
      "source": [
        "dataset = SourceTestDataset(root=CODE_DIR)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ksFoSu69IP1q"
      },
      "source": [
        "### Inspect Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv8nGlfyIWFw",
        "outputId": "1dcd9dd0-bbf0-48e6-c770-ac5897725359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset: SourceTestDataset(1881):\n",
            "====================\n",
            "Number of graphs: 1881\n",
            "Number of features: 4\n",
            "Number of classes: 2\n"
          ]
        }
      ],
      "source": [
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('====================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uCp8XqYORr46"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d0CbMz5aqAgR"
      },
      "source": [
        "### neptune.ai Integration\n",
        "\n",
        "See [here](https://docs.neptune.ai/setup/installation/) for setting up your own neptune.ai API key and project\n",
        "\n",
        "If you don't require neptune you can set `run` to None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC8TnzX8qJ0A"
      },
      "outputs": [],
      "source": [
        "! pip install -Uqqq neptune-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcpQwclsBV_G",
        "outputId": "fa57f813-0cb8-4aeb-b27b-260a1f85aa4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/neptune/internal/backends/hosted_client.py:50: NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n",
            "  from neptune.version import version as neptune_client_version\n",
            "<ipython-input-19-80e405492d42>:1: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
            "  import neptune.new as neptune\n",
            "<ipython-input-19-80e405492d42>:7: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
            "  run = neptune.init_run(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://app.neptune.ai/tjsun009/test-src-classifier/e/TES-44\n"
          ]
        }
      ],
      "source": [
        "import neptune.new as neptune\n",
        "\n",
        "neptune_api_token = \"YOUR TOKEN\"\n",
        "\n",
        "project = \"YOUR PROJECT NAME\"\n",
        "\n",
        "run = neptune.init_run(\n",
        "    api_token=neptune_api_token,\n",
        "    project=project,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rLnWBuZhKZCG"
      },
      "source": [
        "### Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJHfytlTKcmO"
      },
      "outputs": [],
      "source": [
        "split_ratio = 0.8\n",
        "batch_size = 32\n",
        "hidden_channels = 64\n",
        "learning_rate = 0.01\n",
        "\n",
        "# log params\n",
        "run[\"parameters\"] = {\"split_ratio\": split_ratio, \"batch_size\": batch_size, \"hidden_channels\": hidden_channels, \"learning_rate\": learning_rate}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7mu7WUHAIgQ3"
      },
      "source": [
        "### Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZVcVry9Imgl",
        "outputId": "bae76063-b932-4d05-9d2b-28c43a5135f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training graphs: 1504\n",
            "Number of test graphs: 377\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(12345)\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "split_idx = int(len(dataset)*split_ratio)\n",
        "\n",
        "train_dataset = dataset[:split_idx]\n",
        "test_dataset = dataset[split_idx:]\n",
        "\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4todTZosLdmb"
      },
      "source": [
        "### Prepare Dataset Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHOfyT5JLgVr",
        "outputId": "8ceda365-22de-4d54-b301-0bb677058ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 986526], edge_attr=[986526, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 2:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 420841], edge_attr=[420841, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 3:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1080426], edge_attr=[1080426, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 4:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1023737], edge_attr=[1023737, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 5:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 586733], edge_attr=[586733, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 6:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 856422], edge_attr=[856422, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 7:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1383674], edge_attr=[1383674, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 8:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1101432], edge_attr=[1101432, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 9:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1045643], edge_attr=[1045643, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 10:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1163654], edge_attr=[1163654, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 11:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 657190], edge_attr=[657190, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 12:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 841959], edge_attr=[841959, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 13:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 788819], edge_attr=[788819, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 14:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1020086], edge_attr=[1020086, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 15:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 584942], edge_attr=[584942, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 16:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1336108], edge_attr=[1336108, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 17:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 838802], edge_attr=[838802, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 18:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1341576], edge_attr=[1341576, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 19:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1286502], edge_attr=[1286502, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 20:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1342927], edge_attr=[1342927, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 21:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1891469], edge_attr=[1891469, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 22:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 868893], edge_attr=[868893, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 23:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 617524], edge_attr=[617524, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 24:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1376016], edge_attr=[1376016, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 25:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 708279], edge_attr=[708279, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 26:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1014330], edge_attr=[1014330, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 27:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1474387], edge_attr=[1474387, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 28:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 831398], edge_attr=[831398, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 29:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 480232], edge_attr=[480232, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 30:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1145782], edge_attr=[1145782, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 31:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 942661], edge_attr=[942661, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 32:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1087541], edge_attr=[1087541, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 33:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1236022], edge_attr=[1236022, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 34:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 975582], edge_attr=[975582, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 35:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 878369], edge_attr=[878369, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 36:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 988180], edge_attr=[988180, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 37:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 743020], edge_attr=[743020, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 38:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 711264], edge_attr=[711264, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 39:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1530226], edge_attr=[1530226, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 40:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 866362], edge_attr=[866362, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 41:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 609815], edge_attr=[609815, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 42:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1175402], edge_attr=[1175402, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 43:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 910680], edge_attr=[910680, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 44:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 730401], edge_attr=[730401, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 45:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 1392522], edge_attr=[1392522, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 46:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 823338], edge_attr=[823338, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n",
            "Step 47:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[5827616, 4], edge_index=[2, 719273], edge_attr=[719273, 1], y=[32], batch=[5827616], ptr=[33])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# use GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=batch_size, \n",
        "    shuffle=True,\n",
        "    **kwargs\n",
        "    )\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=batch_size, \n",
        "    shuffle=False,\n",
        "    **kwargs\n",
        "    )\n",
        "\n",
        "for step, data in enumerate(train_loader):\n",
        "  print(f'Step {step + 1}:')\n",
        "  print('=======')\n",
        "  print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "  print(data)\n",
        "  print()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0pq-VyzUwPpw"
      },
      "source": [
        "## Training a Graph Neural Network (GNN)\n",
        "\n",
        "copied from: https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN3sRVuaQ88l",
        "outputId": "932d0c17-88e3-420c-bdcc-79002c273e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(4, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Obtain node embeddings \n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=hidden_channels)\n",
        "model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Q37tbHyQ6A"
      },
      "source": [
        "Here, we again make use of the [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) with $\\mathrm{ReLU}(x) = \\max(x, 0)$ activation for obtaining localized node embeddings, before we apply our final classifier on top of a graph readout layer.\n",
        "\n",
        "Let's train our network for a few epochs to see how well it performs on the training as well as test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvhgQoO8Svw4"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "  model.train()\n",
        "\n",
        "  for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "    out = model(data.x.to(device), data.edge_index.to(device), data.batch.to(device))  # Perform a single forward pass.\n",
        "    loss = criterion(out, data.y.to(device))  # Compute the loss.\n",
        "    if run:\n",
        "      run[\"train/loss\"].append(loss) # log loss to neptune ai\n",
        "      run[\"train/loss-pow-2\"].append(loss**2) # log loss squared to neptune ai\n",
        "    loss.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "    optimizer.zero_grad()  # Clear gradients.\n",
        "\n",
        "def test(loader):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "        out = model(data.x.to(device), data.edge_index.to(device), data.batch.to(device))  \n",
        "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "        del(out)\n",
        "        correct += int((pred.to(device) == data.y.to(device)).sum())  # Check against ground-truth labels.\n",
        "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "78a1364bb69e47bea873812cf28af911",
            "453794b3a39c45b48817f1f86cb48009",
            "1cc4902dbe7f41b68712842e37f73732",
            "fc4ac420aa88448d9d0249bbfdc1e4a4",
            "e86e8f1f263648918a7125b6e99314d8",
            "f28096f88b6d426b83651e645398392d",
            "0cbaf214e01844cdace377de61686e0e",
            "1cbaeb8524994b98915bfec663dbe130",
            "ee136ff149754cc4aba4b1ecde0ae4b8",
            "8adf01a6a6c74e41abe0a9f58a670763",
            "bcdff6d05d024a10aeed5c5cdea83b4f"
          ]
        },
        "id": "ZFEk4BvLygxE",
        "outputId": "620f4407-ad92-4975-a60d-bfe87d85aeb6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78a1364bb69e47bea873812cf28af911",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 2 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 2 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/tjsun009/test-src-classifier/e/TES-44/metadata\n"
          ]
        }
      ],
      "source": [
        "# At least 3 times the number of features\n",
        "pbar = tqdm(range(1, 13))\n",
        "for epoch in pbar:\n",
        "  train()\n",
        "  train_acc = test(train_loader)\n",
        "  test_acc = test(test_loader)\n",
        "  \n",
        "  pbar.set_description(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "  if run:  \n",
        "    # log accuracy to neptune ai\n",
        "    run[\"train/accuracy\"].append(train_acc)\n",
        "    run[\"test/accuracy\"].append(test_acc)\n",
        "\n",
        "if run:\n",
        "  run.stop()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPfYehix7BymH4MX4l9sGwO",
      "collapsed_sections": [
        "NGiAvVTs535v",
        "7mu7WUHAIgQ3"
      ],
      "include_colab_link": true,
      "mount_file_id": "1q-ANjgDr-4UZo4aEyU57OG0B5AEty3Zu",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cbaf214e01844cdace377de61686e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cbaeb8524994b98915bfec663dbe130": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc4902dbe7f41b68712842e37f73732": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cbaeb8524994b98915bfec663dbe130",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee136ff149754cc4aba4b1ecde0ae4b8",
            "value": 12
          }
        },
        "453794b3a39c45b48817f1f86cb48009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28096f88b6d426b83651e645398392d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0cbaf214e01844cdace377de61686e0e",
            "value": "Epoch: 012, Train Acc: 0.9840, Test Acc: 0.9814: 100%"
          }
        },
        "78a1364bb69e47bea873812cf28af911": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_453794b3a39c45b48817f1f86cb48009",
              "IPY_MODEL_1cc4902dbe7f41b68712842e37f73732",
              "IPY_MODEL_fc4ac420aa88448d9d0249bbfdc1e4a4"
            ],
            "layout": "IPY_MODEL_e86e8f1f263648918a7125b6e99314d8"
          }
        },
        "8adf01a6a6c74e41abe0a9f58a670763": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcdff6d05d024a10aeed5c5cdea83b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e86e8f1f263648918a7125b6e99314d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee136ff149754cc4aba4b1ecde0ae4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f28096f88b6d426b83651e645398392d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4ac420aa88448d9d0249bbfdc1e4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8adf01a6a6c74e41abe0a9f58a670763",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bcdff6d05d024a10aeed5c5cdea83b4f",
            "value": " 12/12 [12:48&lt;00:00, 63.72s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
