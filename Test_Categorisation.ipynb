{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XmlJDDgsAygS",
        "MtceTKCtv90g",
        "Ryp_nCHK1tpF",
        "Nx8bR496Oi9n",
        "Lwo1NEv5OnGg",
        "pc7yPRTAyH3h",
        "yHS2iAoovFP1",
        "t5FnQZDp_vWu",
        "jnyjuC7-CW27"
      ],
      "mount_file_id": "1J3-QrijqHd0jsI8uAtQTDWGNkiXTw3sb",
      "authorship_tag": "ABX9TyNpOgnw4lMl/e9H+0/QzOfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TJSun009/University-Projects/blob/main/Test_Categorisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preamble\n",
        "This model is designed to look at categorising unit tests in order to perform downstream tasks (such as mapping test types to certain actions)\n",
        "\n",
        "List of sources used:\n",
        "\n",
        "\n",
        "*   [https://www.geeksforgeeks.org/unit-testing-software-testing](https://www.geeksforgeeks.org/unit-testing-software-testing)\n",
        "*   [https://www.javatpoint.com/unit-testing](https://www.javatpoint.com/unit-testing)\n",
        "*   [https://www.imperva.com/learn/application-security/black-box-testing](https://www.imperva.com/learn/application-security/black-box-testing)\n",
        "*   [https://www.imperva.com/learn/application-security/white-box-testing/](https://www.imperva.com/learn/application-security/white-box-testing/)\n",
        "\n",
        "\n",
        "\n",
        "Broadly speaking documentation  refers to three broad unit test types:\n",
        "\n",
        "\n",
        "* Black Box Testing - Testing a system with no knowledge of its internals\n",
        "    * This involves testing the user interface i.e input and outputs\n",
        "    * **Utility** - checks that the *system as a whole is working* as expected\n",
        "    * Example: \n",
        "        * checking that it is possible to log in using correct user credentials, and not possible to log in using wrong credentials.\n",
        "    * Includes checking:\n",
        "        * input/output **formats** (length and REGEX)\n",
        "        * **boundary** values\n",
        "* White Box Testing - Testing a system with knowledge of internals (source code, documentation etc.)\n",
        "    * This involves testing behaviour of the system from developer perspective\n",
        "    * **Utility** - can uncover structural problems, hidden errors and problems with specific components; ensures code is comprehensively covered\n",
        "    * Example:\n",
        "        * \n",
        "    * Includes checking:\n",
        "        * **security vulnerabilities**\n",
        "        * **loop testing**\n",
        "        * **types**\n",
        "        * **data flow**\n",
        "        * **control flow** - order of execution\n",
        "    * Code coverage Techniques:\n",
        "        * **branch coverage**\n",
        "        * **statement coverage**\n",
        "        * **path coverage** - looking at executed code paths and their relevance\n",
        "* Gray Box Testing - Testing with partial knowledge of the system's internals\n",
        "    * It's a combination of White and Gray Box Testing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VDK45Gxu6gBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assumptions\n",
        "Given that we will be using the source code we can assume our tests will either be White or Grey Box\n",
        "\n",
        "The most common tests expected to come up are:\n",
        "\n",
        "* Bounds Testing\n",
        "* Branching Statements\n",
        "* Loop Testing\n",
        "* Format\n",
        "* Error\n",
        "\n",
        "The basic things that will be checked are:\n",
        "* Return type\n",
        "* Return length\n",
        "* Function calls\n",
        "* Exception raised\n",
        "\n"
      ],
      "metadata": {
        "id": "KnDFxhm5D4UM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 1"
      ],
      "metadata": {
        "id": "AjHpv5AIgsJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll work with the pyUnittest_Tutorial which provides source code and tests for a simple calculator\n",
        "\n",
        "Our work assumes both the code and tests are correct and functioning"
      ],
      "metadata": {
        "id": "fwKTOKKhgymL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start with two generic labels"
      ],
      "metadata": {
        "id": "UsIVSyDXgM5H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i6bZgsD6ZqQ"
      },
      "outputs": [],
      "source": [
        "labels = [\"valid\", \"invalid\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Test File"
      ],
      "metadata": {
        "id": "XmlJDDgsAygS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Teatoller/pyUnittest_Tutorial.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J14bdkFzAt7z",
        "outputId": "f778e98d-ec22-4e23-d1ac-debe337935d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pyUnittest_Tutorial'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Total 27 (delta 0), reused 0 (delta 0), pack-reused 27\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "bgjOkMrriB-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph generator Setup"
      ],
      "metadata": {
        "id": "7r6xILtEw08A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Git Config\n",
        "import getpass\n",
        "!git config --global user.email \"emmanuelo009.oe@gmail.com\"\n",
        "!git config --global user.name \"TJSun009\"\n",
        "\n",
        "TARGET_DIR = \"/content/typilus\"\n",
        "BRANCH_NAME = \"time.clock-bugfix\"\n",
        "ACCESS_TOKEN = getpass.getpass()\n",
        "REMOTE = f\"https://{ACCESS_TOKEN}@github.com/TJSun009/typilus.git\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj5PGb5Zw0UF",
        "outputId": "63d3dbe5-306c-476a-b493-774025876e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Typilus Forked Bugfix Branch\n",
        "\n",
        "!git clone https://github.com/TJSun009/typilus.git\n",
        "\n",
        "!(cd {TARGET_DIR}/; \\\n",
        "git pull {REMOTE} {BRANCH_NAME}; \\\n",
        "git checkout {BRANCH_NAME})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "MzdqNk1DxAXx",
        "outputId": "960d274b-c93f-4488-e17e-d23bda759421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'typilus'...\n",
            "remote: Enumerating objects: 161, done.\u001b[K\n",
            "remote: Counting objects: 100% (161/161), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 161 (delta 41), reused 118 (delta 20), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (161/161), 162.54 KiB | 3.19 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "From https://github.com/TJSun009/typilus\n",
            " * branch            time.clock-bugfix -> FETCH_HEAD\n",
            "Updating 69c377b..1467053\n",
            "Fast-forward\n",
            " src/data_preparation/scripts/graph_generator/extract_graphs.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n",
            "Branch 'time.clock-bugfix' set up to track remote branch 'time.clock-bugfix' from 'origin'.\n",
            "Switched to a new branch 'time.clock-bugfix'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Add to Path\n",
        "import sys\n",
        "\n",
        "GRAPH_GENERATOR_PATH = \"/content/typilus/src/data_preparation/scripts/graph_generator\"\n",
        "\n",
        "#change graphgenerator to module\n",
        "!touch {GRAPH_GENERATOR_PATH}/__init__.py\n",
        "\n",
        "SRC_FOLDER = \"/content/pyUnittest_Tutorial/\"\n",
        "TYPING_RULES_PATH = \"/content/typilus/src/data_preparation/metadata/typingRules.json\"\n",
        "CORPUS_DUPLICATES = \"/content/drive/MyDrive/Year 3/Dissertation/Projects/corpus_duplicates.json\"\n",
        "\n",
        "if (GRAPH_GENERATOR_PATH not in sys.path):\n",
        "  sys.path.append(f\"{GRAPH_GENERATOR_PATH}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Nd19KhTWxM3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph generator Functions"
      ],
      "metadata": {
        "id": "MtceTKCtv90g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqqq dpu_utils typed_ast\n",
        "import extract_graphs, os, gzip, json\n",
        "\n",
        "\n",
        "def generate_graphs(src, dest = 0):\n",
        "  dest = src if dest == 0 else dest\n",
        "  extract_graphs.main({\n",
        "      \"SOURCE_FOLDER\": src,\n",
        "      \"SAVE_FOLDER\": dest,\n",
        "      \"TYPING_RULES\": TYPING_RULES_PATH,\n",
        "      \"DUPLICATES_JSON\": CORPUS_DUPLICATES\n",
        "  })\n",
        "\n",
        "def graphToJson(file):\n",
        "  json_content = []\n",
        "  with gzip.open(file) as f:\n",
        "    for line in f:\n",
        "      line = line.rstrip()\n",
        "      if line:\n",
        "        obj = json.loads(line)\n",
        "        json_content.append(obj)\n",
        "  return json_content"
      ],
      "metadata": {
        "id": "ehTcAiACv7hB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc43486-3ee4-4573-db5f-23846f53b3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 73 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 897 kB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 135 kB 71.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 383 kB 64.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 65.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 67.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 172 kB 74.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 744 kB/s \n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC = \"/content/pyUnittest_Tutorial\"\n",
        "\n",
        "generate_graphs(SRC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4PANUlBiGjD",
        "outputId": "ddddb7d8-5a7f-429c-b172-2496c45fa462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exploring folders ...\n",
            "/content/pyUnittest_Tutorial/app/ __init__.py\n",
            "/content/pyUnittest_Tutorial/app/calculator.py\n",
            "/content/pyUnittest_Tutorial/test/__init__.py\n",
            "/content/pyUnittest_Tutorial/test/test_calculator.py\n",
            "Building and saving the type graph...\n",
            "Building type graph for project... (0 elements to process)\n",
            "Done building type graph\n",
            "Done.\n",
            "Generated 4 graphs out of 4 snippets\n",
            "\n",
            "Execution in:  0.09160692000000026  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = graphToJson(\"/content/pyUnittest_Tutorial/all-graphs000.jsonl.gz\")"
      ],
      "metadata": {
        "id": "ybVAOboF0bv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Test by Function"
      ],
      "metadata": {
        "id": "Ryp_nCHK1tpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Imports and setUp files will be needed in the \n",
        "\n"
      ],
      "metadata": {
        "id": "mftXIDlC_TSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast, astunparse, pathlib\n",
        "from re import sub\n",
        "# for visual debug\n",
        "# !pip install -Uqqq pprintast\n",
        "# from pprintast import pprintast as ppast\n",
        "\n",
        "def flatten(ls):\n",
        "  return [item for l in ls for item in l]\n",
        "\n",
        "\n",
        "def title_case(s):\n",
        "  s = sub(r\"(_|-)+\", \" \", s).title().replace(\" \", \"\")\n",
        "  return ''.join([s[0].upper(), s[1:]])\n",
        "\n",
        "def split_tests(src_folder, dest_folder = \"./\"):\n",
        "  src_folder = pathlib.Path(src_folder)\n",
        "\n",
        "  matches = [src_folder.glob(\"**/test_*.py\"), src_folder.glob(\"**/*_test.py\")]\n",
        "  matches = flatten(matches)\n",
        "  \n",
        "  imports = []\n",
        "  functions = {}\n",
        "  \n",
        "  for file in matches:\n",
        "    \n",
        "    with open(file, 'r') as f:\n",
        "      code = f.read()\n",
        "      head = ast.parse(code)\n",
        "      for node in ast.walk(head):\n",
        "        try:\n",
        "          for x in node.body:\n",
        "            if (isinstance(x, ast.Import) or isinstance(x, ast.ImportFrom)):\n",
        "              imports.append(x)\n",
        "            elif isinstance(x, ast.FunctionDef):\n",
        "              functions[x.name] = x\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for _,func in functions.items():\n",
        "    # ignore setup file\n",
        "    if(_ != \"setUp\"):\n",
        "      test_file_head = ast.Module(body = [])\n",
        "      # add imports\n",
        "      for i in imports:\n",
        "        test_file_head.body.append(i)\n",
        "      \n",
        "      className = title_case(file.name.replace(\".py\", ''))\n",
        "\n",
        "      # add class definition and setup and test functions\n",
        "      test_file_head.body.append(\n",
        "          ast.ClassDef(\n",
        "              f\"{className}{count}\",\n",
        "              [ast.Name(id='unittest.TestCase', ctx=ast.Load())],\n",
        "              keywords = [],# add \n",
        "              body = [\n",
        "                  functions[\"setUp\"],\n",
        "                  func\n",
        "                  ],\n",
        "              decorator_list = []\n",
        "          )\n",
        "      )\n",
        "\n",
        "      # create a folder where the files can go\n",
        "      dest_path = pathlib.Path(dest_folder, file.name.replace(\".py\", ''))\n",
        "      dest_path.mkdir(parents = True, exist_ok = True) \n",
        "\n",
        "      # files are distinguished by their parent folder and each function by a counter\n",
        "      with open(pathlib.Path(dest_path, f\"{count}.py\"), 'w') as f:\n",
        "        code = astunparse.unparse(test_file_head)\n",
        "        f.write(code)\n",
        "\n",
        "      count+=1"
      ],
      "metadata": {
        "id": "R8Ba5S-K1zoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do split tests"
      ],
      "metadata": {
        "id": "Nx8bR496Oi9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT_TEST_DEST = \"/content/split_tests/\""
      ],
      "metadata": {
        "id": "xSd9G53A_E3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_tests(SRC, SPLIT_TEST_DEST)"
      ],
      "metadata": {
        "id": "xg9POBmlNBM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Graphs"
      ],
      "metadata": {
        "id": "Lwo1NEv5OnGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_graphs(\"/content/split_tests/test_calculator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tkOfLMTOr5P",
        "outputId": "0da75306-8d9b-412d-e283-e09278e1ffeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exploring folders ...\n",
            "/content/split_tests/test_calculator/1.py\n",
            "/content/split_tests/test_calculator/3.py\n",
            "/content/split_tests/test_calculator/2.py\n",
            "/content/split_tests/test_calculator/0.py\n",
            "Building and saving the type graph...\n",
            "Building type graph for project... (0 elements to process)\n",
            "Done building type graph\n",
            "Done.\n",
            "Generated 4 graphs out of 4 snippets\n",
            "\n",
            "Execution in:  0.03364505399999995  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graphToJson(\"/content/split_tests/test_calculator/all-graphs000.jsonl.gz\")\n",
        "# graphToJson(\"/content/split_tests/test_calculator/_type_lattice.json.gz\")\n",
        "# print(example)\n",
        "# print(f\"nodes length = {len(set(example[0]['nodes']))}, token lengths = {len(example[0]['token-sequence'])}\")"
      ],
      "metadata": {
        "id": "orEoDnP4O6Pv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce421df-fd6f-4102-944c-d7f06fd001f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'nodes': ['Module',\n",
              "   'Import',\n",
              "   'alias',\n",
              "   'ImportFrom',\n",
              "   'ClassDef',\n",
              "   'class',\n",
              "   'TestCalculator1',\n",
              "   '(',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'unittest',\n",
              "   'unittest',\n",
              "   '.',\n",
              "   'TestCase',\n",
              "   'unittest.TestCase',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'FunctionDef',\n",
              "   'def',\n",
              "   'setUp',\n",
              "   'setUp',\n",
              "   '(',\n",
              "   'arguments',\n",
              "   'arg',\n",
              "   'self',\n",
              "   'self',\n",
              "   ',',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'Assign',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'calc',\n",
              "   'Attribute',\n",
              "   'self.calc',\n",
              "   'Call',\n",
              "   '=',\n",
              "   'Name',\n",
              "   'Calculator',\n",
              "   'Calculator',\n",
              "   '(',\n",
              "   ')',\n",
              "   '<DEDENT>',\n",
              "   '<NL>',\n",
              "   'FunctionDef',\n",
              "   'def',\n",
              "   'test_calculator_returns_error_message_if_both_args_not_numbers',\n",
              "   'test_calculator_returns_error_message_if_both_args_not_numbers',\n",
              "   '(',\n",
              "   'arguments',\n",
              "   'arg',\n",
              "   'self',\n",
              "   'self',\n",
              "   ',',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'Expr',\n",
              "   'Call',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'assertRaises',\n",
              "   'self.assertRaises',\n",
              "   '(',\n",
              "   'Name',\n",
              "   'ValueError',\n",
              "   'ValueError',\n",
              "   ',',\n",
              "   'Attribute',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'calc',\n",
              "   '.',\n",
              "   'add',\n",
              "   'self.calc.add',\n",
              "   ',',\n",
              "   'Str',\n",
              "   'two',\n",
              "   ',',\n",
              "   'Str',\n",
              "   'three',\n",
              "   ')',\n",
              "   '<DEDENT>',\n",
              "   '<DEDENT>',\n",
              "   'calc',\n",
              "   'self',\n",
              "   'test',\n",
              "   'calculator',\n",
              "   'returns',\n",
              "   'error',\n",
              "   'message',\n",
              "   'if',\n",
              "   'both',\n",
              "   'args',\n",
              "   'not',\n",
              "   'numbers',\n",
              "   'assert',\n",
              "   'raises',\n",
              "   'set',\n",
              "   'up',\n",
              "   'case',\n",
              "   'add',\n",
              "   '1',\n",
              "   'value',\n",
              "   'unittest'],\n",
              "  'edges': {'CHILD': {'0': [1, 3, 4],\n",
              "    '1': [2],\n",
              "    '4': [5, 6, 7, 8, 44, 45, 15, 16, 17, 87],\n",
              "    '8': [9, 12, 13],\n",
              "    '9': [10],\n",
              "    '17': [43, 18, 19, 21, 22, 27, 28, 29],\n",
              "    '22': [26, 23],\n",
              "    '23': [24],\n",
              "    '29': [32, 33, 36, 37, 30],\n",
              "    '30': [31],\n",
              "    '36': [41, 42, 38],\n",
              "    '38': [39],\n",
              "    '45': [46, 47, 49, 50, 86, 55, 56, 57],\n",
              "    '50': [51, 54],\n",
              "    '51': [52],\n",
              "    '57': [58],\n",
              "    '58': [65, 66, 69, 70, 79, 80, 82, 83, 85, 59],\n",
              "    '59': [60, 62, 63],\n",
              "    '60': [61],\n",
              "    '66': [67],\n",
              "    '70': [76, 77, 71],\n",
              "    '71': [72, 74, 75],\n",
              "    '72': [73],\n",
              "    '80': [81],\n",
              "    '83': [84]},\n",
              "   'NEXT': {'5': [6],\n",
              "    '6': [7],\n",
              "    '7': [10],\n",
              "    '10': [12],\n",
              "    '12': [13],\n",
              "    '13': [15],\n",
              "    '15': [16],\n",
              "    '16': [18],\n",
              "    '18': [19],\n",
              "    '19': [21],\n",
              "    '21': [24],\n",
              "    '24': [26],\n",
              "    '26': [27],\n",
              "    '27': [28],\n",
              "    '28': [31],\n",
              "    '31': [32],\n",
              "    '32': [33],\n",
              "    '33': [37],\n",
              "    '37': [39],\n",
              "    '39': [41],\n",
              "    '41': [42],\n",
              "    '42': [43],\n",
              "    '43': [44],\n",
              "    '44': [46],\n",
              "    '46': [47],\n",
              "    '47': [49],\n",
              "    '49': [52],\n",
              "    '52': [54],\n",
              "    '54': [55],\n",
              "    '55': [56],\n",
              "    '56': [61],\n",
              "    '61': [62],\n",
              "    '62': [63],\n",
              "    '63': [65],\n",
              "    '65': [67],\n",
              "    '67': [69],\n",
              "    '69': [73],\n",
              "    '73': [74],\n",
              "    '74': [75],\n",
              "    '75': [76],\n",
              "    '76': [77],\n",
              "    '77': [79],\n",
              "    '79': [81],\n",
              "    '81': [82],\n",
              "    '82': [84],\n",
              "    '84': [85],\n",
              "    '85': [86],\n",
              "    '17': [45],\n",
              "    '86': [87]},\n",
              "   'LAST_LEXICAL_USE': {'24': [31], '52': [61], '61': [73], '34': [71]},\n",
              "   'NEXT_USE': {'52': [61], '61': [73]},\n",
              "   'COMPUTED_FROM': {'34': [36]},\n",
              "   'OCCURRENCE_OF': {'10': [11],\n",
              "    '8': [14],\n",
              "    '19': [20],\n",
              "    '24': [25],\n",
              "    '31': [25],\n",
              "    '34': [35],\n",
              "    '39': [40],\n",
              "    '47': [48],\n",
              "    '52': [53],\n",
              "    '61': [53],\n",
              "    '59': [64],\n",
              "    '67': [68],\n",
              "    '73': [53],\n",
              "    '71': [35],\n",
              "    '70': [78]},\n",
              "   'SUBTOKEN_OF': {'88': [33, 75],\n",
              "    '89': [73, 52, 24, 61, 31],\n",
              "    '90': [13, 6, 47],\n",
              "    '91': [39, 6, 47],\n",
              "    '92': [47],\n",
              "    '93': [67, 47],\n",
              "    '94': [47],\n",
              "    '95': [47],\n",
              "    '96': [47],\n",
              "    '97': [47],\n",
              "    '98': [47],\n",
              "    '99': [47],\n",
              "    '100': [63],\n",
              "    '101': [63],\n",
              "    '102': [19],\n",
              "    '103': [19],\n",
              "    '104': [13],\n",
              "    '105': [77],\n",
              "    '106': [6],\n",
              "    '107': [67],\n",
              "    '108': [10]}},\n",
              "  'token-sequence': [5,\n",
              "   6,\n",
              "   7,\n",
              "   10,\n",
              "   12,\n",
              "   13,\n",
              "   15,\n",
              "   16,\n",
              "   18,\n",
              "   19,\n",
              "   21,\n",
              "   24,\n",
              "   26,\n",
              "   27,\n",
              "   28,\n",
              "   31,\n",
              "   32,\n",
              "   33,\n",
              "   37,\n",
              "   39,\n",
              "   41,\n",
              "   42,\n",
              "   43,\n",
              "   44,\n",
              "   46,\n",
              "   47,\n",
              "   49,\n",
              "   52,\n",
              "   54,\n",
              "   55,\n",
              "   56,\n",
              "   61,\n",
              "   62,\n",
              "   63,\n",
              "   65,\n",
              "   67,\n",
              "   69,\n",
              "   73,\n",
              "   74,\n",
              "   75,\n",
              "   76,\n",
              "   77,\n",
              "   79,\n",
              "   81,\n",
              "   82,\n",
              "   84,\n",
              "   85,\n",
              "   86,\n",
              "   87],\n",
              "  'supernodes': {'20': {'name': 'setUp',\n",
              "    'annotation': None,\n",
              "    'location': [7, 4],\n",
              "    'type': 'class-or-function'},\n",
              "   '35': {'name': 'self.calc',\n",
              "    'annotation': None,\n",
              "    'location': [8, 8],\n",
              "    'type': 'variable'},\n",
              "   '48': {'name': 'test_calculator_returns_error_message_if_both_args_not_numbers',\n",
              "    'annotation': None,\n",
              "    'location': [10, 4],\n",
              "    'type': 'class-or-function'}},\n",
              "  'filename': '/1.py'},\n",
              " {'nodes': ['Module',\n",
              "   'Import',\n",
              "   'alias',\n",
              "   'ImportFrom',\n",
              "   'ClassDef',\n",
              "   'class',\n",
              "   'TestCalculator3',\n",
              "   '(',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'unittest',\n",
              "   'unittest',\n",
              "   '.',\n",
              "   'TestCase',\n",
              "   'unittest.TestCase',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'FunctionDef',\n",
              "   'def',\n",
              "   'setUp',\n",
              "   'setUp',\n",
              "   '(',\n",
              "   'arguments',\n",
              "   'arg',\n",
              "   'self',\n",
              "   'self',\n",
              "   ',',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'Assign',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'calc',\n",
              "   'Attribute',\n",
              "   'self.calc',\n",
              "   'Call',\n",
              "   '=',\n",
              "   'Name',\n",
              "   'Calculator',\n",
              "   'Calculator',\n",
              "   '(',\n",
              "   ')',\n",
              "   '<DEDENT>',\n",
              "   '<NL>',\n",
              "   'FunctionDef',\n",
              "   'def',\n",
              "   'test_calculator_returns_error_message_if_y_args_not_number',\n",
              "   'test_calculator_returns_error_message_if_y_args_not_number',\n",
              "   '(',\n",
              "   'arguments',\n",
              "   'arg',\n",
              "   'self',\n",
              "   'self',\n",
              "   ',',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'Expr',\n",
              "   'Call',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'assertRaises',\n",
              "   'self.assertRaises',\n",
              "   '(',\n",
              "   'Name',\n",
              "   'ValueError',\n",
              "   'ValueError',\n",
              "   ',',\n",
              "   'Attribute',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'calc',\n",
              "   '.',\n",
              "   'add',\n",
              "   'self.calc.add',\n",
              "   ',',\n",
              "   'Num',\n",
              "   '2',\n",
              "   ',',\n",
              "   'Str',\n",
              "   'three',\n",
              "   ')',\n",
              "   '<DEDENT>',\n",
              "   '<DEDENT>',\n",
              "   'self',\n",
              "   'assert',\n",
              "   'raises',\n",
              "   'unittest',\n",
              "   'add',\n",
              "   'test',\n",
              "   'calculator',\n",
              "   '3',\n",
              "   'case',\n",
              "   'set',\n",
              "   'up',\n",
              "   'returns',\n",
              "   'error',\n",
              "   'message',\n",
              "   'if',\n",
              "   'y',\n",
              "   'args',\n",
              "   'not',\n",
              "   'number',\n",
              "   'calc',\n",
              "   'value'],\n",
              "  'edges': {'CHILD': {'0': [1, 3, 4],\n",
              "    '1': [2],\n",
              "    '4': [5, 6, 7, 8, 44, 45, 15, 16, 17, 87],\n",
              "    '8': [9, 12, 13],\n",
              "    '9': [10],\n",
              "    '17': [43, 18, 19, 21, 22, 27, 28, 29],\n",
              "    '22': [26, 23],\n",
              "    '23': [24],\n",
              "    '29': [32, 33, 36, 37, 30],\n",
              "    '30': [31],\n",
              "    '36': [41, 42, 38],\n",
              "    '38': [39],\n",
              "    '45': [46, 47, 49, 50, 86, 55, 56, 57],\n",
              "    '50': [51, 54],\n",
              "    '51': [52],\n",
              "    '57': [58],\n",
              "    '58': [65, 66, 69, 70, 79, 80, 82, 83, 85, 59],\n",
              "    '59': [60, 62, 63],\n",
              "    '60': [61],\n",
              "    '66': [67],\n",
              "    '70': [76, 77, 71],\n",
              "    '71': [72, 74, 75],\n",
              "    '72': [73],\n",
              "    '80': [81],\n",
              "    '83': [84]},\n",
              "   'NEXT': {'5': [6],\n",
              "    '6': [7],\n",
              "    '7': [10],\n",
              "    '10': [12],\n",
              "    '12': [13],\n",
              "    '13': [15],\n",
              "    '15': [16],\n",
              "    '16': [18],\n",
              "    '18': [19],\n",
              "    '19': [21],\n",
              "    '21': [24],\n",
              "    '24': [26],\n",
              "    '26': [27],\n",
              "    '27': [28],\n",
              "    '28': [31],\n",
              "    '31': [32],\n",
              "    '32': [33],\n",
              "    '33': [37],\n",
              "    '37': [39],\n",
              "    '39': [41],\n",
              "    '41': [42],\n",
              "    '42': [43],\n",
              "    '43': [44],\n",
              "    '44': [46],\n",
              "    '46': [47],\n",
              "    '47': [49],\n",
              "    '49': [52],\n",
              "    '52': [54],\n",
              "    '54': [55],\n",
              "    '55': [56],\n",
              "    '56': [61],\n",
              "    '61': [62],\n",
              "    '62': [63],\n",
              "    '63': [65],\n",
              "    '65': [67],\n",
              "    '67': [69],\n",
              "    '69': [73],\n",
              "    '73': [74],\n",
              "    '74': [75],\n",
              "    '75': [76],\n",
              "    '76': [77],\n",
              "    '77': [79],\n",
              "    '79': [81],\n",
              "    '81': [82],\n",
              "    '82': [84],\n",
              "    '84': [85],\n",
              "    '85': [86],\n",
              "    '17': [45],\n",
              "    '86': [87]},\n",
              "   'LAST_LEXICAL_USE': {'24': [31], '52': [61], '61': [73], '34': [71]},\n",
              "   'NEXT_USE': {'52': [61], '61': [73]},\n",
              "   'COMPUTED_FROM': {'34': [36]},\n",
              "   'OCCURRENCE_OF': {'10': [11],\n",
              "    '8': [14],\n",
              "    '19': [20],\n",
              "    '24': [25],\n",
              "    '31': [25],\n",
              "    '34': [35],\n",
              "    '39': [40],\n",
              "    '47': [48],\n",
              "    '52': [53],\n",
              "    '61': [53],\n",
              "    '59': [64],\n",
              "    '67': [68],\n",
              "    '73': [53],\n",
              "    '71': [35],\n",
              "    '70': [78]},\n",
              "   'SUBTOKEN_OF': {'88': [73, 52, 24, 61, 31],\n",
              "    '89': [63],\n",
              "    '90': [63],\n",
              "    '91': [10],\n",
              "    '92': [77],\n",
              "    '93': [13, 6, 47],\n",
              "    '94': [47, 6, 39],\n",
              "    '95': [6],\n",
              "    '96': [13],\n",
              "    '97': [19],\n",
              "    '98': [19],\n",
              "    '99': [47],\n",
              "    '100': [67, 47],\n",
              "    '101': [47],\n",
              "    '102': [47],\n",
              "    '103': [47],\n",
              "    '104': [47],\n",
              "    '105': [47],\n",
              "    '106': [47],\n",
              "    '107': [33, 75],\n",
              "    '108': [67]}},\n",
              "  'token-sequence': [5,\n",
              "   6,\n",
              "   7,\n",
              "   10,\n",
              "   12,\n",
              "   13,\n",
              "   15,\n",
              "   16,\n",
              "   18,\n",
              "   19,\n",
              "   21,\n",
              "   24,\n",
              "   26,\n",
              "   27,\n",
              "   28,\n",
              "   31,\n",
              "   32,\n",
              "   33,\n",
              "   37,\n",
              "   39,\n",
              "   41,\n",
              "   42,\n",
              "   43,\n",
              "   44,\n",
              "   46,\n",
              "   47,\n",
              "   49,\n",
              "   52,\n",
              "   54,\n",
              "   55,\n",
              "   56,\n",
              "   61,\n",
              "   62,\n",
              "   63,\n",
              "   65,\n",
              "   67,\n",
              "   69,\n",
              "   73,\n",
              "   74,\n",
              "   75,\n",
              "   76,\n",
              "   77,\n",
              "   79,\n",
              "   81,\n",
              "   82,\n",
              "   84,\n",
              "   85,\n",
              "   86,\n",
              "   87],\n",
              "  'supernodes': {'20': {'name': 'setUp',\n",
              "    'annotation': None,\n",
              "    'location': [7, 4],\n",
              "    'type': 'class-or-function'},\n",
              "   '35': {'name': 'self.calc',\n",
              "    'annotation': None,\n",
              "    'location': [8, 8],\n",
              "    'type': 'variable'},\n",
              "   '48': {'name': 'test_calculator_returns_error_message_if_y_args_not_number',\n",
              "    'annotation': None,\n",
              "    'location': [10, 4],\n",
              "    'type': 'class-or-function'}},\n",
              "  'filename': '/3.py'},\n",
              " {'nodes': ['Module',\n",
              "   'Import',\n",
              "   'alias',\n",
              "   'ImportFrom',\n",
              "   'ClassDef',\n",
              "   'class',\n",
              "   'TestCalculator2',\n",
              "   '(',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'unittest',\n",
              "   'unittest',\n",
              "   '.',\n",
              "   'TestCase',\n",
              "   'unittest.TestCase',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'FunctionDef',\n",
              "   'def',\n",
              "   'setUp',\n",
              "   'setUp',\n",
              "   '(',\n",
              "   'arguments',\n",
              "   'arg',\n",
              "   'self',\n",
              "   'self',\n",
              "   ',',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'Assign',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'calc',\n",
              "   'Attribute',\n",
              "   'self.calc',\n",
              "   'Call',\n",
              "   '=',\n",
              "   'Name',\n",
              "   'Calculator',\n",
              "   'Calculator',\n",
              "   '(',\n",
              "   ')',\n",
              "   '<DEDENT>',\n",
              "   '<NL>',\n",
              "   'FunctionDef',\n",
              "   'def',\n",
              "   'test_calculator_returns_error_message_if_x_args_not_number',\n",
              "   'test_calculator_returns_error_message_if_x_args_not_number',\n",
              "   '(',\n",
              "   'arguments',\n",
              "   'arg',\n",
              "   'self',\n",
              "   'self',\n",
              "   ',',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'Expr',\n",
              "   'Call',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'assertRaises',\n",
              "   'self.assertRaises',\n",
              "   '(',\n",
              "   'Name',\n",
              "   'ValueError',\n",
              "   'ValueError',\n",
              "   ',',\n",
              "   'Attribute',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'calc',\n",
              "   '.',\n",
              "   'add',\n",
              "   'self.calc.add',\n",
              "   ',',\n",
              "   'Str',\n",
              "   'two',\n",
              "   ',',\n",
              "   'Num',\n",
              "   '3',\n",
              "   ')',\n",
              "   '<DEDENT>',\n",
              "   '<DEDENT>',\n",
              "   'test',\n",
              "   'calculator',\n",
              "   '2',\n",
              "   'assert',\n",
              "   'raises',\n",
              "   'calc',\n",
              "   'self',\n",
              "   'case',\n",
              "   'unittest',\n",
              "   'value',\n",
              "   'error',\n",
              "   'add',\n",
              "   'returns',\n",
              "   'message',\n",
              "   'if',\n",
              "   'x',\n",
              "   'args',\n",
              "   'not',\n",
              "   'number',\n",
              "   'set',\n",
              "   'up'],\n",
              "  'edges': {'CHILD': {'0': [1, 3, 4],\n",
              "    '1': [2],\n",
              "    '4': [5, 6, 7, 8, 44, 45, 15, 16, 17, 87],\n",
              "    '8': [9, 12, 13],\n",
              "    '9': [10],\n",
              "    '17': [43, 18, 19, 21, 22, 27, 28, 29],\n",
              "    '22': [26, 23],\n",
              "    '23': [24],\n",
              "    '29': [32, 33, 36, 37, 30],\n",
              "    '30': [31],\n",
              "    '36': [41, 42, 38],\n",
              "    '38': [39],\n",
              "    '45': [46, 47, 49, 50, 86, 55, 56, 57],\n",
              "    '50': [51, 54],\n",
              "    '51': [52],\n",
              "    '57': [58],\n",
              "    '58': [65, 66, 69, 70, 79, 80, 82, 83, 85, 59],\n",
              "    '59': [60, 62, 63],\n",
              "    '60': [61],\n",
              "    '66': [67],\n",
              "    '70': [76, 77, 71],\n",
              "    '71': [72, 74, 75],\n",
              "    '72': [73],\n",
              "    '80': [81],\n",
              "    '83': [84]},\n",
              "   'NEXT': {'5': [6],\n",
              "    '6': [7],\n",
              "    '7': [10],\n",
              "    '10': [12],\n",
              "    '12': [13],\n",
              "    '13': [15],\n",
              "    '15': [16],\n",
              "    '16': [18],\n",
              "    '18': [19],\n",
              "    '19': [21],\n",
              "    '21': [24],\n",
              "    '24': [26],\n",
              "    '26': [27],\n",
              "    '27': [28],\n",
              "    '28': [31],\n",
              "    '31': [32],\n",
              "    '32': [33],\n",
              "    '33': [37],\n",
              "    '37': [39],\n",
              "    '39': [41],\n",
              "    '41': [42],\n",
              "    '42': [43],\n",
              "    '43': [44],\n",
              "    '44': [46],\n",
              "    '46': [47],\n",
              "    '47': [49],\n",
              "    '49': [52],\n",
              "    '52': [54],\n",
              "    '54': [55],\n",
              "    '55': [56],\n",
              "    '56': [61],\n",
              "    '61': [62],\n",
              "    '62': [63],\n",
              "    '63': [65],\n",
              "    '65': [67],\n",
              "    '67': [69],\n",
              "    '69': [73],\n",
              "    '73': [74],\n",
              "    '74': [75],\n",
              "    '75': [76],\n",
              "    '76': [77],\n",
              "    '77': [79],\n",
              "    '79': [81],\n",
              "    '81': [82],\n",
              "    '82': [84],\n",
              "    '84': [85],\n",
              "    '85': [86],\n",
              "    '17': [45],\n",
              "    '86': [87]},\n",
              "   'LAST_LEXICAL_USE': {'24': [31], '52': [61], '61': [73], '34': [71]},\n",
              "   'NEXT_USE': {'52': [61], '61': [73]},\n",
              "   'COMPUTED_FROM': {'34': [36]},\n",
              "   'OCCURRENCE_OF': {'10': [11],\n",
              "    '8': [14],\n",
              "    '19': [20],\n",
              "    '24': [25],\n",
              "    '31': [25],\n",
              "    '34': [35],\n",
              "    '39': [40],\n",
              "    '47': [48],\n",
              "    '52': [53],\n",
              "    '61': [53],\n",
              "    '59': [64],\n",
              "    '67': [68],\n",
              "    '73': [53],\n",
              "    '71': [35],\n",
              "    '70': [78]},\n",
              "   'SUBTOKEN_OF': {'88': [13, 6, 47],\n",
              "    '89': [47, 6, 39],\n",
              "    '90': [6],\n",
              "    '91': [63],\n",
              "    '92': [63],\n",
              "    '93': [33, 75],\n",
              "    '94': [73, 52, 24, 61, 31],\n",
              "    '95': [13],\n",
              "    '96': [10],\n",
              "    '97': [67],\n",
              "    '98': [67, 47],\n",
              "    '99': [77],\n",
              "    '100': [47],\n",
              "    '101': [47],\n",
              "    '102': [47],\n",
              "    '103': [47],\n",
              "    '104': [47],\n",
              "    '105': [47],\n",
              "    '106': [47],\n",
              "    '107': [19],\n",
              "    '108': [19]}},\n",
              "  'token-sequence': [5,\n",
              "   6,\n",
              "   7,\n",
              "   10,\n",
              "   12,\n",
              "   13,\n",
              "   15,\n",
              "   16,\n",
              "   18,\n",
              "   19,\n",
              "   21,\n",
              "   24,\n",
              "   26,\n",
              "   27,\n",
              "   28,\n",
              "   31,\n",
              "   32,\n",
              "   33,\n",
              "   37,\n",
              "   39,\n",
              "   41,\n",
              "   42,\n",
              "   43,\n",
              "   44,\n",
              "   46,\n",
              "   47,\n",
              "   49,\n",
              "   52,\n",
              "   54,\n",
              "   55,\n",
              "   56,\n",
              "   61,\n",
              "   62,\n",
              "   63,\n",
              "   65,\n",
              "   67,\n",
              "   69,\n",
              "   73,\n",
              "   74,\n",
              "   75,\n",
              "   76,\n",
              "   77,\n",
              "   79,\n",
              "   81,\n",
              "   82,\n",
              "   84,\n",
              "   85,\n",
              "   86,\n",
              "   87],\n",
              "  'supernodes': {'20': {'name': 'setUp',\n",
              "    'annotation': None,\n",
              "    'location': [7, 4],\n",
              "    'type': 'class-or-function'},\n",
              "   '35': {'name': 'self.calc',\n",
              "    'annotation': None,\n",
              "    'location': [8, 8],\n",
              "    'type': 'variable'},\n",
              "   '48': {'name': 'test_calculator_returns_error_message_if_x_args_not_number',\n",
              "    'annotation': None,\n",
              "    'location': [10, 4],\n",
              "    'type': 'class-or-function'}},\n",
              "  'filename': '/2.py'},\n",
              " {'nodes': ['Module',\n",
              "   'Import',\n",
              "   'alias',\n",
              "   'ImportFrom',\n",
              "   'ClassDef',\n",
              "   'class',\n",
              "   'TestCalculator0',\n",
              "   '(',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'unittest',\n",
              "   'unittest',\n",
              "   '.',\n",
              "   'TestCase',\n",
              "   'unittest.TestCase',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'FunctionDef',\n",
              "   'def',\n",
              "   'setUp',\n",
              "   'setUp',\n",
              "   '(',\n",
              "   'arguments',\n",
              "   'arg',\n",
              "   'self',\n",
              "   'self',\n",
              "   ',',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'Assign',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'calc',\n",
              "   'Attribute',\n",
              "   'self.calc',\n",
              "   'Call',\n",
              "   '=',\n",
              "   'Name',\n",
              "   'Calculator',\n",
              "   'Calculator',\n",
              "   '(',\n",
              "   ')',\n",
              "   '<DEDENT>',\n",
              "   '<NL>',\n",
              "   'FunctionDef',\n",
              "   'def',\n",
              "   'test_calculator_add_method_returns_correct_result',\n",
              "   'test_calculator_add_method_returns_correct_result',\n",
              "   '(',\n",
              "   'arguments',\n",
              "   'arg',\n",
              "   'self',\n",
              "   'self',\n",
              "   ',',\n",
              "   ')',\n",
              "   '<INDENT>',\n",
              "   'Assign',\n",
              "   'Name',\n",
              "   'result',\n",
              "   'result',\n",
              "   'Call',\n",
              "   '=',\n",
              "   'Attribute',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'calc',\n",
              "   '.',\n",
              "   'add',\n",
              "   'self.calc.add',\n",
              "   '(',\n",
              "   'Num',\n",
              "   '2',\n",
              "   ',',\n",
              "   'Num',\n",
              "   '2',\n",
              "   ')',\n",
              "   '<NL>',\n",
              "   'Expr',\n",
              "   'Call',\n",
              "   'Attribute',\n",
              "   'Name',\n",
              "   'self',\n",
              "   '.',\n",
              "   'assertEqual',\n",
              "   'self.assertEqual',\n",
              "   '(',\n",
              "   'Num',\n",
              "   '4',\n",
              "   ',',\n",
              "   'Name',\n",
              "   'result',\n",
              "   ')',\n",
              "   '<DEDENT>',\n",
              "   '<DEDENT>',\n",
              "   'self',\n",
              "   'calc',\n",
              "   'add',\n",
              "   'unittest',\n",
              "   'assert',\n",
              "   'equal',\n",
              "   'result',\n",
              "   'test',\n",
              "   'case',\n",
              "   'calculator',\n",
              "   '0',\n",
              "   'method',\n",
              "   'returns',\n",
              "   'correct',\n",
              "   'set',\n",
              "   'up'],\n",
              "  'edges': {'CHILD': {'0': [1, 3, 4],\n",
              "    '1': [2],\n",
              "    '4': [96, 5, 6, 7, 8, 44, 45, 15, 16, 17],\n",
              "    '8': [9, 12, 13],\n",
              "    '9': [10],\n",
              "    '17': [43, 18, 19, 21, 22, 27, 28, 29],\n",
              "    '22': [26, 23],\n",
              "    '23': [24],\n",
              "    '29': [32, 33, 36, 37, 30],\n",
              "    '30': [31],\n",
              "    '36': [41, 42, 38],\n",
              "    '38': [39],\n",
              "    '45': [46, 47, 79, 49, 50, 80, 55, 56, 57, 95],\n",
              "    '50': [51, 54],\n",
              "    '51': [52],\n",
              "    '57': [58, 61, 62],\n",
              "    '58': [59],\n",
              "    '61': [72, 73, 75, 76, 78, 63],\n",
              "    '63': [64, 69, 70],\n",
              "    '64': [65, 67, 68],\n",
              "    '65': [66],\n",
              "    '73': [74],\n",
              "    '76': [77],\n",
              "    '80': [81],\n",
              "    '81': [82, 88, 89, 91, 92, 94],\n",
              "    '82': [83, 85, 86],\n",
              "    '83': [84],\n",
              "    '89': [90],\n",
              "    '92': [93]},\n",
              "   'NEXT': {'5': [6],\n",
              "    '6': [7],\n",
              "    '7': [10],\n",
              "    '10': [12],\n",
              "    '12': [13],\n",
              "    '13': [15],\n",
              "    '15': [16],\n",
              "    '16': [18],\n",
              "    '18': [19],\n",
              "    '19': [21],\n",
              "    '21': [24],\n",
              "    '24': [26],\n",
              "    '26': [27],\n",
              "    '27': [28],\n",
              "    '28': [31],\n",
              "    '31': [32],\n",
              "    '32': [33],\n",
              "    '33': [37],\n",
              "    '37': [39],\n",
              "    '39': [41],\n",
              "    '41': [42],\n",
              "    '42': [43],\n",
              "    '43': [44],\n",
              "    '44': [46],\n",
              "    '46': [47],\n",
              "    '47': [49],\n",
              "    '49': [52],\n",
              "    '52': [54],\n",
              "    '54': [55],\n",
              "    '55': [56],\n",
              "    '56': [59],\n",
              "    '59': [62],\n",
              "    '62': [66],\n",
              "    '66': [67],\n",
              "    '67': [68],\n",
              "    '68': [69],\n",
              "    '69': [70],\n",
              "    '70': [72],\n",
              "    '72': [74],\n",
              "    '74': [75],\n",
              "    '75': [77],\n",
              "    '77': [78],\n",
              "    '78': [79],\n",
              "    '79': [84],\n",
              "    '84': [85],\n",
              "    '85': [86],\n",
              "    '86': [88],\n",
              "    '88': [90],\n",
              "    '90': [91],\n",
              "    '91': [93],\n",
              "    '93': [94],\n",
              "    '57': [80],\n",
              "    '94': [95],\n",
              "    '17': [45],\n",
              "    '95': [96]},\n",
              "   'LAST_LEXICAL_USE': {'24': [31],\n",
              "    '52': [66],\n",
              "    '34': [64],\n",
              "    '66': [84],\n",
              "    '59': [93]},\n",
              "   'NEXT_USE': {'52': [66], '66': [84], '59': [93]},\n",
              "   'COMPUTED_FROM': {'34': [36], '58': [61]},\n",
              "   'OCCURRENCE_OF': {'10': [11],\n",
              "    '8': [14],\n",
              "    '19': [20],\n",
              "    '24': [25],\n",
              "    '31': [25],\n",
              "    '34': [35],\n",
              "    '39': [40],\n",
              "    '47': [48],\n",
              "    '52': [53],\n",
              "    '59': [60],\n",
              "    '66': [53],\n",
              "    '64': [35],\n",
              "    '63': [71],\n",
              "    '84': [53],\n",
              "    '82': [87],\n",
              "    '93': [60]},\n",
              "   'SUBTOKEN_OF': {'97': [66, 52, 84, 24, 31],\n",
              "    '98': [33, 68],\n",
              "    '99': [70, 47],\n",
              "    '100': [10],\n",
              "    '101': [86],\n",
              "    '102': [86],\n",
              "    '103': [59, 93, 47],\n",
              "    '104': [13, 6, 47],\n",
              "    '105': [13],\n",
              "    '106': [47, 6, 39],\n",
              "    '107': [6],\n",
              "    '108': [47],\n",
              "    '109': [47],\n",
              "    '110': [47],\n",
              "    '111': [19],\n",
              "    '112': [19]}},\n",
              "  'token-sequence': [5,\n",
              "   6,\n",
              "   7,\n",
              "   10,\n",
              "   12,\n",
              "   13,\n",
              "   15,\n",
              "   16,\n",
              "   18,\n",
              "   19,\n",
              "   21,\n",
              "   24,\n",
              "   26,\n",
              "   27,\n",
              "   28,\n",
              "   31,\n",
              "   32,\n",
              "   33,\n",
              "   37,\n",
              "   39,\n",
              "   41,\n",
              "   42,\n",
              "   43,\n",
              "   44,\n",
              "   46,\n",
              "   47,\n",
              "   49,\n",
              "   52,\n",
              "   54,\n",
              "   55,\n",
              "   56,\n",
              "   59,\n",
              "   62,\n",
              "   66,\n",
              "   67,\n",
              "   68,\n",
              "   69,\n",
              "   70,\n",
              "   72,\n",
              "   74,\n",
              "   75,\n",
              "   77,\n",
              "   78,\n",
              "   79,\n",
              "   84,\n",
              "   85,\n",
              "   86,\n",
              "   88,\n",
              "   90,\n",
              "   91,\n",
              "   93,\n",
              "   94,\n",
              "   95,\n",
              "   96],\n",
              "  'supernodes': {'20': {'name': 'setUp',\n",
              "    'annotation': None,\n",
              "    'location': [7, 4],\n",
              "    'type': 'class-or-function'},\n",
              "   '35': {'name': 'self.calc',\n",
              "    'annotation': None,\n",
              "    'location': [8, 8],\n",
              "    'type': 'variable'},\n",
              "   '48': {'name': 'test_calculator_add_method_returns_correct_result',\n",
              "    'annotation': None,\n",
              "    'location': [10, 4],\n",
              "    'type': 'class-or-function'},\n",
              "   '60': {'name': 'result',\n",
              "    'annotation': None,\n",
              "    'location': [11, 8],\n",
              "    'type': 'variable'}},\n",
              "  'filename': '/0.py'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feed Data to Graph Network"
      ],
      "metadata": {
        "id": "h7jOhrQzPO-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NUjrG3-fDDcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "oU99QvDTcEAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## tokenize edges\n",
        "## edges have features of CHILD, NEXT, LAST_LEXICAL_USE, NEXT_USE, COMPUTED_FROM, OCCURRENCE_OF, SUBTOKEN_OF\n",
        "## could try different methods to aggregate edge features\n",
        "## each feature would correspond to an index\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def edgesToFeatureVector(embedding, aggregation = \"sum\"):\n",
        "  no_nodes = len(embedding[\"nodes\"])\n",
        "  edges = embedding[\"edges\"]\n",
        "  feature_vect = []\n",
        "  \n",
        "  # loop through all edge_types and add them, use index to refer to type\n",
        "  for type_idx, edge_type in enumerate(list(edges.keys())):\n",
        "    for node in edges[edge_type].keys():\n",
        "      for val in edges[edge_type][node]:\n",
        "        # feature_vect.append([int(node), val, type_idx])\n",
        "        feature_vect.append([int(node), val])\n",
        "\n",
        "  \n",
        "  return np.array(feature_vect)\n",
        "\n",
        "# get the label for the method using the methd name\n",
        "def getLabel(embedding):\n",
        "    function_name = embedding[\"supernodes\"][\"48\"][\"name\"]\n",
        "\n",
        "    return labels[1] if (function_name.find(\"error\")) else labels[0]\n",
        "\n",
        "# get embedding of node texts\n",
        "def getWordVectors(embedding, technique=\"one-hot\"):\n",
        "  if(technique == \"one-hot\"):\n",
        "    words = []\n",
        "    for graph in graphs:\n",
        "      [words.append(token) for token in graph[\"nodes\"]]\n",
        "\n",
        "    \n",
        "    max_nodes = max([len(node) for node in (embedding[\"nodes\"] for embedding in graphs)])\n",
        "\n",
        "    words = list(set(words))\n",
        "\n",
        "    word_vects = []\n",
        "\n",
        "    for token in embedding[\"nodes\"]:\n",
        "      word_vect = np.zeros((1, len(words)), dtype=object)\n",
        "      word_vect[0][words.index(token)] = 1\n",
        "      word_vects.append(word_vect)\n",
        "\n",
        "    while len(word_vects) < max_nodes:\n",
        "      word_vects.append(np.zeros((1, len(words)), dtype=object))\n",
        "    \n",
        "    return np.concatenate(np.array(word_vects, dtype=object))\n",
        "\n",
        "# Extract node_features, edges and weights from a given graph\n",
        "def getGraphInfo(graph):\n",
        "  # Create an edges array (sparse adjacency matrix) of shape [3, num_edges].\n",
        "  edges = np.array(edgesToFeatureVector(graph)).T\n",
        "\n",
        "  # Create an edge weights array of ones.\n",
        "  edge_weights = tf.ones(shape=edges.shape[1], dtype=tf.float32)\n",
        "\n",
        "  # Create a node features array of shape [num_nodes, num_features].\n",
        "  node_features = getWordVectors(graph)\n",
        "\n",
        "  # Create graph info dictionary with node_features, edges, and edge_weights.\n",
        "  return {\"node_features\": node_features, \"edges\": edges, \"edge_weights\": edge_weights}\n",
        "  # return {\"node_features\": node_features, \"edges\": edges, \"edge_weights\": None}"
      ],
      "metadata": {
        "id": "AXebVpAwIf6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformGraphForGNN(graph):\n",
        "    return {\n",
        "        \"name\": graph[\"supernodes\"][\"48\"][\"name\"],\n",
        "        \"info\": getGraphInfo(graph),\n",
        "        \"label\": getLabel(graph)\n",
        "    }\n",
        "\n",
        "def groupByLabel(data, labels):\n",
        "  groups = [[] for i in labels]\n",
        "\n",
        "  for name in data.keys():\n",
        "    graph = data[name]\n",
        "    which = labels.index(graph[\"label\"])\n",
        "    groups[which].append(graph)\n",
        "  \n",
        "  return [np.array(group) for group in groups]"
      ],
      "metadata": {
        "id": "e6V3BZ98ucfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphs = graphToJson(\"/content/split_tests/test_calculator/all-graphs000.jsonl.gz\")"
      ],
      "metadata": {
        "id": "ouHfxM9cC4BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prep Datasets\n",
        "\n",
        "\n",
        "*   Test and Train Features\n",
        "\n"
      ],
      "metadata": {
        "id": "pc7yPRTAyH3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(labels)"
      ],
      "metadata": {
        "id": "SzJyHJhDx5zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Feed Forward Network"
      ],
      "metadata": {
        "id": "yHS2iAoovFP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ffn(hidden_units, dropout_rate, name=None):\n",
        "    fnn_layers = []\n",
        "\n",
        "    for units in hidden_units:\n",
        "        # Batch Normalization normalizes unit values in batches (using its mean and standard dev) to create even spread \n",
        "        fnn_layers.append(layers.BatchNormalization())\n",
        "        # Dropout removes units randomly to prevent overfitting\n",
        "        fnn_layers.append(layers.Dropout(dropout_rate))\n",
        "        # Dense layer every node conected to the others\n",
        "        fnn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
        "\n",
        "    return keras.Sequential(fnn_layers, name=name)"
      ],
      "metadata": {
        "id": "uv1HcodxvMrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train and Evaluation Experiment"
      ],
      "metadata": {
        "id": "HQlk4IC4FXp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Arch variables\n",
        "hidden_units = [32, 32]\n",
        "learning_rate = 0.01\n",
        "dropout_rate = 0.5\n",
        "num_epochs = 300\n",
        "batch_size = 256"
      ],
      "metadata": {
        "id": "mjkPGv8CFb85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model, x_train, y_train):\n",
        "    # Compile the model.\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
        "    )\n",
        "    # Create an early stopping callback.\n",
        "    early_stopping = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_acc\", patience=50, restore_best_weights=True\n",
        "    )\n",
        "    # Fit the model.\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        epochs=num_epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_split=0.15,\n",
        "        callbacks=[early_stopping],\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "oPSmo0L5Fhr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_learning_curves(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    ax1.plot(history.history[\"loss\"])\n",
        "    ax1.plot(history.history[\"val_loss\"])\n",
        "    ax1.legend([\"train\", \"test\"], loc=\"upper right\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "\n",
        "    ax2.plot(history.history[\"acc\"])\n",
        "    ax2.plot(history.history[\"val_acc\"])\n",
        "    ax2.legend([\"train\", \"test\"], loc=\"upper right\")\n",
        "    ax2.set_xlabel(\"Epochs\")\n",
        "    ax2.set_ylabel(\"Accuracy\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zxrDRjYcSWl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Graph Convolutional Layer"
      ],
      "metadata": {
        "id": "t5FnQZDp_vWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvLayer(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_units,\n",
        "        dropout_rate=0.2,\n",
        "        # used to aggregate node messages\n",
        "        aggregation_type=\"mean\",\n",
        "        # used to combine node representations with their messages\n",
        "        combination_type=\"concat\",\n",
        "        normalize=False,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super(GraphConvLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.aggregation_type = aggregation_type\n",
        "        self.combination_type = combination_type\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self.ffn_prepare = create_ffn(hidden_units, dropout_rate)\n",
        "        if self.combination_type == \"gated\":\n",
        "            self.update_fn = layers.GRU(\n",
        "                units=hidden_units,\n",
        "                activation=\"tanh\",\n",
        "                recurrent_activation=\"sigmoid\",\n",
        "                dropout=dropout_rate,\n",
        "                return_state=True,\n",
        "                recurrent_dropout=dropout_rate,\n",
        "            )\n",
        "        else:\n",
        "            self.update_fn = create_ffn(hidden_units, dropout_rate)\n",
        "\n",
        "    def prepare(self, node_repesentations, weights=None):\n",
        "        # node_repesentations shape is [num_edges, embedding_dim].\n",
        "        messages = self.ffn_prepare(node_repesentations)\n",
        "        if weights is not None:\n",
        "            messages = messages * tf.expand_dims(weights, -1)\n",
        "        return messages\n",
        "\n",
        "    def aggregate(self, node_indices, neighbour_messages, node_repesentations):\n",
        "        # node_indices shape is [num_edges].\n",
        "        # neighbour_messages shape: [num_edges, representation_dim].\n",
        "        # node_repesentations shape is [num_nodes, representation_dim]\n",
        "        num_nodes = node_repesentations.shape[0]\n",
        "        if self.aggregation_type == \"sum\":\n",
        "            aggregated_message = tf.math.unsorted_segment_sum(\n",
        "                neighbour_messages, node_indices, num_segments=num_nodes\n",
        "            )\n",
        "        elif self.aggregation_type == \"mean\":\n",
        "            aggregated_message = tf.math.unsorted_segment_mean(\n",
        "                neighbour_messages, node_indices, num_segments=num_nodes\n",
        "            )\n",
        "        elif self.aggregation_type == \"max\":\n",
        "            aggregated_message = tf.math.unsorted_segment_max(\n",
        "                neighbour_messages, node_indices, num_segments=num_nodes\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid aggregation type: {self.aggregation_type}.\")\n",
        "\n",
        "        return aggregated_message\n",
        "\n",
        "    def update(self, node_repesentations, aggregated_messages):\n",
        "        # node_repesentations shape is [num_nodes, representation_dim].\n",
        "        # aggregated_messages shape is [num_nodes, representation_dim].\n",
        "        if self.combination_type == \"gru\":\n",
        "            # Create a sequence of two elements for the GRU layer.\n",
        "            h = tf.stack([node_repesentations, aggregated_messages], axis=1)\n",
        "        elif self.combination_type == \"concat\":\n",
        "            # Concatenate the node_repesentations and aggregated_messages.\n",
        "            h = tf.concat([node_repesentations, aggregated_messages], axis=1)\n",
        "        elif self.combination_type == \"add\":\n",
        "            # Add node_repesentations and aggregated_messages.\n",
        "            h = node_repesentations + aggregated_messages\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid combination type: {self.combination_type}.\")\n",
        "\n",
        "        # Apply the processing function.\n",
        "        node_embeddings = self.update_fn(h)\n",
        "        if self.combination_type == \"gru\":\n",
        "            node_embeddings = tf.unstack(node_embeddings, axis=1)[-1]\n",
        "\n",
        "        if self.normalize:\n",
        "            node_embeddings = tf.nn.l2_normalize(node_embeddings, axis=-1)\n",
        "        return node_embeddings\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Process the inputs to produce the node_embeddings.\n",
        "\n",
        "        inputs: a tuple of three elements: node_repesentations, edges, edge_weights.\n",
        "        Returns: node_embeddings of shape [num_nodes, representation_dim].\n",
        "        \"\"\"\n",
        "\n",
        "        node_repesentations, edges, edge_weights = inputs\n",
        "        # Get node_indices (source) and neighbour_indices (target) from edges.\n",
        "        node_indices, neighbour_indices = edges[0], edges[1]\n",
        "        # neighbour_repesentations shape is [num_edges, representation_dim].\n",
        "        neighbour_repesentations = tf.gather(node_repesentations, neighbour_indices)\n",
        "\n",
        "        # Prepare the messages of the neighbours.\n",
        "        neighbour_messages = self.prepare(neighbour_repesentations, edge_weights)\n",
        "        # Aggregate the neighbour messages.\n",
        "        aggregated_messages = self.aggregate(\n",
        "            node_indices, neighbour_messages, node_repesentations\n",
        "        )\n",
        "        # Update the node embedding with the neighbour messages.\n",
        "        return self.update(node_repesentations, aggregated_messages)"
      ],
      "metadata": {
        "id": "aM-KXNdB_1vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create GNN Classifier"
      ],
      "metadata": {
        "id": "jnyjuC7-CW27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNNodeClassifier(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        graph_info,\n",
        "        num_classes,\n",
        "        hidden_units,\n",
        "        aggregation_type=\"sum\",\n",
        "        combination_type=\"concat\",\n",
        "        dropout_rate=0.2,\n",
        "        normalize=True,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super(GNNNodeClassifier, self).__init__(*args, **kwargs)\n",
        "\n",
        "        # Unpack graph_info to three elements: node_features, edges, and edge_weight.\n",
        "        node_features, edges, edge_weights = graph_info\n",
        "        self.node_features = node_features\n",
        "        self.edges = edges\n",
        "        self.edge_weights = edge_weights\n",
        "        # Set edge_weights to ones if not provided.\n",
        "        if self.edge_weights is None:\n",
        "            self.edge_weights = tf.ones(shape=edges.shape[1])\n",
        "        # Scale edge_weights to sum to 1.\n",
        "        self.edge_weights = self.edge_weights / tf.math.reduce_sum(self.edge_weights)\n",
        "\n",
        "        # Create a process layer.\n",
        "        self.preprocess = create_ffn(hidden_units, dropout_rate, name=\"preprocess\")\n",
        "        # Create the first GraphConv layer.\n",
        "        self.conv1 = GraphConvLayer(\n",
        "            hidden_units,\n",
        "            dropout_rate,\n",
        "            aggregation_type,\n",
        "            combination_type,\n",
        "            normalize,\n",
        "            name=\"graph_conv1\",\n",
        "        )\n",
        "        # Create the second GraphConv layer.\n",
        "        self.conv2 = GraphConvLayer(\n",
        "            hidden_units,\n",
        "            dropout_rate,\n",
        "            aggregation_type,\n",
        "            combination_type,\n",
        "            normalize,\n",
        "            name=\"graph_conv2\",\n",
        "        )\n",
        "        # Create a postprocess layer.\n",
        "        self.postprocess = create_ffn(hidden_units, dropout_rate, name=\"postprocess\")\n",
        "        # Create a compute logits layer.\n",
        "        self.compute_logits = layers.Dense(units=num_classes, name=\"logits\")\n",
        "\n",
        "    def call(self, input_node_indices):\n",
        "        # Preprocess the node_features to produce node representations.\n",
        "        print(self.node_features)\n",
        "        x = self.preprocess(self.node_features)\n",
        "        # Apply the first graph conv layer.\n",
        "        x1 = self.conv1((x, self.edges, self.edge_weights))\n",
        "        # Skip connection.\n",
        "        x = x1 + x\n",
        "        # Apply the second graph conv layer.\n",
        "        x2 = self.conv2((x, self.edges, self.edge_weights))\n",
        "        # Skip connection.\n",
        "        x = x2 + x\n",
        "        # Postprocess node embedding.\n",
        "        x = self.postprocess(x)\n",
        "        # Fetch node embeddings for the input node_indices.\n",
        "        node_embeddings = tf.gather(x, input_node_indices)\n",
        "        # Compute logits\n",
        "        return self.compute_logits(node_embeddings)"
      ],
      "metadata": {
        "id": "mr7dSPszCb9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXntve8b5CKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate GNN Classifier"
      ],
      "metadata": {
        "id": "V9SjhhydE7so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainOnGraphs(graphs):\n",
        "  x_train, y_train = [], []\n",
        "  \n",
        "  for graph in graphs:\n",
        "    graph_dict = transformGraphForGNN(graph)\n",
        "\n",
        "    x_train.append(np.array([node_feature for node_feature in graph_dict[\"info\"][\"node_features\"]]))\n",
        "    y_train.append(labels.index(graph_dict[\"label\"]))\n",
        "    # for node_feature in graph_dict[\"info\"][\"node_features\"]:\n",
        "    #   x_train.append(node_feature)\n",
        "    # y_train.append([labels.index(graph_dict[\"label\"])])\n",
        "\n",
        "  x_train = tf.cast(\n",
        "      np.array(x_train, dtype=np.float32), \n",
        "      dtype=tf.dtypes.float32\n",
        "  )\n",
        "  # print(x_train)\n",
        "\n",
        "  y_train = np.array(y_train, dtype=np.float32)\n",
        "  # print(y_train)\n",
        "\n",
        "  # x_train = np.array([1,1,1,1])\n",
        "  # y_train = np.array([1, 0, 1, 0])\n",
        "\n",
        "  print(graph_dict[\"info\"].values())\n",
        "\n",
        "  gnn_model = GNNNodeClassifier(\n",
        "    graph_info=tuple(graph_dict[\"info\"].values()),\n",
        "    num_classes=num_classes,\n",
        "    hidden_units=hidden_units,\n",
        "    dropout_rate=dropout_rate,\n",
        "    name=\"gnn_model\",\n",
        "  )\n",
        "\n",
        "  # print(\"GNN output shape:\", gnn_model(tf.constant([1, 10])))\n",
        "\n",
        "  # gnn_model.summary()\n",
        "\n",
        "   # print(\"GNN output shape:\", gnn_model(np.asarray([1, 10, 100])))\n",
        "\n",
        "  return run_experiment(gnn_model, x_train, y_train)\n",
        "\n",
        "import json\n",
        "\n",
        "HISTORY_PATH = \"/content/history.json\"\n",
        "\n",
        "history = trainOnGraphs(graphs).history\n",
        "\n",
        "# json.dump(history, open(HISTORY_PATH, \"w+\"))\n",
        "\n",
        "print(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NSDSVa3eHLvk",
        "outputId": "1f06e24b-a95f-4411-d950-6efc1bdb9e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([array([[0, 0, 0, ..., 0, 1, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=object), array([[  0,   0,   0,   1,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
            "          4,   8,   8,   8,   9,  17,  17,  17,  17,  17,  17,  17,  17,\n",
            "         22,  22,  23,  29,  29,  29,  29,  29,  30,  36,  36,  36,  38,\n",
            "         45,  45,  45,  45,  45,  45,  45,  45,  45,  45,  50,  50,  51,\n",
            "         57,  57,  57,  58,  61,  61,  61,  61,  61,  61,  63,  63,  63,\n",
            "         64,  64,  64,  65,  73,  76,  80,  81,  81,  81,  81,  81,  81,\n",
            "         82,  82,  82,  83,  89,  92,   5,   6,   7,  10,  12,  13,  15,\n",
            "         16,  18,  19,  21,  24,  26,  27,  28,  31,  32,  33,  37,  39,\n",
            "         41,  42,  43,  44,  46,  47,  49,  52,  54,  55,  56,  59,  62,\n",
            "         66,  67,  68,  69,  70,  72,  74,  75,  77,  78,  79,  84,  85,\n",
            "         86,  88,  90,  91,  93,  57,  94,  17,  95,  24,  52,  34,  66,\n",
            "         59,  52,  66,  59,  34,  58,  10,   8,  19,  24,  31,  34,  39,\n",
            "         47,  52,  59,  66,  64,  63,  84,  82,  93,  97,  97,  97,  97,\n",
            "         97,  98,  98,  99,  99, 100, 101, 102, 103, 103, 103, 104, 104,\n",
            "        104, 105, 106, 106, 106, 107, 108, 109, 110, 111, 112],\n",
            "       [  1,   3,   4,   2,  96,   5,   6,   7,   8,  44,  45,  15,  16,\n",
            "         17,   9,  12,  13,  10,  43,  18,  19,  21,  22,  27,  28,  29,\n",
            "         26,  23,  24,  32,  33,  36,  37,  30,  31,  41,  42,  38,  39,\n",
            "         46,  47,  79,  49,  50,  80,  55,  56,  57,  95,  51,  54,  52,\n",
            "         58,  61,  62,  59,  72,  73,  75,  76,  78,  63,  64,  69,  70,\n",
            "         65,  67,  68,  66,  74,  77,  81,  82,  88,  89,  91,  92,  94,\n",
            "         83,  85,  86,  84,  90,  93,   6,   7,  10,  12,  13,  15,  16,\n",
            "         18,  19,  21,  24,  26,  27,  28,  31,  32,  33,  37,  39,  41,\n",
            "         42,  43,  44,  46,  47,  49,  52,  54,  55,  56,  59,  62,  66,\n",
            "         67,  68,  69,  70,  72,  74,  75,  77,  78,  79,  84,  85,  86,\n",
            "         88,  90,  91,  93,  94,  80,  95,  45,  96,  31,  66,  64,  84,\n",
            "         93,  66,  84,  93,  36,  61,  11,  14,  20,  25,  25,  35,  40,\n",
            "         48,  53,  60,  53,  35,  71,  53,  87,  60,  66,  52,  84,  24,\n",
            "         31,  33,  68,  70,  47,  10,  86,  86,  59,  93,  47,  13,   6,\n",
            "         47,  13,  47,   6,  39,   6,  47,  47,  47,  19,  19]]), <tf.Tensor: shape=(193,), dtype=float32, numpy=\n",
            "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1.], dtype=float32)>])\n",
            "Epoch 1/300\n",
            "[[0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-2a5e5269c94e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mHISTORY_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/history.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainOnGraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# json.dump(history, open(HISTORY_PATH, \"w+\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-2a5e5269c94e>\u001b[0m in \u001b[0;36mtrainOnGraphs\u001b[0;34m(graphs)\u001b[0m\n\u001b[1;32m     39\u001b[0m    \u001b[0;31m# print(\"GNN output shape:\", gnn_model(np.asarray([1, 10, 100])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-757d14a85ba4>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, x_train, y_train)\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Fit the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filefo0vgs31.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, input_node_indices)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filefo0vgs31.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).preprocess, (ag__.ld(self).node_features,), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"gnn_model\" (type GNNNodeClassifier).\n    \n    in user code:\n    \n        File \"<ipython-input-25-a4244dafb696>\", line 55, in call  *\n            x = self.preprocess(self.node_features)\n        File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"tensorflow/python/framework/fast_tensor_util.pyx\", line 127, in tensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto\n            \n    \n        TypeError: Expected binary or unicode string, got 0\n    \n    \n    Call arguments received by layer \"gnn_model\" (type GNNNodeClassifier):\n      • input_node_indices=tf.Tensor(shape=(None, 113, 78), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}