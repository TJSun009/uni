{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TJSun009/University-Projects/blob/main/Test_Categorisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDK45Gxu6gBE"
      },
      "source": [
        "# Plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuTry73ATwWk"
      },
      "outputs": [],
      "source": [
        "# Plan of Action\n",
        "\n",
        "# Source-Test Mapping\n",
        "# Get Graph Representation of Programs\n",
        "# Create a Graph Neural Network Classfier to map src and test graph\n",
        "# (Optional) Enhance graph tokens using GraphCodeBERT, CodeBERT or TREEBERT embeddings\n",
        "\n",
        "# Test Generation\n",
        "# Create a GraphTransformer using Graph Representations and Encoder-Decoder Architecture\n",
        "# Prior Embeddings may be useful\n",
        "# See GraphBERT - https://arxiv.org/abs/2001.05140\n",
        "# Encoder - convert Graph nodes to a node embedding Representation based on surrounding nodes and edges\n",
        "\n",
        "# Use Masked Node Modelling to Mask a Node in the AST and Generate it based on it's connected nodes and edges"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Cloud Login"
      ],
      "metadata": {
        "id": "X2de2lPwdQXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login --no-launch-browser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eorg51KqqyQq",
        "outputId": "3e98979c-a62a-4f8c-d8c8-69eb515fdbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=7XrsEvQwmbyIGEkKe9DvarWDdiTgdF&prompt=consent&access_type=offline&code_challenge=GnhVDoNciVs6r7fDLqtzE_HAA8PxEsiF0-RJLpbucYk&code_challenge_method=S256\n",
            "\n",
            "Enter authorization code: \n",
            "\n",
            "Command killed by keyboard interrupt\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Cloud Helpers"
      ],
      "metadata": {
        "id": "Mid38jp9sDMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = \"southern-camera-367511\"\n",
        "bucket_name = \"dissertation-data-bucket-1\"\n",
        "!gcloud config set project {project_id}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25l7dUyUdYTv",
        "outputId": "99b295be-9ea3-4ae9-fe9a-5613581a2a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GCS Helpers\n",
        "\n",
        "# copy file to GCS\n",
        "def copy_to_gcs(file_path, options=\"\"):\n",
        "  file_path = file_path.replace(\"/content\", \"\")\n",
        "  command = ! gsutil -m cp{options} {file_path} gs://{bucket_name}/{file_path}\n",
        "\n",
        "# copy file to GCS\n",
        "def copy_from_gcs(src_file_path, dest_file_path=\"\", options=\"\"):\n",
        "  gcs_file_path = src_file_path.replace(\"/content/\", \"\")\n",
        "\n",
        "  dest_file_path = dest_file_path if dest_file_path != \"\" else src_file_path\n",
        "\n",
        "  if not os.path.exists(dest_file_path):\n",
        "    os.makedirs(os.path.dirname(dest_file_path), exist_ok=True)\n",
        "\n",
        "  command = ! gsutil -m cp{options} gs://{bucket_name}/{gcs_file_path} {dest_file_path}\n",
        "  print(\"copied succesfully\")\n",
        "\n",
        "def list_gcs_files(file_path):\n",
        "  file_path = file_path.replace(\"/content/\", \"\")\n",
        "  files = ! gsutil ls gs://{bucket_name}/{file_path}\n",
        "  return files\n",
        "\n",
        "def gcs_file_path_to_colab(gcs_file_path):\n",
        "  return gcs_file_path.replace(f\"gs://{bucket_name}/\", \"/content/\")\n",
        "\n",
        "# check for file in GCS\n",
        "def is_in_gcs(file_path):\n",
        "  file_path = file_path.replace(\"/content/\", \"\")\n",
        "  output = ! gsutil -q stat gs://{bucket_name}/{file_path}; echo $?\n",
        "  return output[0] == '0'"
      ],
      "metadata": {
        "id": "K-7eqv7Pf-XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjHpv5AIgsJ6"
      },
      "source": [
        "# Source-Test Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgjOkMrriB-Q"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiDQAGIjk1ee"
      },
      "outputs": [],
      "source": [
        "! pip install -Uqqq scipy networkx fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUjrG3-fDDcX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "# import pandas as pd\n",
        "import networkx as nx\n",
        "from glob import iglob\n",
        "import importlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGiAvVTs535v"
      },
      "source": [
        "### python-graphs dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r31L5nnSeL-"
      },
      "outputs": [],
      "source": [
        "# New Graph Generator Approach\n",
        "# https://arxiv.org/pdf/2208.07461v1.pdf\n",
        "\n",
        "# install python-graphs on startup\n",
        "! echo {SUDO} | sudo -S apt-get -qq -y install graphviz graphviz-dev\n",
        "# ! pip install -Uqqq python-graphs gast==0.3.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/google-research/python-graphs.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e92Y-Tcb25hE",
        "outputId": "a091c922-e1bb-439f-cc06-c858e0e6a3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'python-graphs' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd ./python-graphs && python setup.py develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSI7Q7wC3C3H",
        "outputId": "cddb43cc-a463-41b8-e346-cfdc3f17d31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "writing python_graphs.egg-info/PKG-INFO\n",
            "writing dependency_links to python_graphs.egg-info/dependency_links.txt\n",
            "writing requirements to python_graphs.egg-info/requires.txt\n",
            "writing top-level names to python_graphs.egg-info/top_level.txt\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'python_graphs.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.8/dist-packages/python-graphs.egg-link (link to .)\n",
            "python-graphs 1.3.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /content/python-graphs\n",
            "Processing dependencies for python-graphs==1.3.0\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pygraphviz==1.10\n",
            "Best match: pygraphviz 1.10\n",
            "Adding pygraphviz 1.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for networkx==3.0\n",
            "Best match: networkx 3.0\n",
            "Adding networkx 3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for gast==0.3.2\n",
            "Best match: gast 0.3.2\n",
            "Adding gast 0.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for absl-py==1.3.0\n",
            "Best match: absl-py 1.3.0\n",
            "Adding absl-py 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for wheel==0.38.4\n",
            "Best match: wheel 0.38.4\n",
            "Adding wheel 0.38.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Finished processing dependencies for python-graphs==1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h3hDQAKiSK2"
      },
      "source": [
        "#### Understanding python-graphs Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr7lEAu3FlxE"
      },
      "outputs": [],
      "source": [
        "# import gast as ast\n",
        "# from python_graphs import program_graph\n",
        "\n",
        "# # example file\n",
        "# file_path = DIR_PREFIX + \"Year 3/Dissertation/Projects/Datasets/data/minified/src/unittest_utils.py\"\n",
        "\n",
        "# with open(file_path, \"r\") as f:\n",
        "#   # graph = program_graph.get_program_graph(f.read())\n",
        "  \n",
        "#   # read ast head\n",
        "#   graph = program_graph.get_program_graph(ast.parse(f.read()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kauehBVaem2"
      },
      "outputs": [],
      "source": [
        "# # nodes are stored in a dictionary representing a key-value pair of the node id and node itself\n",
        "# example_node_dict = graph.nodes\n",
        "\n",
        "# # nodes are represented as strings by joining the node id and node ast_type if it has one \n",
        "# example_node_dict_item = list(example_node_dict.items())[0]\n",
        "\n",
        "# # item 0 is the node id and item 1 the node representation\n",
        "# example_node_dict_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgwVVv1JfKd2"
      },
      "outputs": [],
      "source": [
        "# # as above the node is the value\n",
        "# example_node = example_node_dict_item[1]\n",
        "\n",
        "# # we can view the nodes properties as well\n",
        "# # the ast_value is of particular interest as well for retrieving tokens\n",
        "# # not all nodes will have a value though\n",
        "# print(example_node.__dict__)\n",
        "# print(example_node.__dict__[\"ast_node\"].__dict__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_9j7z6PFNY8"
      },
      "outputs": [],
      "source": [
        "# # show what ast_values look like\n",
        "# nodes = list(graph.all_nodes())\n",
        "\n",
        "# node_values = []\n",
        "# for node in nodes:\n",
        "#   if node.ast_value:\n",
        "#     node_values.append(node.ast_value)\n",
        "# # some ast_values are long strings so will need subtokens which can be combined\n",
        "# # may require CodeBERT embeddings\n",
        "# node_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFxwIA9jCZc_"
      },
      "outputs": [],
      "source": [
        "# # check edge\n",
        "# example_edge = graph.edges[0]\n",
        "# example_edge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1fREN-3ktCY"
      },
      "source": [
        "### CodeBERT dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w0I1cLCVrUb"
      },
      "outputs": [],
      "source": [
        "# imports for tokenising code values\n",
        "! pip install -Uqqq transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ThqF6zVgR_"
      },
      "source": [
        "#### Investigating CodeBERT Tokeniser for code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# import torch\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "# model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
      ],
      "metadata": {
        "id": "MDTIheOElCdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhXA4pwkc-B9"
      },
      "outputs": [],
      "source": [
        "# # join node values into single string\n",
        "# code = (' ').join([str(val) for val in node_values])\n",
        "# # code\n",
        "# code_tokens = tokenizer.tokenize(code)\n",
        "# # code_tokens\n",
        "# tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]\n",
        "# # tokens\n",
        "# tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# # this is the final output from the model\n",
        "# # it consists of 1 vector for each token across 768 distinct features \n",
        "# context_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]\n",
        "# # context_embeddings.shape\n",
        "# len(code_tokens), context_embeddings.shape\n",
        "\n",
        "# # in the graph embedding the node values could be represented as each value padded\n",
        "# # by N others on either side, N would be calibrated for best results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJq3_r9jFem7"
      },
      "source": [
        "## Prepare Dataset Helpers\n",
        "\n",
        "produces graph_list (list of python_graphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJy8aIye_hMm"
      },
      "outputs": [],
      "source": [
        "CODE_MINI_DIR =  \"/content/data/minified\"\n",
        "CODE_LARGE_DIR = \"/content/data/large\"\n",
        "CODE_DIR = CODE_MINI_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7jOhrQzPO-i"
      },
      "source": [
        "## Feed Data to Graph Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILzKE0s9F_gU"
      },
      "source": [
        "### Creating Code Graph Class\n",
        "\n",
        "This class makes use of networkx a popular graph representation library"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "XYDzw1GVdjKe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCUAunHgfRDc"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqqq torch-scatter torch-sparse torch-geometric -f https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DFjEdSGF-ma"
      },
      "outputs": [],
      "source": [
        "# each edge should be weighted differently based on its type, edge should contain types\n",
        "from python_graphs import program_graph_dataclasses\n",
        "\n",
        "# for ast class list\n",
        "import sys, inspect\n",
        "\n",
        "# imports for tokenising code values\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Node Feature Helpers"
      ],
      "metadata": {
        "id": "pYH9kJs2dTSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import process\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "import pdb\n",
        "import gc\n",
        "# use enum value to set node type\n",
        "# dict updates only keys contained therein\n",
        "# automatic enum conversion\n",
        "\n",
        "def clean_vars(vars):\n",
        "  for i in vars:\n",
        "    del(i)\n",
        "  gc.collect()\n",
        "\n",
        "def node_types_to_ints(G):\n",
        "  node_type_dict = nx.get_node_attributes(G, \"node_type\")\n",
        "  int_dict = {k: {\"node_type\": v.value} for k, v in node_type_dict.items()}\n",
        "  nx.set_node_attributes(G, int_dict)\n",
        "\n",
        "  vars = [node_type_dict, int_dict, G]\n",
        "  clean_vars(vars)\n",
        "  \n",
        "\n",
        "# use enum class to convert value back\n",
        "def ints_to_node_types(G):\n",
        "  node_type_dict = nx.get_node_attributes(G, \"node_type\")\n",
        "  node_type_dict = {k: {\"node_type\": program_graph_dataclasses.NodeType(v)} for k, v in node_type_dict.items()}\n",
        "  nx.set_node_attributes(G, node_type_dict)\n",
        "\n",
        "  vars = [node_type_dict, G]\n",
        "  clean_vars(vars)\n",
        "\n",
        "# ast type can be dealt with using string byte encoding\n",
        "def ast_types_to_ints(G, ast_types):\n",
        "  ast_type_dict = nx.get_node_attributes(G, \"ast_type\")\n",
        "  int_dict = {k: {\"ast_type\": ast_types.index(v)} if v in ast_types else {\"ast_type\": -1} for k, v in ast_type_dict.items()}\n",
        "  nx.set_node_attributes(G, int_dict)\n",
        "\n",
        "  vars = [ast_type_dict, int_dict, G, ast_types]\n",
        "  clean_vars(vars)\n",
        "\n",
        "def ints_to_ast_types(G, ast_types):\n",
        "  ast_type_dict = nx.get_node_attributes(G, \"ast_type\")\n",
        "  int_dict = {k: {\"ast_type\": ast_types[v]} for k, v in ast_type_dict.items()}\n",
        "  nx.set_node_attributes(G, int_dict)\n",
        "\n",
        "  vars = [ast_type_dict, int_dict, G, ast_types]\n",
        "  clean_vars(vars)\n",
        "\n",
        "# ast_value embeddings done using CodeBERT embeddings\n",
        "# N equates to context padding how many subsequent and following tokens are used in embedding\n",
        "def ast_values_to_context_embeddings(G, vocab):\n",
        "  # tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "  # model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "  ast_value_dict = nx.get_node_attributes(G, \"ast_value\")\n",
        "\n",
        "  embedding_dict = {}\n",
        "\n",
        "  vocab = list(vocab)\n",
        "\n",
        "  batch_sentences = [str(v) for v in ast_value_dict.values()]\n",
        "\n",
        "  encoded_inputs = tokenizer(batch_sentences, padding=True)\n",
        "\n",
        "  for k in ast_value_dict.keys():\n",
        "    context_embeddings = model(torch.tensor(encoded_inputs[\"input_ids\"][k])[None,:])[0]\n",
        "    embedding_dict[k] = {\"ast_value\": context_embeddings}\n",
        "\n",
        "  nx.set_node_attributes(G, embedding_dict)\n",
        "\n",
        "  vars = [ast_value_dict, embedding_dict, vocab, batch_sentences, encoded_inputs, G]\n",
        "  clean_vars(vars)\n"
      ],
      "metadata": {
        "id": "c54hNyKAdMah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a60abf0-0e99-4b67-f94a-d0276d6e06b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Edge Feature Helpers"
      ],
      "metadata": {
        "id": "8Gxa_6fQFFSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_types_to_ints(G):\n",
        "  edge_type_dict = nx.get_edge_attributes(G, \"type\")\n",
        "  int_dict = {(node1, node2, dir): {\"type\": v.value} for (node1, node2, dir), v in edge_type_dict.items()}\n",
        "  nx.set_edge_attributes(G, int_dict)"
      ],
      "metadata": {
        "id": "HFoN-UBoFD0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementation"
      ],
      "metadata": {
        "id": "-tYAVWXzdoN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils.convert import from_networkx\n",
        "from accelerate import init_empty_weights\n",
        "\n",
        "# This code graph class represents a single graph generated in the code corpus\n",
        "class CodeGraph:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.G = nx.MultiDiGraph()\n",
        "    self.embeddings = {}\n",
        "    self.identifier = \"\"\n",
        "    self.is_pair = None\n",
        "    self.types = {\n",
        "        \"edge\" : program_graph_dataclasses.EdgeType._member_names_,\n",
        "        \"ast\" : [cls.__name__ for _, cls in inspect.getmembers(sys.modules[\"ast\"], inspect.isclass)]\n",
        "        }\n",
        "    self.max_length = 512\n",
        "\n",
        "  def node_value_to_vect(self, k, v):\n",
        "    if k == \"node_type\":\n",
        "      return v.value\n",
        "    elif k == \"ast_type\":\n",
        "      ast_types = self.types[\"ast\"]\n",
        "      return ast_types.index(v) if v in ast_types else -1\n",
        "    elif k == \"ast_value\":\n",
        "      return self.embeddings[v]\n",
        "\n",
        "  def tokens_to_embeddings(self, tokens):\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "    with init_empty_weights():\n",
        "      model = AutoModel.from_pretrained(\"microsoft/codebert-base\", low_cpu_mem_usage=True)\n",
        "    \n",
        "    batch_sentences = [str(v) for v in tokens]\n",
        "\n",
        "    encoded_inputs = tokenizer(batch_sentences, padding=\"max_length\", truncation=True, max_length = self.max_length)\n",
        "\n",
        "    for idx, t in enumerate(tokens):\n",
        "      if t in self.embeddings.keys():\n",
        "        continue\n",
        "      else:\n",
        "        context_embeddings = model(torch.tensor(encoded_inputs[\"input_ids\"][idx])[None,:])[0]\n",
        "        self.embeddings[t] = context_embeddings\n",
        "    \n",
        "    del(model)\n",
        "    del(tokenizer)\n",
        "\n",
        "  def read(self, graph):\n",
        "\n",
        "    # set identifier to file_name of graph if graph is a module\n",
        "    if (graph.root.ast_type == \"Module\"):\n",
        "      self.identifier = graph.filename\n",
        "    # TODO implement identifier for functions instead\n",
        "\n",
        "    # add nodes to graph along with their attributes\n",
        "    # dict comprehension deduplicates node id\n",
        "    # we can exclude the ast_node as this info should be encoded in the graphs and edges\n",
        "    # exclude instruction temporarily due to complexity\n",
        "\n",
        "    nodes = graph.all_nodes()\n",
        "\n",
        "    # create dictionary of ast token values to context embeddings\n",
        "    pdb.set_trace()\n",
        "\n",
        "\n",
        "    self.tokens_to_embeddings([node.ast_value for node in nodes])\n",
        "\n",
        "    self.G.add_nodes_from([(node.id, {k: self.node_value_to_vect(k, v) for k, v in node.__dict__.items() if k not in [\"id\", \"ast_node\", \"instruction\"]}) for node in nodes])\n",
        "    \n",
        "    # append edges to the graph along with their attributes\n",
        "    # dict comprehension deduplicates node ids for edge\n",
        "    self.G.add_edges_from([(edge.id1, edge.id2, {\"type\": edge.type.value}) for edge in graph.edges])\n",
        "    \n",
        "\n",
        "  def node_feature_vector_graph(self, H):\n",
        "    \n",
        "    # some node features have been discarded as they are too complex to be used by pytorch\n",
        "    # or replicate info stored elsewhere in the graph\n",
        "\n",
        "    node_type = list(H.nodes(data=\"node_type\"))[0][1]\n",
        "    if not isinstance(node_type, int):\n",
        "      node_types_to_ints(H)\n",
        "      ast_types_to_ints(H, self.types[\"ast\"])\n",
        "      ast_values_to_context_embeddings(H, self.vocab)\n",
        "    \n",
        "    return H\n",
        "  \n",
        "  def edge_feature_vector_graph(self, H):\n",
        "    \n",
        "    # converts edge type to an integer\n",
        "\n",
        "    edge_type = list(H.edges(data=\"type\"))[0][2]\n",
        "    if not isinstance(edge_type, int):\n",
        "      edge_types_to_ints(H)\n",
        "    \n",
        "    return H\n",
        "\n",
        "    \"\"\"{'node_type': <NodeType.AST_NODE: 1>, \n",
        "      # ignoring instruction due to it being another complex graph\n",
        "      'instruction': <python_graphs.instruction.Instruction object at 0x7ff853d756d0>, \n",
        "      'ast_type': 'Expr', \n",
        "      'ast_value': '', \n",
        "      'syntax': ''}\"\"\"\n",
        "    \n",
        "    # ast_value encoding\n",
        "  \n",
        "  def draw(self):\n",
        "    if len(self.G.nodes) > 0:\n",
        "      # create normalizer for colours\n",
        "      norm = plt.Normalize()\n",
        "\n",
        "      # use vocab and edge_types to generate colours for plot\n",
        "      # edges are mapped to their position in types\n",
        "      token_colors = [self.vocab.index(val) for val in list(nx.get_node_attributes(self.G, \"ast_value\").values())]\n",
        "      edge_type_colors = [edge_type.value for edge_type in list(nx.get_edge_attributes(self.G, \"type\").values())]\n",
        "      \n",
        "      # normalize the colors between [0, 1]\n",
        "      node_color, edge_color = norm(token_colors), norm(edge_type_colors)\n",
        "\n",
        "      fig, ax = plt.subplots(1, 1, figsize=(10, 10));\n",
        "\n",
        "      nx.draw_networkx(self.G, edge_color = edge_color, node_color = node_color, with_labels=True, ax = ax)\n",
        "  \n",
        "  def pytorch_graph(self):\n",
        "    # H = self.node_feature_vector_graph(self.G)\n",
        "\n",
        "    # P = self.edge_feature_vector_graph(H)\n",
        "\n",
        "    pyg = from_networkx(self.G)\n",
        "    \n",
        "    if (self.is_pair):\n",
        "      pyg.y = torch.tensor([int(self.is_pair)])\n",
        "    \n",
        "    return "
      ],
      "metadata": {
        "id": "ZNQNLu0zbvTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch Data Obj Implementation"
      ],
      "metadata": {
        "id": "zb-RAp29RvT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data.dataset import to_list\n",
        "from accelerate import init_empty_weights\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# This code data class represents a single graph generated in the code corpus as a pytorch data object\n",
        "class CodeData:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.x = []\n",
        "    self.edge_index = [[], []]\n",
        "    self.edge_attr = []\n",
        "    self.y = []\n",
        "    self.data = None\n",
        "    self.types = {\n",
        "        \"edge\" : program_graph_dataclasses.EdgeType._member_names_,\n",
        "        \"ast\" : [cls.__name__ for _, cls in inspect.getmembers(sys.modules[\"ast\"], inspect.isclass)]\n",
        "        }\n",
        "    # self.embeddings = {}\n",
        "    self.vocab = set()\n",
        "    self.max_length = 256\n",
        "    self.identifier = None\n",
        "\n",
        "  def node_value_to_vect(self, k, v):\n",
        "    if k == \"node_type\":\n",
        "      return v.value\n",
        "    elif k == \"ast_type\":\n",
        "      ast_types = self.types[\"ast\"]\n",
        "      return ast_types.index(v) if v in ast_types else -1\n",
        "    elif k == \"ast_value\":\n",
        "      # return self.embeddings[v]\n",
        "      # one-hot encode based on length of vocab\n",
        "      return F.one_hot(torch.tensor([self.vocab.index(v)]), num_classes = len(self.embeddings)).to_list()\n",
        "\n",
        "  # def tokens_to_embeddings(self, tokens):\n",
        "\n",
        "  #   tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "  #   with init_empty_weights():\n",
        "  #     model = AutoModel.from_pretrained(\"microsoft/codebert-base\", low_cpu_mem_usage=True)\n",
        "    \n",
        "  #   batch_sentences = [str(v) for v in tokens]\n",
        "\n",
        "  #   encoded_inputs = tokenizer(batch_sentences, padding=\"max_length\", truncation=True, max_length = self.max_length)\n",
        "\n",
        "  #   for idx, t in enumerate(tokens):\n",
        "  #     if t in self.embeddings.keys():\n",
        "  #       continue\n",
        "  #     else:\n",
        "  #       context_embeddings = model(torch.tensor(encoded_inputs[\"input_ids\"][idx])[None,:])[0]\n",
        "  #       self.embeddings[t] = context_embeddings\n",
        "    \n",
        "  #   del(model)\n",
        "  #   del(tokenizer)\n",
        "\n",
        "\n",
        "  def read(self, src_graph, test_graph):\n",
        "\n",
        "    # set identifier to file_name of graph if graph is a module\n",
        "    # TODO implement identifier for functions instead\n",
        "    self.y = [int(src_graph.filename.replace(\"_test.py\", \"\") == test_graph.filename.replace(\"_test.py\", \"\"))]\n",
        "\n",
        "    # offset to differentiate src and test nodes\n",
        "    offset = 0\n",
        "\n",
        "    for graph in [src_graph, test_graph]:\n",
        "\n",
        "      # add nodes to graph along with their attributes\n",
        "      # dict comprehension deduplicates node id\n",
        "      # we can exclude the ast_node as this info should be encoded in the graphs and edges\n",
        "      # exclude instruction temporarily due to complexity\n",
        "\n",
        "      nodes = graph.all_nodes()\n",
        "\n",
        "      # create dictionary of ast token values to context embeddings\n",
        "\n",
        "      # do one_hot_encoding instead for ease\n",
        "      # self.tokens_to_embeddings([node.ast_value for node in nodes])\n",
        "      self.vocab.update(set([node.ast_value for node in nodes]))\n",
        "\n",
        "      self.x.extend([(idx + offset, node) for idx, node in enumerate(nodes)])\n",
        "\n",
        "      \n",
        "      # append edges to the graph along with their attributes\n",
        "      # dict comprehension deduplicates node ids for edge\n",
        "      \n",
        "      for edge in graph.edges:\n",
        "        self.edge_index[0].append(edge.id1 + offset)\n",
        "        self.edge_index[1].append(edge.id2 + offset)\n",
        "        self.edge_attr.append([edge.type.value])\n",
        "\n",
        "      offset = len(self.x)\n",
        "\n",
        "    self.vocab = list(self.vocab)\n",
        "\n",
        "\n",
        "    # enumerate through self.x and add other features\n",
        "    for idx, (id, node) in enumerate(self.x):\n",
        "      self.x[idx] = [id] + [self.node_value_to_vect(k, v) for k, v in node.__dict__.items() if k not in [\"id\", \"ast_node\", \"instruction\", \"syntax\"]]\n",
        "\n",
        "    self.x = torch.tensor(self.x)\n",
        "    self.edge_index = torch.tensor(self.x)\n",
        "    self.edge_attr = torch.tensor(self.x)\n",
        "  \n",
        "  def get_data(self):\n",
        "    if (len(self.y) > 0):\n",
        "      return Data(x=self.x, edge_index=self.edge_index, edge_attr=self.edge_attr, y=self.y)\n",
        "\n",
        "  def draw(self):\n",
        "    if len(self.x) > 0:\n",
        "\n",
        "      G = self.get_data().to_networkx()\n",
        "\n",
        "      # create normalizer for colours\n",
        "      norm = plt.Normalize()\n",
        "\n",
        "      # use vocab and edge_types to generate colours for plot\n",
        "      # edges are mapped to their position in types\n",
        "      token_colors = [self.vocab.index(val) for val in list(nx.get_node_attributes(self.G, \"ast_value\").values())]\n",
        "      edge_type_colors = [edge_type.value for edge_type in list(nx.get_edge_attributes(self.G, \"type\").values())]\n",
        "      \n",
        "      # normalize the colors between [0, 1]\n",
        "      node_color, edge_color = norm(token_colors), norm(edge_type_colors)\n",
        "\n",
        "      fig, ax = plt.subplots(1, 1, figsize=(10, 10));\n",
        "\n",
        "      nx.draw_networkx(G, edge_color = edge_color, node_color = node_color, with_labels=True, ax = ax)"
      ],
      "metadata": {
        "id": "Fe_YGzOGR0Uh"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Code Graphs"
      ],
      "metadata": {
        "id": "UKiLLhYWCzki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset will consist of:\n",
        "# graph - a graph containing  candidate src graph and test graph\n",
        "# label - a 0 or 1 corresponding to whether the test and src are a valid pairing\n",
        "\n",
        "# function for combining code_graphs\n",
        "def combine_code_graphs(pair):\n",
        "  code_graph1, code_graph2 = pair\n",
        "  # # check if the node vectorisation has already happened\n",
        "  # node_type_list = [\n",
        "  #     list(code_graph1.G.nodes(data=\"node_type\"))[0][1],\n",
        "  #     list(code_graph2.G.nodes(data=\"node_type\"))[0][1],\n",
        "  # ]\n",
        "  \n",
        "  # if any([isinstance(node_type, int) for node_type in node_type_list]):\n",
        "  #   raise Exception(\"Cannot combine code graphs that have already been vectorised\")\n",
        "\n",
        "  # uses number of nodes to verify combination graph worked correctly\n",
        "  graph1, graph2 = code_graph1.G, code_graph2.G\n",
        "  \n",
        "  H = nx.disjoint_union(graph1, graph2)\n",
        "\n",
        "  code_graph1.G = H\n",
        "  code_graph1.embeddings.update(code_graph2.embeddings)\n",
        "\n",
        "  # add a property to the code_graph checking whether or not there are a code, test pair\n",
        "  # False for pair, True for non pair\n",
        "  # dealing with file at present\n",
        "  # mapping functions it will require looking at AST calls etc.\n",
        "  code_graph1.is_pair = code_graph1.identifier.replace(\"_test.py\", \"\") == code_graph2.identifier.replace(\"_test.py\", \"\")\n",
        "\n",
        "  # cleanup vars for concurrency\n",
        "  del(graph1)\n",
        "  del(graph2)\n",
        "  del(code_graph2)\n",
        "  del(H)\n",
        "  return code_graph1\n",
        "# # function for combining code_graphs\n",
        "# def combine_code_graphs(pair):\n",
        "#   code_graph1, code_graph2 = pair\n",
        "#   # check if the node vectorisation has already happened\n",
        "#   node_type_list = [\n",
        "#       list(code_graph1.G.nodes(data=\"node_type\"))[0][1],\n",
        "#       list(code_graph2.G.nodes(data=\"node_type\"))[0][1],\n",
        "#   ]\n",
        "  \n",
        "#   if any([isinstance(node_type, int) for node_type in node_type_list]):\n",
        "#     raise Exception(\"Cannot combine code graphs that have already been vectorised\")\n",
        "\n",
        "#   # uses number of nodes to verify combination graph worked correctly\n",
        "#   graph1, graph2 = code_graph1.G, code_graph2.G\n",
        "  \n",
        "#   H = nx.disjoint_union(graph1, graph2)\n",
        "\n",
        "#   code_graph1.G = H\n",
        "#   code_graph1.vocab.update(list(code_graph2.vocab))\n",
        "\n",
        "#   # add a property to the code_graph checking whether or not there are a code, test pair\n",
        "#   # False for pair, True for non pair\n",
        "#   # dealing with file at present\n",
        "#   # mapping functions it will require looking at AST calls etc.\n",
        "#   code_graph1.is_pair = code_graph1.identifier.replace(\"_test.py\", \"\") == code_graph2.identifier.replace(\"_test.py\", \"\")\n",
        "\n",
        "#   # cleanup vars for concurrency\n",
        "#   del(graph1)\n",
        "#   del(graph2)\n",
        "#   del(code_graph2)\n",
        "#   del(node_type_list)\n",
        "#   del(H)\n",
        "#   return code_graph1"
      ],
      "metadata": {
        "id": "HWeiGfM_CxpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8fX44jExinI"
      },
      "source": [
        "### PyTorch Conversion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Dataset\n",
        "import glob\n",
        "from torch_geometric.data.makedirs import makedirs\n",
        "from itertools import product\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "51lrAu2lK9Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_files = [os.path.basename(gcs_file_path_to_colab(file)) for file in list_gcs_files(os.path.join(CODE_DIR, \"src\", \"\"))]\n",
        "RAW_FILES = []\n",
        "for file in source_files:\n",
        "  RAW_FILES.append(os.path.join(\"src\", file))\n",
        "  RAW_FILES.append(os.path.join(\"test\", file.replace(\".py\", \"_test.py\")))\n",
        "\n",
        "PROCESSED_FILES = [file.replace(\".py\", \".pt\") for file in source_files]"
      ],
      "metadata": {
        "id": "VomYTtdHmY1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gast\n",
        "from python_graphs import program_graph\n",
        "from contextlib import suppress\n",
        "\n",
        "def save_data(raw_paths, processed_dir):\n",
        "  src_paths, test_paths = [], []\n",
        "\n",
        "  for path in raw_paths:\n",
        "    test_paths.append(path) if path.find(\"_test.py\") != -1 else src_paths.append(path)\n",
        "\n",
        "  source_test_pairs = list(product(src_paths, test_paths))\n",
        "\n",
        "  idx = 0\n",
        "\n",
        "  source_test_pairs = source_test_pairs\n",
        "\n",
        "  unparseable = []\n",
        "\n",
        "  for i, (src_path, test_path) in enumerate(pbar := tqdm(source_test_pairs)):\n",
        "    \n",
        "    if src_path in unparseable or test_path in unparseable:\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      with open(src_path, encoding=\"utf-8\") as f:\n",
        "          src_graph = program_graph.get_program_graph(gast.parse(f.read()))\n",
        "          src_graph.filename = os.path.basename(src_path)\n",
        "    except (TypeError, SyntaxError):\n",
        "        unparseable.append(src_path)\n",
        "        pbar.set_description(f\"Could not parse {os.path.basename(src_path)}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "      with open(test_path, encoding=\"utf-8\") as f:\n",
        "        test_graph = program_graph.get_program_graph(gast.parse(f.read()))\n",
        "        test_graph.filename = os.path.basename(src_path)\n",
        "    except (TypeError, SyntaxError):\n",
        "        unparseable.append(test_path)\n",
        "        pbar.set_description(f\"Could not parse {os.path.basename(test_path)}\")\n",
        "        continue\n",
        "    else:\n",
        "      if (os.path.exists(os.path.join(processed_dir, f\"data_{idx}.pt\"))):\n",
        "        idx += 1\n",
        "        continue\n",
        "    \n",
        "    pbar.set_description(f\"pairing [{os.path.basename(src_path)}, {os.path.basename(test_path)}]\")\n",
        "    \n",
        "    src_code_graph = CodeGraph()\n",
        "    src_code_graph.read(src_graph)\n",
        "\n",
        "    test_code_graph = CodeGraph()\n",
        "    test_code_graph.read(test_graph)\n",
        "\n",
        "    combined_code_graph = combine_code_graphs((src_code_graph, test_code_graph))\n",
        "    pdb.set_trace()\n",
        "\n",
        "    data = combined_code_graph.pytorch_graph()\n",
        "\n",
        "    torch.save(data, os.path.join(processed_dir, f\"data_{idx}.pt\"))\n",
        "\n",
        "    pbar.set_description(f\"saved data_{idx}.pt\")\n",
        "    \n",
        "    idx += 1\n",
        "\n",
        "class SourceTestDataset(Dataset):\n",
        "  def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "      super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return RAW_FILES\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return PROCESSED_FILES\n",
        "\n",
        "  def download(self):\n",
        "    # Download to `self.raw_dir`.\n",
        "    copy_from_gcs(os.path.join(self.root, \"src\", ''), os.path.join(self.root, \"raw\", ''), \" -r\")\n",
        "    copy_from_gcs(os.path.join(self.root, \"test\", ''), os.path.join(self.root, \"raw\", ''), \" -r\")\n",
        "\n",
        "  def process(self):\n",
        "    # Read data into huge `Data` list.\n",
        "    pass\n",
        "\n",
        "  def len(self):\n",
        "    return len(self.processed_file_names)\n",
        "\n",
        "  def get(self, idx):\n",
        "    data = torch.load(os.path.join(self.processed_dir, f\"data_{idx}.pt\"))\n",
        "    return data"
      ],
      "metadata": {
        "id": "iI8AOKIDyHn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gast\n",
        "from python_graphs import program_graph\n",
        "from contextlib import suppress\n",
        "\n",
        "def save_pytorch_data(raw_paths, processed_dir):\n",
        "  src_paths, test_paths = [], []\n",
        "\n",
        "  for path in raw_paths:\n",
        "    test_paths.append(path) if path.find(\"_test.py\") != -1 else src_paths.append(path)\n",
        "\n",
        "  source_test_pairs = list(product(src_paths, test_paths))\n",
        "\n",
        "  idx = 0\n",
        "\n",
        "  source_test_pairs = source_test_pairs\n",
        "\n",
        "  unparseable = []\n",
        "\n",
        "  for i, (src_path, test_path) in enumerate(pbar := tqdm(source_test_pairs)):\n",
        "    \n",
        "    if src_path in unparseable or test_path in unparseable:\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      with open(src_path, encoding=\"utf-8\") as f:\n",
        "          src_graph = program_graph.get_program_graph(gast.parse(f.read()))\n",
        "          src_graph.filename = os.path.basename(src_path)\n",
        "    except (TypeError, SyntaxError, KeyError):\n",
        "        unparseable.append(src_path)\n",
        "        pbar.set_description(f\"Could not parse {os.path.basename(src_path)}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "      with open(test_path, encoding=\"utf-8\") as f:\n",
        "        test_graph = program_graph.get_program_graph(gast.parse(f.read()))\n",
        "        test_graph.filename = os.path.basename(src_path)\n",
        "    except (TypeError, SyntaxError, KeyError):\n",
        "        unparseable.append(test_path)\n",
        "        pbar.set_description(f\"Could not parse {os.path.basename(test_path)}\")\n",
        "        continue\n",
        "    else:\n",
        "      if (os.path.exists(os.path.join(processed_dir, f\"data_{idx}.pt\"))):\n",
        "        idx += 1\n",
        "        continue\n",
        "    \n",
        "    pbar.set_description(f\"pairing [{os.path.basename(src_path)}, {os.path.basename(test_path)}]\")\n",
        "    \n",
        "    paired_data = CodeData()\n",
        "\n",
        "    paired_data.read(src_graph, test_graph)\n",
        "\n",
        "    data = paired_data.get_data()\n",
        "\n",
        "    torch.save(data, os.path.join(processed_dir, f\"data_{idx}.pt\"))\n",
        "\n",
        "    pbar.set_description(f\"saved data_{idx}.pt\")\n",
        "    \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "_26M7_6GkZIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPlC4qLL0CY-",
        "outputId": "0c645df2-7e36-4b74-9d6f-dccaa4c6dba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 1.13.0+cu116\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_paths = [file_path for file_path in iglob(os.path.join(CODE_DIR, \"raw\", '**', '*.py'), recursive=True)]"
      ],
      "metadata": {
        "id": "JBTCFkX9QFPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_pytorch_data(raw_paths, os.path.join(CODE_DIR, \"processed\", \"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "f98c4adc5fda411993c4cb551fbafb84",
            "88598251aacd4aa39fe18904cf892333",
            "9f060855b73a46d69f2ec04377d8f126",
            "e957ca5b6fda40e4adbdd1af127e5219",
            "dac1646762024043815271547c773688",
            "f6a6f0a7af7140edae6851cc0f436218",
            "6f4e2b3684154676b7f8b14ec6818871",
            "3fdbe10ab92c4f4c9ccc7336ee3dc87f",
            "31f12173d1d6496dadb96331cce58cfa",
            "b7cd7ec5fbe94eba91399f83c917861c",
            "628c152e1d184016af2871365b470161"
          ]
        },
        "id": "hOb36f4SRAzm",
        "outputId": "10954b2a-54dd-485f-8d3e-273cec0fe8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4761 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f98c4adc5fda411993c4cb551fbafb84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-9559f7a9880b>:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.edge_index = torch.tensor(self.x).clone().detach()\n",
            "<ipython-input-79-9559f7a9880b>:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.edge_attr = torch.tensor(self.x).clone().detach()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "copy_to_gcs(os.path.join(CODE_DIR, \"processed\"), \" -r\")"
      ],
      "metadata": {
        "id": "ufoz37i6dJU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debug"
      ],
      "metadata": {
        "id": "2fyRdme-734G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "id": "bankf8RLFRaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl92SSHT0hMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844ad8c1-cb32-4047-8e5f-fcffd8a5cb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset = SourceTestDataset(root=CODE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/minified/processed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgM5xrTyUJ4r",
        "outputId": "bdcb09b2-1e67-4678-d093-428bc8ef8cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_0.pt     data_133.pt   data_167.pt   data_325.pt  data_665.pt\n",
            "data_1000.pt  data_1340.pt  data_1680.pt  data_326.pt  data_666.pt\n",
            "data_1001.pt  data_1341.pt  data_1681.pt  data_327.pt  data_667.pt\n",
            "data_1002.pt  data_1342.pt  data_1682.pt  data_328.pt  data_668.pt\n",
            "data_1003.pt  data_1343.pt  data_1683.pt  data_329.pt  data_669.pt\n",
            "data_1004.pt  data_1344.pt  data_1684.pt  data_32.pt   data_66.pt\n",
            "data_1005.pt  data_1345.pt  data_1685.pt  data_330.pt  data_670.pt\n",
            "data_1006.pt  data_1346.pt  data_1686.pt  data_331.pt  data_671.pt\n",
            "data_1007.pt  data_1347.pt  data_1687.pt  data_332.pt  data_672.pt\n",
            "data_1008.pt  data_1348.pt  data_1688.pt  data_333.pt  data_673.pt\n",
            "data_1009.pt  data_1349.pt  data_1689.pt  data_334.pt  data_674.pt\n",
            "data_100.pt   data_134.pt   data_168.pt   data_335.pt  data_675.pt\n",
            "data_1010.pt  data_1350.pt  data_1690.pt  data_336.pt  data_676.pt\n",
            "data_1011.pt  data_1351.pt  data_1691.pt  data_337.pt  data_677.pt\n",
            "data_1012.pt  data_1352.pt  data_1692.pt  data_338.pt  data_678.pt\n",
            "data_1013.pt  data_1353.pt  data_1693.pt  data_339.pt  data_679.pt\n",
            "data_1014.pt  data_1354.pt  data_1694.pt  data_33.pt   data_67.pt\n",
            "data_1015.pt  data_1355.pt  data_1695.pt  data_340.pt  data_680.pt\n",
            "data_1016.pt  data_1356.pt  data_1696.pt  data_341.pt  data_681.pt\n",
            "data_1017.pt  data_1357.pt  data_1697.pt  data_342.pt  data_682.pt\n",
            "data_1018.pt  data_1358.pt  data_1698.pt  data_343.pt  data_683.pt\n",
            "data_1019.pt  data_1359.pt  data_1699.pt  data_344.pt  data_684.pt\n",
            "data_101.pt   data_135.pt   data_169.pt   data_345.pt  data_685.pt\n",
            "data_1020.pt  data_1360.pt  data_16.pt\t  data_346.pt  data_686.pt\n",
            "data_1021.pt  data_1361.pt  data_1700.pt  data_347.pt  data_687.pt\n",
            "data_1022.pt  data_1362.pt  data_1701.pt  data_348.pt  data_688.pt\n",
            "data_1023.pt  data_1363.pt  data_1702.pt  data_349.pt  data_689.pt\n",
            "data_1024.pt  data_1364.pt  data_1703.pt  data_34.pt   data_68.pt\n",
            "data_1025.pt  data_1365.pt  data_1704.pt  data_350.pt  data_690.pt\n",
            "data_1026.pt  data_1366.pt  data_1705.pt  data_351.pt  data_691.pt\n",
            "data_1027.pt  data_1367.pt  data_1706.pt  data_352.pt  data_692.pt\n",
            "data_1028.pt  data_1368.pt  data_1707.pt  data_353.pt  data_693.pt\n",
            "data_1029.pt  data_1369.pt  data_1708.pt  data_354.pt  data_694.pt\n",
            "data_102.pt   data_136.pt   data_1709.pt  data_355.pt  data_695.pt\n",
            "data_1030.pt  data_1370.pt  data_170.pt   data_356.pt  data_696.pt\n",
            "data_1031.pt  data_1371.pt  data_1710.pt  data_357.pt  data_697.pt\n",
            "data_1032.pt  data_1372.pt  data_1711.pt  data_358.pt  data_698.pt\n",
            "data_1033.pt  data_1373.pt  data_1712.pt  data_359.pt  data_699.pt\n",
            "data_1034.pt  data_1374.pt  data_1713.pt  data_35.pt   data_69.pt\n",
            "data_1035.pt  data_1375.pt  data_1714.pt  data_360.pt  data_6.pt\n",
            "data_1036.pt  data_1376.pt  data_1715.pt  data_361.pt  data_700.pt\n",
            "data_1037.pt  data_1377.pt  data_1716.pt  data_362.pt  data_701.pt\n",
            "data_1038.pt  data_1378.pt  data_1717.pt  data_363.pt  data_702.pt\n",
            "data_1039.pt  data_1379.pt  data_1718.pt  data_364.pt  data_703.pt\n",
            "data_103.pt   data_137.pt   data_1719.pt  data_365.pt  data_704.pt\n",
            "data_1040.pt  data_1380.pt  data_171.pt   data_366.pt  data_705.pt\n",
            "data_1041.pt  data_1381.pt  data_1720.pt  data_367.pt  data_706.pt\n",
            "data_1042.pt  data_1382.pt  data_1721.pt  data_368.pt  data_707.pt\n",
            "data_1043.pt  data_1383.pt  data_1722.pt  data_369.pt  data_708.pt\n",
            "data_1044.pt  data_1384.pt  data_1723.pt  data_36.pt   data_709.pt\n",
            "data_1045.pt  data_1385.pt  data_1724.pt  data_370.pt  data_70.pt\n",
            "data_1046.pt  data_1386.pt  data_1725.pt  data_371.pt  data_710.pt\n",
            "data_1047.pt  data_1387.pt  data_1726.pt  data_372.pt  data_711.pt\n",
            "data_1048.pt  data_1388.pt  data_1727.pt  data_373.pt  data_712.pt\n",
            "data_1049.pt  data_1389.pt  data_1728.pt  data_374.pt  data_713.pt\n",
            "data_104.pt   data_138.pt   data_1729.pt  data_375.pt  data_714.pt\n",
            "data_1050.pt  data_1390.pt  data_172.pt   data_376.pt  data_715.pt\n",
            "data_1051.pt  data_1391.pt  data_1730.pt  data_377.pt  data_716.pt\n",
            "data_1052.pt  data_1392.pt  data_1731.pt  data_378.pt  data_717.pt\n",
            "data_1053.pt  data_1393.pt  data_1732.pt  data_379.pt  data_718.pt\n",
            "data_1054.pt  data_1394.pt  data_1733.pt  data_37.pt   data_719.pt\n",
            "data_1055.pt  data_1395.pt  data_1734.pt  data_380.pt  data_71.pt\n",
            "data_1056.pt  data_1396.pt  data_1735.pt  data_381.pt  data_720.pt\n",
            "data_1057.pt  data_1397.pt  data_1736.pt  data_382.pt  data_721.pt\n",
            "data_1058.pt  data_1398.pt  data_1737.pt  data_383.pt  data_722.pt\n",
            "data_1059.pt  data_1399.pt  data_1738.pt  data_384.pt  data_723.pt\n",
            "data_105.pt   data_139.pt   data_1739.pt  data_385.pt  data_724.pt\n",
            "data_1060.pt  data_13.pt    data_173.pt   data_386.pt  data_725.pt\n",
            "data_1061.pt  data_1400.pt  data_1740.pt  data_387.pt  data_726.pt\n",
            "data_1062.pt  data_1401.pt  data_1741.pt  data_388.pt  data_727.pt\n",
            "data_1063.pt  data_1402.pt  data_1742.pt  data_389.pt  data_728.pt\n",
            "data_1064.pt  data_1403.pt  data_1743.pt  data_38.pt   data_729.pt\n",
            "data_1065.pt  data_1404.pt  data_1744.pt  data_390.pt  data_72.pt\n",
            "data_1066.pt  data_1405.pt  data_1745.pt  data_391.pt  data_730.pt\n",
            "data_1067.pt  data_1406.pt  data_1746.pt  data_392.pt  data_731.pt\n",
            "data_1068.pt  data_1407.pt  data_1747.pt  data_393.pt  data_732.pt\n",
            "data_1069.pt  data_1408.pt  data_1748.pt  data_394.pt  data_733.pt\n",
            "data_106.pt   data_1409.pt  data_1749.pt  data_395.pt  data_734.pt\n",
            "data_1070.pt  data_140.pt   data_174.pt   data_396.pt  data_735.pt\n",
            "data_1071.pt  data_1410.pt  data_1750.pt  data_397.pt  data_736.pt\n",
            "data_1072.pt  data_1411.pt  data_1751.pt  data_398.pt  data_737.pt\n",
            "data_1073.pt  data_1412.pt  data_1752.pt  data_399.pt  data_738.pt\n",
            "data_1074.pt  data_1413.pt  data_1753.pt  data_39.pt   data_739.pt\n",
            "data_1075.pt  data_1414.pt  data_1754.pt  data_3.pt    data_73.pt\n",
            "data_1076.pt  data_1415.pt  data_1755.pt  data_400.pt  data_740.pt\n",
            "data_1077.pt  data_1416.pt  data_1756.pt  data_401.pt  data_741.pt\n",
            "data_1078.pt  data_1417.pt  data_1757.pt  data_402.pt  data_742.pt\n",
            "data_1079.pt  data_1418.pt  data_1758.pt  data_403.pt  data_743.pt\n",
            "data_107.pt   data_1419.pt  data_1759.pt  data_404.pt  data_744.pt\n",
            "data_1080.pt  data_141.pt   data_175.pt   data_405.pt  data_745.pt\n",
            "data_1081.pt  data_1420.pt  data_1760.pt  data_406.pt  data_746.pt\n",
            "data_1082.pt  data_1421.pt  data_1761.pt  data_407.pt  data_747.pt\n",
            "data_1083.pt  data_1422.pt  data_1762.pt  data_408.pt  data_748.pt\n",
            "data_1084.pt  data_1423.pt  data_1763.pt  data_409.pt  data_749.pt\n",
            "data_1085.pt  data_1424.pt  data_1764.pt  data_40.pt   data_74.pt\n",
            "data_1086.pt  data_1425.pt  data_1765.pt  data_410.pt  data_750.pt\n",
            "data_1087.pt  data_1426.pt  data_1766.pt  data_411.pt  data_751.pt\n",
            "data_1088.pt  data_1427.pt  data_1767.pt  data_412.pt  data_752.pt\n",
            "data_1089.pt  data_1428.pt  data_1768.pt  data_413.pt  data_753.pt\n",
            "data_108.pt   data_1429.pt  data_1769.pt  data_414.pt  data_754.pt\n",
            "data_1090.pt  data_142.pt   data_176.pt   data_415.pt  data_755.pt\n",
            "data_1091.pt  data_1430.pt  data_1770.pt  data_416.pt  data_756.pt\n",
            "data_1092.pt  data_1431.pt  data_1771.pt  data_417.pt  data_757.pt\n",
            "data_1093.pt  data_1432.pt  data_1772.pt  data_418.pt  data_758.pt\n",
            "data_1094.pt  data_1433.pt  data_1773.pt  data_419.pt  data_759.pt\n",
            "data_1095.pt  data_1434.pt  data_1774.pt  data_41.pt   data_75.pt\n",
            "data_1096.pt  data_1435.pt  data_1775.pt  data_420.pt  data_760.pt\n",
            "data_1097.pt  data_1436.pt  data_1776.pt  data_421.pt  data_761.pt\n",
            "data_1098.pt  data_1437.pt  data_1777.pt  data_422.pt  data_762.pt\n",
            "data_1099.pt  data_1438.pt  data_1778.pt  data_423.pt  data_763.pt\n",
            "data_109.pt   data_1439.pt  data_1779.pt  data_424.pt  data_764.pt\n",
            "data_10.pt    data_143.pt   data_177.pt   data_425.pt  data_765.pt\n",
            "data_1100.pt  data_1440.pt  data_1780.pt  data_426.pt  data_766.pt\n",
            "data_1101.pt  data_1441.pt  data_1781.pt  data_427.pt  data_767.pt\n",
            "data_1102.pt  data_1442.pt  data_1782.pt  data_428.pt  data_768.pt\n",
            "data_1103.pt  data_1443.pt  data_1783.pt  data_429.pt  data_769.pt\n",
            "data_1104.pt  data_1444.pt  data_1784.pt  data_42.pt   data_76.pt\n",
            "data_1105.pt  data_1445.pt  data_1785.pt  data_430.pt  data_770.pt\n",
            "data_1106.pt  data_1446.pt  data_1786.pt  data_431.pt  data_771.pt\n",
            "data_1107.pt  data_1447.pt  data_1787.pt  data_432.pt  data_772.pt\n",
            "data_1108.pt  data_1448.pt  data_1788.pt  data_433.pt  data_773.pt\n",
            "data_1109.pt  data_1449.pt  data_1789.pt  data_434.pt  data_774.pt\n",
            "data_110.pt   data_144.pt   data_178.pt   data_435.pt  data_775.pt\n",
            "data_1110.pt  data_1450.pt  data_1790.pt  data_436.pt  data_776.pt\n",
            "data_1111.pt  data_1451.pt  data_1791.pt  data_437.pt  data_777.pt\n",
            "data_1112.pt  data_1452.pt  data_1792.pt  data_438.pt  data_778.pt\n",
            "data_1113.pt  data_1453.pt  data_1793.pt  data_439.pt  data_779.pt\n",
            "data_1114.pt  data_1454.pt  data_1794.pt  data_43.pt   data_77.pt\n",
            "data_1115.pt  data_1455.pt  data_1795.pt  data_440.pt  data_780.pt\n",
            "data_1116.pt  data_1456.pt  data_1796.pt  data_441.pt  data_781.pt\n",
            "data_1117.pt  data_1457.pt  data_1797.pt  data_442.pt  data_782.pt\n",
            "data_1118.pt  data_1458.pt  data_1798.pt  data_443.pt  data_783.pt\n",
            "data_1119.pt  data_1459.pt  data_1799.pt  data_444.pt  data_784.pt\n",
            "data_111.pt   data_145.pt   data_179.pt   data_445.pt  data_785.pt\n",
            "data_1120.pt  data_1460.pt  data_17.pt\t  data_446.pt  data_786.pt\n",
            "data_1121.pt  data_1461.pt  data_1800.pt  data_447.pt  data_787.pt\n",
            "data_1122.pt  data_1462.pt  data_1801.pt  data_448.pt  data_788.pt\n",
            "data_1123.pt  data_1463.pt  data_1802.pt  data_449.pt  data_789.pt\n",
            "data_1124.pt  data_1464.pt  data_1803.pt  data_44.pt   data_78.pt\n",
            "data_1125.pt  data_1465.pt  data_1804.pt  data_450.pt  data_790.pt\n",
            "data_1126.pt  data_1466.pt  data_1805.pt  data_451.pt  data_791.pt\n",
            "data_1127.pt  data_1467.pt  data_1806.pt  data_452.pt  data_792.pt\n",
            "data_1128.pt  data_1468.pt  data_1807.pt  data_453.pt  data_793.pt\n",
            "data_1129.pt  data_1469.pt  data_1808.pt  data_454.pt  data_794.pt\n",
            "data_112.pt   data_146.pt   data_1809.pt  data_455.pt  data_795.pt\n",
            "data_1130.pt  data_1470.pt  data_180.pt   data_456.pt  data_796.pt\n",
            "data_1131.pt  data_1471.pt  data_1810.pt  data_457.pt  data_797.pt\n",
            "data_1132.pt  data_1472.pt  data_1811.pt  data_458.pt  data_798.pt\n",
            "data_1133.pt  data_1473.pt  data_1812.pt  data_459.pt  data_799.pt\n",
            "data_1134.pt  data_1474.pt  data_1813.pt  data_45.pt   data_79.pt\n",
            "data_1135.pt  data_1475.pt  data_1814.pt  data_460.pt  data_7.pt\n",
            "data_1136.pt  data_1476.pt  data_1815.pt  data_461.pt  data_800.pt\n",
            "data_1137.pt  data_1477.pt  data_1816.pt  data_462.pt  data_801.pt\n",
            "data_1138.pt  data_1478.pt  data_1817.pt  data_463.pt  data_802.pt\n",
            "data_1139.pt  data_1479.pt  data_1818.pt  data_464.pt  data_803.pt\n",
            "data_113.pt   data_147.pt   data_1819.pt  data_465.pt  data_804.pt\n",
            "data_1140.pt  data_1480.pt  data_181.pt   data_466.pt  data_805.pt\n",
            "data_1141.pt  data_1481.pt  data_1820.pt  data_467.pt  data_806.pt\n",
            "data_1142.pt  data_1482.pt  data_1821.pt  data_468.pt  data_807.pt\n",
            "data_1143.pt  data_1483.pt  data_1822.pt  data_469.pt  data_808.pt\n",
            "data_1144.pt  data_1484.pt  data_1823.pt  data_46.pt   data_809.pt\n",
            "data_1145.pt  data_1485.pt  data_1824.pt  data_470.pt  data_80.pt\n",
            "data_1146.pt  data_1486.pt  data_1825.pt  data_471.pt  data_810.pt\n",
            "data_1147.pt  data_1487.pt  data_1826.pt  data_472.pt  data_811.pt\n",
            "data_1148.pt  data_1488.pt  data_1827.pt  data_473.pt  data_812.pt\n",
            "data_1149.pt  data_1489.pt  data_1828.pt  data_474.pt  data_813.pt\n",
            "data_114.pt   data_148.pt   data_1829.pt  data_475.pt  data_814.pt\n",
            "data_1150.pt  data_1490.pt  data_182.pt   data_476.pt  data_815.pt\n",
            "data_1151.pt  data_1491.pt  data_1830.pt  data_477.pt  data_816.pt\n",
            "data_1152.pt  data_1492.pt  data_1831.pt  data_478.pt  data_817.pt\n",
            "data_1153.pt  data_1493.pt  data_1832.pt  data_479.pt  data_818.pt\n",
            "data_1154.pt  data_1494.pt  data_1833.pt  data_47.pt   data_819.pt\n",
            "data_1155.pt  data_1495.pt  data_1834.pt  data_480.pt  data_81.pt\n",
            "data_1156.pt  data_1496.pt  data_1835.pt  data_481.pt  data_820.pt\n",
            "data_1157.pt  data_1497.pt  data_1836.pt  data_482.pt  data_821.pt\n",
            "data_1158.pt  data_1498.pt  data_1837.pt  data_483.pt  data_822.pt\n",
            "data_1159.pt  data_1499.pt  data_1838.pt  data_484.pt  data_823.pt\n",
            "data_115.pt   data_149.pt   data_1839.pt  data_485.pt  data_824.pt\n",
            "data_1160.pt  data_14.pt    data_183.pt   data_486.pt  data_825.pt\n",
            "data_1161.pt  data_1500.pt  data_1840.pt  data_487.pt  data_826.pt\n",
            "data_1162.pt  data_1501.pt  data_1841.pt  data_488.pt  data_827.pt\n",
            "data_1163.pt  data_1502.pt  data_1842.pt  data_489.pt  data_828.pt\n",
            "data_1164.pt  data_1503.pt  data_1843.pt  data_48.pt   data_829.pt\n",
            "data_1165.pt  data_1504.pt  data_1844.pt  data_490.pt  data_82.pt\n",
            "data_1166.pt  data_1505.pt  data_1845.pt  data_491.pt  data_830.pt\n",
            "data_1167.pt  data_1506.pt  data_1846.pt  data_492.pt  data_831.pt\n",
            "data_1168.pt  data_1507.pt  data_1847.pt  data_493.pt  data_832.pt\n",
            "data_1169.pt  data_1508.pt  data_1848.pt  data_494.pt  data_833.pt\n",
            "data_116.pt   data_1509.pt  data_1849.pt  data_495.pt  data_834.pt\n",
            "data_1170.pt  data_150.pt   data_184.pt   data_496.pt  data_835.pt\n",
            "data_1171.pt  data_1510.pt  data_1850.pt  data_497.pt  data_836.pt\n",
            "data_1172.pt  data_1511.pt  data_1851.pt  data_498.pt  data_837.pt\n",
            "data_1173.pt  data_1512.pt  data_1852.pt  data_499.pt  data_838.pt\n",
            "data_1174.pt  data_1513.pt  data_1853.pt  data_49.pt   data_839.pt\n",
            "data_1175.pt  data_1514.pt  data_1854.pt  data_4.pt    data_83.pt\n",
            "data_1176.pt  data_1515.pt  data_1855.pt  data_500.pt  data_840.pt\n",
            "data_1177.pt  data_1516.pt  data_1856.pt  data_501.pt  data_841.pt\n",
            "data_1178.pt  data_1517.pt  data_1857.pt  data_502.pt  data_842.pt\n",
            "data_1179.pt  data_1518.pt  data_1858.pt  data_503.pt  data_843.pt\n",
            "data_117.pt   data_1519.pt  data_1859.pt  data_504.pt  data_844.pt\n",
            "data_1180.pt  data_151.pt   data_185.pt   data_505.pt  data_845.pt\n",
            "data_1181.pt  data_1520.pt  data_1860.pt  data_506.pt  data_846.pt\n",
            "data_1182.pt  data_1521.pt  data_1861.pt  data_507.pt  data_847.pt\n",
            "data_1183.pt  data_1522.pt  data_1862.pt  data_508.pt  data_848.pt\n",
            "data_1184.pt  data_1523.pt  data_1863.pt  data_509.pt  data_849.pt\n",
            "data_1185.pt  data_1524.pt  data_1864.pt  data_50.pt   data_84.pt\n",
            "data_1186.pt  data_1525.pt  data_1865.pt  data_510.pt  data_850.pt\n",
            "data_1187.pt  data_1526.pt  data_1866.pt  data_511.pt  data_851.pt\n",
            "data_1188.pt  data_1527.pt  data_1867.pt  data_512.pt  data_852.pt\n",
            "data_1189.pt  data_1528.pt  data_1868.pt  data_513.pt  data_853.pt\n",
            "data_118.pt   data_1529.pt  data_1869.pt  data_514.pt  data_854.pt\n",
            "data_1190.pt  data_152.pt   data_186.pt   data_515.pt  data_855.pt\n",
            "data_1191.pt  data_1530.pt  data_1870.pt  data_516.pt  data_856.pt\n",
            "data_1192.pt  data_1531.pt  data_1871.pt  data_517.pt  data_857.pt\n",
            "data_1193.pt  data_1532.pt  data_1872.pt  data_518.pt  data_858.pt\n",
            "data_1194.pt  data_1533.pt  data_1873.pt  data_519.pt  data_859.pt\n",
            "data_1195.pt  data_1534.pt  data_1874.pt  data_51.pt   data_85.pt\n",
            "data_1196.pt  data_1535.pt  data_1875.pt  data_520.pt  data_860.pt\n",
            "data_1197.pt  data_1536.pt  data_1876.pt  data_521.pt  data_861.pt\n",
            "data_1198.pt  data_1537.pt  data_1877.pt  data_522.pt  data_862.pt\n",
            "data_1199.pt  data_1538.pt  data_1878.pt  data_523.pt  data_863.pt\n",
            "data_119.pt   data_1539.pt  data_1879.pt  data_524.pt  data_864.pt\n",
            "data_11.pt    data_153.pt   data_187.pt   data_525.pt  data_865.pt\n",
            "data_1200.pt  data_1540.pt  data_1880.pt  data_526.pt  data_866.pt\n",
            "data_1201.pt  data_1541.pt  data_188.pt   data_527.pt  data_867.pt\n",
            "data_1202.pt  data_1542.pt  data_189.pt   data_528.pt  data_868.pt\n",
            "data_1203.pt  data_1543.pt  data_18.pt\t  data_529.pt  data_869.pt\n",
            "data_1204.pt  data_1544.pt  data_190.pt   data_52.pt   data_86.pt\n",
            "data_1205.pt  data_1545.pt  data_191.pt   data_530.pt  data_870.pt\n",
            "data_1206.pt  data_1546.pt  data_192.pt   data_531.pt  data_871.pt\n",
            "data_1207.pt  data_1547.pt  data_193.pt   data_532.pt  data_872.pt\n",
            "data_1208.pt  data_1548.pt  data_194.pt   data_533.pt  data_873.pt\n",
            "data_1209.pt  data_1549.pt  data_195.pt   data_534.pt  data_874.pt\n",
            "data_120.pt   data_154.pt   data_196.pt   data_535.pt  data_875.pt\n",
            "data_1210.pt  data_1550.pt  data_197.pt   data_536.pt  data_876.pt\n",
            "data_1211.pt  data_1551.pt  data_198.pt   data_537.pt  data_877.pt\n",
            "data_1212.pt  data_1552.pt  data_199.pt   data_538.pt  data_878.pt\n",
            "data_1213.pt  data_1553.pt  data_19.pt\t  data_539.pt  data_879.pt\n",
            "data_1214.pt  data_1554.pt  data_1.pt\t  data_53.pt   data_87.pt\n",
            "data_1215.pt  data_1555.pt  data_200.pt   data_540.pt  data_880.pt\n",
            "data_1216.pt  data_1556.pt  data_201.pt   data_541.pt  data_881.pt\n",
            "data_1217.pt  data_1557.pt  data_202.pt   data_542.pt  data_882.pt\n",
            "data_1218.pt  data_1558.pt  data_203.pt   data_543.pt  data_883.pt\n",
            "data_1219.pt  data_1559.pt  data_204.pt   data_544.pt  data_884.pt\n",
            "data_121.pt   data_155.pt   data_205.pt   data_545.pt  data_885.pt\n",
            "data_1220.pt  data_1560.pt  data_206.pt   data_546.pt  data_886.pt\n",
            "data_1221.pt  data_1561.pt  data_207.pt   data_547.pt  data_887.pt\n",
            "data_1222.pt  data_1562.pt  data_208.pt   data_548.pt  data_888.pt\n",
            "data_1223.pt  data_1563.pt  data_209.pt   data_549.pt  data_889.pt\n",
            "data_1224.pt  data_1564.pt  data_20.pt\t  data_54.pt   data_88.pt\n",
            "data_1225.pt  data_1565.pt  data_210.pt   data_550.pt  data_890.pt\n",
            "data_1226.pt  data_1566.pt  data_211.pt   data_551.pt  data_891.pt\n",
            "data_1227.pt  data_1567.pt  data_212.pt   data_552.pt  data_892.pt\n",
            "data_1228.pt  data_1568.pt  data_213.pt   data_553.pt  data_893.pt\n",
            "data_1229.pt  data_1569.pt  data_214.pt   data_554.pt  data_894.pt\n",
            "data_122.pt   data_156.pt   data_215.pt   data_555.pt  data_895.pt\n",
            "data_1230.pt  data_1570.pt  data_216.pt   data_556.pt  data_896.pt\n",
            "data_1231.pt  data_1571.pt  data_217.pt   data_557.pt  data_897.pt\n",
            "data_1232.pt  data_1572.pt  data_218.pt   data_558.pt  data_898.pt\n",
            "data_1233.pt  data_1573.pt  data_219.pt   data_559.pt  data_899.pt\n",
            "data_1234.pt  data_1574.pt  data_21.pt\t  data_55.pt   data_89.pt\n",
            "data_1235.pt  data_1575.pt  data_220.pt   data_560.pt  data_8.pt\n",
            "data_1236.pt  data_1576.pt  data_221.pt   data_561.pt  data_900.pt\n",
            "data_1237.pt  data_1577.pt  data_222.pt   data_562.pt  data_901.pt\n",
            "data_1238.pt  data_1578.pt  data_223.pt   data_563.pt  data_902.pt\n",
            "data_1239.pt  data_1579.pt  data_224.pt   data_564.pt  data_903.pt\n",
            "data_123.pt   data_157.pt   data_225.pt   data_565.pt  data_904.pt\n",
            "data_1240.pt  data_1580.pt  data_226.pt   data_566.pt  data_905.pt\n",
            "data_1241.pt  data_1581.pt  data_227.pt   data_567.pt  data_906.pt\n",
            "data_1242.pt  data_1582.pt  data_228.pt   data_568.pt  data_907.pt\n",
            "data_1243.pt  data_1583.pt  data_229.pt   data_569.pt  data_908.pt\n",
            "data_1244.pt  data_1584.pt  data_22.pt\t  data_56.pt   data_909.pt\n",
            "data_1245.pt  data_1585.pt  data_230.pt   data_570.pt  data_90.pt\n",
            "data_1246.pt  data_1586.pt  data_231.pt   data_571.pt  data_910.pt\n",
            "data_1247.pt  data_1587.pt  data_232.pt   data_572.pt  data_911.pt\n",
            "data_1248.pt  data_1588.pt  data_233.pt   data_573.pt  data_912.pt\n",
            "data_1249.pt  data_1589.pt  data_234.pt   data_574.pt  data_913.pt\n",
            "data_124.pt   data_158.pt   data_235.pt   data_575.pt  data_914.pt\n",
            "data_1250.pt  data_1590.pt  data_236.pt   data_576.pt  data_915.pt\n",
            "data_1251.pt  data_1591.pt  data_237.pt   data_577.pt  data_916.pt\n",
            "data_1252.pt  data_1592.pt  data_238.pt   data_578.pt  data_917.pt\n",
            "data_1253.pt  data_1593.pt  data_239.pt   data_579.pt  data_918.pt\n",
            "data_1254.pt  data_1594.pt  data_23.pt\t  data_57.pt   data_919.pt\n",
            "data_1255.pt  data_1595.pt  data_240.pt   data_580.pt  data_91.pt\n",
            "data_1256.pt  data_1596.pt  data_241.pt   data_581.pt  data_920.pt\n",
            "data_1257.pt  data_1597.pt  data_242.pt   data_582.pt  data_921.pt\n",
            "data_1258.pt  data_1598.pt  data_243.pt   data_583.pt  data_922.pt\n",
            "data_1259.pt  data_1599.pt  data_244.pt   data_584.pt  data_923.pt\n",
            "data_125.pt   data_159.pt   data_245.pt   data_585.pt  data_924.pt\n",
            "data_1260.pt  data_15.pt    data_246.pt   data_586.pt  data_925.pt\n",
            "data_1261.pt  data_1600.pt  data_247.pt   data_587.pt  data_926.pt\n",
            "data_1262.pt  data_1601.pt  data_248.pt   data_588.pt  data_927.pt\n",
            "data_1263.pt  data_1602.pt  data_249.pt   data_589.pt  data_928.pt\n",
            "data_1264.pt  data_1603.pt  data_24.pt\t  data_58.pt   data_929.pt\n",
            "data_1265.pt  data_1604.pt  data_250.pt   data_590.pt  data_92.pt\n",
            "data_1266.pt  data_1605.pt  data_251.pt   data_591.pt  data_930.pt\n",
            "data_1267.pt  data_1606.pt  data_252.pt   data_592.pt  data_931.pt\n",
            "data_1268.pt  data_1607.pt  data_253.pt   data_593.pt  data_932.pt\n",
            "data_1269.pt  data_1608.pt  data_254.pt   data_594.pt  data_933.pt\n",
            "data_126.pt   data_1609.pt  data_255.pt   data_595.pt  data_934.pt\n",
            "data_1270.pt  data_160.pt   data_256.pt   data_596.pt  data_935.pt\n",
            "data_1271.pt  data_1610.pt  data_257.pt   data_597.pt  data_936.pt\n",
            "data_1272.pt  data_1611.pt  data_258.pt   data_598.pt  data_937.pt\n",
            "data_1273.pt  data_1612.pt  data_259.pt   data_599.pt  data_938.pt\n",
            "data_1274.pt  data_1613.pt  data_25.pt\t  data_59.pt   data_939.pt\n",
            "data_1275.pt  data_1614.pt  data_260.pt   data_5.pt    data_93.pt\n",
            "data_1276.pt  data_1615.pt  data_261.pt   data_600.pt  data_940.pt\n",
            "data_1277.pt  data_1616.pt  data_262.pt   data_601.pt  data_941.pt\n",
            "data_1278.pt  data_1617.pt  data_263.pt   data_602.pt  data_942.pt\n",
            "data_1279.pt  data_1618.pt  data_264.pt   data_603.pt  data_943.pt\n",
            "data_127.pt   data_1619.pt  data_265.pt   data_604.pt  data_944.pt\n",
            "data_1280.pt  data_161.pt   data_266.pt   data_605.pt  data_945.pt\n",
            "data_1281.pt  data_1620.pt  data_267.pt   data_606.pt  data_946.pt\n",
            "data_1282.pt  data_1621.pt  data_268.pt   data_607.pt  data_947.pt\n",
            "data_1283.pt  data_1622.pt  data_269.pt   data_608.pt  data_948.pt\n",
            "data_1284.pt  data_1623.pt  data_26.pt\t  data_609.pt  data_949.pt\n",
            "data_1285.pt  data_1624.pt  data_270.pt   data_60.pt   data_94.pt\n",
            "data_1286.pt  data_1625.pt  data_271.pt   data_610.pt  data_950.pt\n",
            "data_1287.pt  data_1626.pt  data_272.pt   data_611.pt  data_951.pt\n",
            "data_1288.pt  data_1627.pt  data_273.pt   data_612.pt  data_952.pt\n",
            "data_1289.pt  data_1628.pt  data_274.pt   data_613.pt  data_953.pt\n",
            "data_128.pt   data_1629.pt  data_275.pt   data_614.pt  data_954.pt\n",
            "data_1290.pt  data_162.pt   data_276.pt   data_615.pt  data_955.pt\n",
            "data_1291.pt  data_1630.pt  data_277.pt   data_616.pt  data_956.pt\n",
            "data_1292.pt  data_1631.pt  data_278.pt   data_617.pt  data_957.pt\n",
            "data_1293.pt  data_1632.pt  data_279.pt   data_618.pt  data_958.pt\n",
            "data_1294.pt  data_1633.pt  data_27.pt\t  data_619.pt  data_959.pt\n",
            "data_1295.pt  data_1634.pt  data_280.pt   data_61.pt   data_95.pt\n",
            "data_1296.pt  data_1635.pt  data_281.pt   data_620.pt  data_960.pt\n",
            "data_1297.pt  data_1636.pt  data_282.pt   data_621.pt  data_961.pt\n",
            "data_1298.pt  data_1637.pt  data_283.pt   data_622.pt  data_962.pt\n",
            "data_1299.pt  data_1638.pt  data_284.pt   data_623.pt  data_963.pt\n",
            "data_129.pt   data_1639.pt  data_285.pt   data_624.pt  data_964.pt\n",
            "data_12.pt    data_163.pt   data_286.pt   data_625.pt  data_965.pt\n",
            "data_1300.pt  data_1640.pt  data_287.pt   data_626.pt  data_966.pt\n",
            "data_1301.pt  data_1641.pt  data_288.pt   data_627.pt  data_967.pt\n",
            "data_1302.pt  data_1642.pt  data_289.pt   data_628.pt  data_968.pt\n",
            "data_1303.pt  data_1643.pt  data_28.pt\t  data_629.pt  data_969.pt\n",
            "data_1304.pt  data_1644.pt  data_290.pt   data_62.pt   data_96.pt\n",
            "data_1305.pt  data_1645.pt  data_291.pt   data_630.pt  data_970.pt\n",
            "data_1306.pt  data_1646.pt  data_292.pt   data_631.pt  data_971.pt\n",
            "data_1307.pt  data_1647.pt  data_293.pt   data_632.pt  data_972.pt\n",
            "data_1308.pt  data_1648.pt  data_294.pt   data_633.pt  data_973.pt\n",
            "data_1309.pt  data_1649.pt  data_295.pt   data_634.pt  data_974.pt\n",
            "data_130.pt   data_164.pt   data_296.pt   data_635.pt  data_975.pt\n",
            "data_1310.pt  data_1650.pt  data_297.pt   data_636.pt  data_976.pt\n",
            "data_1311.pt  data_1651.pt  data_298.pt   data_637.pt  data_977.pt\n",
            "data_1312.pt  data_1652.pt  data_299.pt   data_638.pt  data_978.pt\n",
            "data_1313.pt  data_1653.pt  data_29.pt\t  data_639.pt  data_979.pt\n",
            "data_1314.pt  data_1654.pt  data_2.pt\t  data_63.pt   data_97.pt\n",
            "data_1315.pt  data_1655.pt  data_300.pt   data_640.pt  data_980.pt\n",
            "data_1316.pt  data_1656.pt  data_301.pt   data_641.pt  data_981.pt\n",
            "data_1317.pt  data_1657.pt  data_302.pt   data_642.pt  data_982.pt\n",
            "data_1318.pt  data_1658.pt  data_303.pt   data_643.pt  data_983.pt\n",
            "data_1319.pt  data_1659.pt  data_304.pt   data_644.pt  data_984.pt\n",
            "data_131.pt   data_165.pt   data_305.pt   data_645.pt  data_985.pt\n",
            "data_1320.pt  data_1660.pt  data_306.pt   data_646.pt  data_986.pt\n",
            "data_1321.pt  data_1661.pt  data_307.pt   data_647.pt  data_987.pt\n",
            "data_1322.pt  data_1662.pt  data_308.pt   data_648.pt  data_988.pt\n",
            "data_1323.pt  data_1663.pt  data_309.pt   data_649.pt  data_989.pt\n",
            "data_1324.pt  data_1664.pt  data_30.pt\t  data_64.pt   data_98.pt\n",
            "data_1325.pt  data_1665.pt  data_310.pt   data_650.pt  data_990.pt\n",
            "data_1326.pt  data_1666.pt  data_311.pt   data_651.pt  data_991.pt\n",
            "data_1327.pt  data_1667.pt  data_312.pt   data_652.pt  data_992.pt\n",
            "data_1328.pt  data_1668.pt  data_313.pt   data_653.pt  data_993.pt\n",
            "data_1329.pt  data_1669.pt  data_314.pt   data_654.pt  data_994.pt\n",
            "data_132.pt   data_166.pt   data_315.pt   data_655.pt  data_995.pt\n",
            "data_1330.pt  data_1670.pt  data_316.pt   data_656.pt  data_996.pt\n",
            "data_1331.pt  data_1671.pt  data_317.pt   data_657.pt  data_997.pt\n",
            "data_1332.pt  data_1672.pt  data_318.pt   data_658.pt  data_998.pt\n",
            "data_1333.pt  data_1673.pt  data_319.pt   data_659.pt  data_999.pt\n",
            "data_1334.pt  data_1674.pt  data_31.pt\t  data_65.pt   data_99.pt\n",
            "data_1335.pt  data_1675.pt  data_320.pt   data_660.pt  data_9.pt\n",
            "data_1336.pt  data_1676.pt  data_321.pt   data_661.pt  pre_filter.pt\n",
            "data_1337.pt  data_1677.pt  data_322.pt   data_662.pt  pre_transform.pt\n",
            "data_1338.pt  data_1678.pt  data_323.pt   data_663.pt\n",
            "data_1339.pt  data_1679.pt  data_324.pt   data_664.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Dataset"
      ],
      "metadata": {
        "id": "ksFoSu69IP1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('====================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "Rv8nGlfyIWFw",
        "outputId": "3835b1f9-d27c-4ad7-9d95-9251ab6ae6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: SourceTestDataset(69):\n",
            "====================\n",
            "Number of graphs: 69\n",
            "Number of features: 4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-f372c5080185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of graphs: {len(dataset)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of features: {dataset.num_features}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of classes: {dataset.num_classes}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36mnum_classes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;34mr\"\"\"Returns the number of classes in the dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Do not fill cache for `InMemoryDataset`:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_data_list'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.processed_file_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu_KqtomJdmP",
        "outputId": "05ed5193-757d-4eb6-ee65-eb7ae9bcf362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0USoFtG5Wr0f",
        "outputId": "de4c40b4-5084-48ce-8437-c2afe12b42f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/dataset.py\u001b[0m(152)\u001b[0;36mnum_classes\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    150 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    151 \u001b[0;31m        \u001b[0;34mr\"\"\"Returns the number of classes in the dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 152 \u001b[0;31m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    153 \u001b[0;31m        \u001b[0;31m# Do not fill cache for `InMemoryDataset`:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    154 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_data_list'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> self\n",
            "SourceTestDataset(69)\n",
            "ipdb> list(self)[0]\n",
            "*** Error in argument: '(self)[0]'\n",
            "ipdb> print(list(self))\n",
            "[Data(x=[3358, 4], edge_index=[3358, 4], edge_attr=[3358, 4]), Data(x=[14029, 4], edge_index=[14029, 4], edge_attr=[14029, 4]), Data(x=[2797, 4], edge_index=[2797, 4], edge_attr=[2797, 4]), Data(x=[2122, 4], edge_index=[2122, 4], edge_attr=[2122, 4]), Data(x=[4649, 4], edge_index=[4649, 4], edge_attr=[4649, 4]), Data(x=[11484, 4], edge_index=[11484, 4], edge_attr=[11484, 4]), Data(x=[3297, 4], edge_index=[3297, 4], edge_attr=[3297, 4]), Data(x=[3946, 4], edge_index=[3946, 4], edge_attr=[3946, 4]), Data(x=[2438, 4], edge_index=[2438, 4], edge_attr=[2438, 4]), Data(x=[3189, 4], edge_index=[3189, 4], edge_attr=[3189, 4]), Data(x=[3141, 4], edge_index=[3141, 4], edge_attr=[3141, 4]), Data(x=[3732, 4], edge_index=[3732, 4], edge_attr=[3732, 4]), Data(x=[8205, 4], edge_index=[8205, 4], edge_attr=[8205, 4]), Data(x=[1703, 4], edge_index=[1703, 4], edge_attr=[1703, 4]), Data(x=[16583, 4], edge_index=[16583, 4], edge_attr=[16583, 4]), Data(x=[2235, 4], edge_index=[2235, 4], edge_attr=[2235, 4]), Data(x=[1968, 4], edge_index=[1968, 4], edge_attr=[1968, 4]), Data(x=[1922, 4], edge_index=[1922, 4], edge_attr=[1922, 4]), Data(x=[1697, 4], edge_index=[1697, 4], edge_attr=[1697, 4]), Data(x=[2948, 4], edge_index=[2948, 4], edge_attr=[2948, 4]), Data(x=[4094, 4], edge_index=[4094, 4], edge_attr=[4094, 4]), Data(x=[5184, 4], edge_index=[5184, 4], edge_attr=[5184, 4]), Data(x=[2690, 4], edge_index=[2690, 4], edge_attr=[2690, 4]), Data(x=[2128, 4], edge_index=[2128, 4], edge_attr=[2128, 4]), Data(x=[11989, 4], edge_index=[11989, 4], edge_attr=[11989, 4]), Data(x=[3002, 4], edge_index=[3002, 4], edge_attr=[3002, 4]), Data(x=[6990, 4], edge_index=[6990, 4], edge_attr=[6990, 4]), Data(x=[5885, 4], edge_index=[5885, 4], edge_attr=[5885, 4]), Data(x=[7533, 4], edge_index=[7533, 4], edge_attr=[7533, 4]), Data(x=[26357, 4], edge_index=[26357, 4], edge_attr=[26357, 4]), Data(x=[25843, 4], edge_index=[25843, 4], edge_attr=[25843, 4]), Data(x=[1996, 4], edge_index=[1996, 4], edge_attr=[1996, 4]), Data(x=[2419, 4], edge_index=[2419, 4], edge_attr=[2419, 4]), Data(x=[4367, 4], edge_index=[4367, 4], edge_attr=[4367, 4]), Data(x=[2440, 4], edge_index=[2440, 4], edge_attr=[2440, 4]), Data(x=[5422, 4], edge_index=[5422, 4], edge_attr=[5422, 4]), Data(x=[10431, 4], edge_index=[10431, 4], edge_attr=[10431, 4]), Data(x=[3252, 4], edge_index=[3252, 4], edge_attr=[3252, 4]), Data(x=[4681, 4], edge_index=[4681, 4], edge_attr=[4681, 4]), Data(x=[2172, 4], edge_index=[2172, 4], edge_attr=[2172, 4]), Data(x=[4514, 4], edge_index=[4514, 4], edge_attr=[4514, 4]), Data(x=[4555, 4], edge_index=[4555, 4], edge_attr=[4555, 4]), Data(x=[36493, 4], edge_index=[36493, 4], edge_attr=[36493, 4]), Data(x=[1813, 4], edge_index=[1813, 4], edge_attr=[1813, 4]), Data(x=[2046, 4], edge_index=[2046, 4], edge_attr=[2046, 4]), Data(x=[11038, 4], edge_index=[11038, 4], edge_attr=[11038, 4]), Data(x=[3370, 4], edge_index=[3370, 4], edge_attr=[3370, 4]), Data(x=[4818, 4], edge_index=[4818, 4], edge_attr=[4818, 4]), Data(x=[2297, 4], edge_index=[2297, 4], edge_attr=[2297, 4]), Data(x=[18755, 4], edge_index=[18755, 4], edge_attr=[18755, 4]), Data(x=[2152, 4], edge_index=[2152, 4], edge_attr=[2152, 4]), Data(x=[10429, 4], edge_index=[10429, 4], edge_attr=[10429, 4]), Data(x=[2690, 4], edge_index=[2690, 4], edge_attr=[2690, 4]), Data(x=[2395, 4], edge_index=[2395, 4], edge_attr=[2395, 4]), Data(x=[2801, 4], edge_index=[2801, 4], edge_attr=[2801, 4]), Data(x=[2089, 4], edge_index=[2089, 4], edge_attr=[2089, 4]), Data(x=[2286, 4], edge_index=[2286, 4], edge_attr=[2286, 4]), Data(x=[11462, 4], edge_index=[11462, 4], edge_attr=[11462, 4]), Data(x=[22133, 4], edge_index=[22133, 4], edge_attr=[22133, 4]), Data(x=[10901, 4], edge_index=[10901, 4], edge_attr=[10901, 4]), Data(x=[10226, 4], edge_index=[10226, 4], edge_attr=[10226, 4]), Data(x=[12753, 4], edge_index=[12753, 4], edge_attr=[12753, 4]), Data(x=[19588, 4], edge_index=[19588, 4], edge_attr=[19588, 4]), Data(x=[11401, 4], edge_index=[11401, 4], edge_attr=[11401, 4]), Data(x=[12050, 4], edge_index=[12050, 4], edge_attr=[12050, 4]), Data(x=[10542, 4], edge_index=[10542, 4], edge_attr=[10542, 4]), Data(x=[11293, 4], edge_index=[11293, 4], edge_attr=[11293, 4]), Data(x=[11245, 4], edge_index=[11245, 4], edge_attr=[11245, 4]), Data(x=[11836, 4], edge_index=[11836, 4], edge_attr=[11836, 4])]\n",
            "ipdb> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "uCp8XqYORr46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Parameters"
      ],
      "metadata": {
        "id": "rLnWBuZhKZCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = 0.8\n",
        "batch_size = 64\n",
        "hidden_channels = 64\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "lJHfytlTKcmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/Test split"
      ],
      "metadata": {
        "id": "7mu7WUHAIgQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(12345)\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "split_idx = int(len(dataset)*split_ratio)\n",
        "\n",
        "train_dataset = dataset[:split_idx]\n",
        "test_dataset = dataset[split_idx:]\n",
        "\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "kZVcVry9Imgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Dataset Loader"
      ],
      "metadata": {
        "id": "4todTZosLdmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for step, data in enumerate(train_loader):\n",
        "    print(f'Step {step + 1}:')\n",
        "    print('=======')\n",
        "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(data)\n",
        "    print()"
      ],
      "metadata": {
        "id": "fHOfyT5JLgVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### neptune.ai Integration"
      ],
      "metadata": {
        "id": "d0CbMz5aqAgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -Uqqq neptune-client\n",
        "import neptune.new as neptune\n",
        "\n",
        "neptune_api_token = getpass(\"Enter your Neptune API token: \")\n",
        "\n",
        "project = \"tjsun009/test-src-classifier\"\n",
        "\n",
        "run = neptune.init_run(\n",
        "    api_token=neptune_api_token,\n",
        "    project=project,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC8TnzX8qJ0A",
        "outputId": "43be4368-b15d-4d8d-bba3-0ae0ad82f350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pq-VyzUwPpw"
      },
      "source": [
        "## Training a Graph Neural Network (GNN)\n",
        "\n",
        "copied from: https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb\n",
        "\n",
        "Training a GNN for graph classification usually follows a simple recipe:\n",
        "\n",
        "1. Embed each node by performing multiple rounds of message passing\n",
        "2. Aggregate node embeddings into a unified graph embedding (**readout layer**)\n",
        "3. Train a final classifier on the graph embedding\n",
        "\n",
        "There exists multiple **readout layers** in literature, but the most common one is to simply take the average of node embeddings:\n",
        "\n",
        "$$\n",
        "\\mathbf{x}_{\\mathcal{G}} = \\frac{1}{|\\mathcal{V}|} \\sum_{v \\in \\mathcal{V}} \\mathcal{x}^{(L)}_v\n",
        "$$\n",
        "\n",
        "PyTorch Geometric provides this functionality via [`torch_geometric.nn.global_mean_pool`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.glob.global_mean_pool), which takes in the node embeddings of all nodes in the mini-batch and the assignment vector `batch` to compute a graph embedding of size `[batch_size, hidden_channels]` for each graph in the batch.\n",
        "\n",
        "The final architecture for applying GNNs to the task of graph classification then looks as follows and allows for complete end-to-end training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN3sRVuaQ88l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c998ba-b387-4413-d7d3-2101a27495bd"
      },
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Obtain node embeddings \n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=hidden_channels)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(7, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Q37tbHyQ6A"
      },
      "source": [
        "Here, we again make use of the [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) with $\\mathrm{ReLU}(x) = \\max(x, 0)$ activation for obtaining localized node embeddings, before we apply our final classifier on top of a graph readout layer.\n",
        "\n",
        "Let's train our network for a few epochs to see how well it performs on the training as well as test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvhgQoO8Svw4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4d17af35-85c8-4bcd-8e16-c514fd2ff714"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
        "         loss = criterion(out, data.y)  # Compute the loss.\n",
        "         loss.backward()  # Derive gradients.\n",
        "         optimizer.step()  # Update parameters based on gradients.\n",
        "         optimizer.zero_grad()  # Clear gradients.\n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  \n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
        "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
        "\n",
        "\n",
        "for epoch in range(1, 171):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 002, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 003, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 004, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 005, Train Acc: 0.6467, Test Acc: 0.7368\n",
            "Epoch: 006, Train Acc: 0.6533, Test Acc: 0.7368\n",
            "Epoch: 007, Train Acc: 0.7467, Test Acc: 0.7632\n",
            "Epoch: 008, Train Acc: 0.7267, Test Acc: 0.7632\n",
            "Epoch: 009, Train Acc: 0.7200, Test Acc: 0.7632\n",
            "Epoch: 010, Train Acc: 0.7133, Test Acc: 0.7895\n",
            "Epoch: 011, Train Acc: 0.7200, Test Acc: 0.7632\n",
            "Epoch: 012, Train Acc: 0.7200, Test Acc: 0.7895\n",
            "Epoch: 013, Train Acc: 0.7200, Test Acc: 0.7895\n",
            "Epoch: 014, Train Acc: 0.7133, Test Acc: 0.8421\n",
            "Epoch: 015, Train Acc: 0.7133, Test Acc: 0.8421\n",
            "Epoch: 016, Train Acc: 0.7533, Test Acc: 0.7368\n",
            "Epoch: 017, Train Acc: 0.7400, Test Acc: 0.7632\n",
            "Epoch: 018, Train Acc: 0.7133, Test Acc: 0.8421\n",
            "Epoch: 019, Train Acc: 0.7400, Test Acc: 0.7895\n",
            "Epoch: 020, Train Acc: 0.7533, Test Acc: 0.7368\n",
            "Epoch: 021, Train Acc: 0.7467, Test Acc: 0.7895\n",
            "Epoch: 022, Train Acc: 0.7467, Test Acc: 0.7895\n",
            "Epoch: 023, Train Acc: 0.7533, Test Acc: 0.7895\n",
            "Epoch: 024, Train Acc: 0.7267, Test Acc: 0.8421\n",
            "Epoch: 025, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 026, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 027, Train Acc: 0.7600, Test Acc: 0.8158\n",
            "Epoch: 028, Train Acc: 0.7533, Test Acc: 0.8421\n",
            "Epoch: 029, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 030, Train Acc: 0.7600, Test Acc: 0.8158\n",
            "Epoch: 031, Train Acc: 0.7600, Test Acc: 0.8158\n",
            "Epoch: 032, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 033, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 034, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 035, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 036, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 037, Train Acc: 0.7400, Test Acc: 0.7632\n",
            "Epoch: 038, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 039, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 040, Train Acc: 0.7533, Test Acc: 0.7368\n",
            "Epoch: 041, Train Acc: 0.7467, Test Acc: 0.7368\n",
            "Epoch: 042, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 043, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 044, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 045, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 046, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 047, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 048, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 049, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 050, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 051, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 052, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 053, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 054, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 055, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 056, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 057, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 058, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 059, Train Acc: 0.7800, Test Acc: 0.7632\n",
            "Epoch: 060, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 061, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 062, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 063, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 064, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 065, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 066, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 067, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 068, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 069, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 070, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 071, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 072, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 073, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 074, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 075, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 076, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 077, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 078, Train Acc: 0.7733, Test Acc: 0.8421\n",
            "Epoch: 079, Train Acc: 0.7667, Test Acc: 0.8158\n",
            "Epoch: 080, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 081, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 082, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 083, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 084, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 085, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 086, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 087, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 088, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 089, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 090, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 091, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 092, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 093, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 094, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 095, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 096, Train Acc: 0.7600, Test Acc: 0.7895\n",
            "Epoch: 097, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 098, Train Acc: 0.7733, Test Acc: 0.8158\n",
            "Epoch: 099, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 100, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 101, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 102, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 103, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 104, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 105, Train Acc: 0.7733, Test Acc: 0.7368\n",
            "Epoch: 106, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 107, Train Acc: 0.7733, Test Acc: 0.7105\n",
            "Epoch: 108, Train Acc: 0.8000, Test Acc: 0.7632\n",
            "Epoch: 109, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 110, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 111, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 112, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 113, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 114, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 115, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 116, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 117, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 118, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 119, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 120, Train Acc: 0.8000, Test Acc: 0.7105\n",
            "Epoch: 121, Train Acc: 0.7600, Test Acc: 0.7632\n",
            "Epoch: 122, Train Acc: 0.7667, Test Acc: 0.7105\n",
            "Epoch: 123, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 124, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 125, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 126, Train Acc: 0.7733, Test Acc: 0.7368\n",
            "Epoch: 127, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 128, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 129, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 130, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 131, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 132, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 133, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 134, Train Acc: 0.7667, Test Acc: 0.7632\n",
            "Epoch: 135, Train Acc: 0.8067, Test Acc: 0.7368\n",
            "Epoch: 136, Train Acc: 0.7800, Test Acc: 0.7632\n",
            "Epoch: 137, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 138, Train Acc: 0.8133, Test Acc: 0.7105\n",
            "Epoch: 139, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 140, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 141, Train Acc: 0.8000, Test Acc: 0.6579\n",
            "Epoch: 142, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 143, Train Acc: 0.7933, Test Acc: 0.7632\n",
            "Epoch: 144, Train Acc: 0.7867, Test Acc: 0.7368\n",
            "Epoch: 145, Train Acc: 0.8267, Test Acc: 0.7368\n",
            "Epoch: 146, Train Acc: 0.7667, Test Acc: 0.7895\n",
            "Epoch: 147, Train Acc: 0.7800, Test Acc: 0.7105\n",
            "Epoch: 148, Train Acc: 0.7933, Test Acc: 0.7895\n",
            "Epoch: 149, Train Acc: 0.8200, Test Acc: 0.7105\n",
            "Epoch: 150, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 151, Train Acc: 0.7800, Test Acc: 0.7632\n",
            "Epoch: 152, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 153, Train Acc: 0.8067, Test Acc: 0.7368\n",
            "Epoch: 154, Train Acc: 0.8067, Test Acc: 0.7368\n",
            "Epoch: 155, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 156, Train Acc: 0.7800, Test Acc: 0.7105\n",
            "Epoch: 157, Train Acc: 0.8000, Test Acc: 0.7368\n",
            "Epoch: 158, Train Acc: 0.7800, Test Acc: 0.7368\n",
            "Epoch: 159, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 160, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 161, Train Acc: 0.7800, Test Acc: 0.7632\n",
            "Epoch: 162, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 163, Train Acc: 0.7867, Test Acc: 0.7632\n",
            "Epoch: 164, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 165, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 166, Train Acc: 0.7733, Test Acc: 0.7632\n",
            "Epoch: 167, Train Acc: 0.7867, Test Acc: 0.7895\n",
            "Epoch: 168, Train Acc: 0.7867, Test Acc: 0.7895\n",
            "Epoch: 169, Train Acc: 0.8000, Test Acc: 0.7632\n",
            "Epoch: 170, Train Acc: 0.8000, Test Acc: 0.7632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mTJL0WfzeBq"
      },
      "source": [
        "As one can see, our model reaches around **76% test accuracy**.\n",
        "Reasons for the fluctations in accuracy can be explained by the rather small dataset (only 38 test graphs), and usually disappear once one applies GNNs to larger datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Neptune"
      ],
      "metadata": {
        "id": "-8vjanQAls2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stop neptune\n",
        "run.stop()"
      ],
      "metadata": {
        "id": "XQ4LwHDMH0DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# idea for doing tested source MLM\n",
        "# provide the source graph as input and mask a node in the test graph randomly\n",
        "# predict what the node is, including node_type, node_value if applicable "
      ],
      "metadata": {
        "id": "3l-ghrohKAcO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "X2de2lPwdQXn",
        "bgjOkMrriB-Q",
        "NGiAvVTs535v",
        "6h3hDQAKiSK2",
        "D3ThqF6zVgR_",
        "LJq3_r9jFem7",
        "ILzKE0s9F_gU",
        "XYDzw1GVdjKe",
        "pYH9kJs2dTSf",
        "-tYAVWXzdoN4",
        "xRWkelnRF2lE",
        "Nm0Iqtv0rC5u",
        "d0CbMz5aqAgR",
        "c5Ehm0ON8sh9",
        "-8vjanQAls2N"
      ],
      "provenance": [],
      "mount_file_id": "1J3-QrijqHd0jsI8uAtQTDWGNkiXTw3sb",
      "authorship_tag": "ABX9TyODlD5NxysmnqqWhscQJ9LF",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f98c4adc5fda411993c4cb551fbafb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88598251aacd4aa39fe18904cf892333",
              "IPY_MODEL_9f060855b73a46d69f2ec04377d8f126",
              "IPY_MODEL_e957ca5b6fda40e4adbdd1af127e5219"
            ],
            "layout": "IPY_MODEL_dac1646762024043815271547c773688"
          }
        },
        "88598251aacd4aa39fe18904cf892333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a6f0a7af7140edae6851cc0f436218",
            "placeholder": "​",
            "style": "IPY_MODEL_6f4e2b3684154676b7f8b14ec6818871",
            "value": "Could not parse iostream.py: 100%"
          }
        },
        "9f060855b73a46d69f2ec04377d8f126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fdbe10ab92c4f4c9ccc7336ee3dc87f",
            "max": 4761,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31f12173d1d6496dadb96331cce58cfa",
            "value": 4761
          }
        },
        "e957ca5b6fda40e4adbdd1af127e5219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7cd7ec5fbe94eba91399f83c917861c",
            "placeholder": "​",
            "style": "IPY_MODEL_628c152e1d184016af2871365b470161",
            "value": " 4761/4761 [3:19:00&lt;00:00,  8.79it/s]"
          }
        },
        "dac1646762024043815271547c773688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a6f0a7af7140edae6851cc0f436218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f4e2b3684154676b7f8b14ec6818871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fdbe10ab92c4f4c9ccc7336ee3dc87f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f12173d1d6496dadb96331cce58cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7cd7ec5fbe94eba91399f83c917861c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628c152e1d184016af2871365b470161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}